{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a617a22a-8bd1-432c-9dd2-7c22c79bd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d4279d-8b83-427e-8c9a-f7e09c805103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from copy import copy\n",
    "from pprint import pprint\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import abc\n",
    "import sys\n",
    "import re\n",
    "sys.path.append(\"../\")\n",
    "import gpusims\n",
    "import gpusims.plot.metrics as metric\n",
    "from gpusims.plot.data import PlotData\n",
    "from gpusims.config import Config, parse_configs\n",
    "from gpusims.bench import parse_benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6b2101-e133-4d35-b06f-1a4bb2906112",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 700)\n",
    "pd.set_option('display.max_columns', 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a54e1e5-a25c-4a1c-bf2e-5c42a1d16411",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path(\"/Users/roman/dev/gpgpusims\")\n",
    "benchmark_dir = root_dir / \"benchmarks\"\n",
    "run_dir = root_dir / \"run\"\n",
    "assert benchmark_dir.is_dir()\n",
    "assert run_dir.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d8e610e-18a1-4b33-9203-7616305b48f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sm6_gtx1080': Config(key='sm6_gtx1080', name='GTX 1080', path=PosixPath('/Users/roman/dev/gpgpusims/benchmarks/configs/SM6_GTX1080'), spec={'sm_count': 20, 'clock_speed': 1607}),\n",
      " 'sm86_a4000': Config(key='sm86_a4000', name='A4000', path=PosixPath('/Users/roman/dev/gpgpusims/benchmarks/configs/SM86_A4000'), spec={'sm_count': 48, 'clock_speed': 735}),\n",
      " 'sm86_rtx3070': Config(key='sm86_rtx3070', name='RTX 3070', path=PosixPath('/Users/roman/dev/gpgpusims/benchmarks/configs/SM86_RTX3070'), spec={'sm_count': 46, 'clock_speed': 1132})}\n",
      "{'babelstream': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/BabelStream),\n",
      " 'cuda10-matrixmul': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/CUDA10-matrixMul),\n",
      " 'cuda10-transpose': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/CUDA10-transpose),\n",
      " 'cuda4-matrixmul': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/CUDA4-matrixMul),\n",
      " 'cuda6-transpose': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/CUDA6-transpose),\n",
      " 'vectoradd': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/vectorAdd)}\n",
      "{'accelsim-ptx': <class 'gpusims.accelsim.AccelSimPTXBenchmarkConfig'>,\n",
      " 'accelsim-sass': <class 'gpusims.accelsim_sass.AccelSimSASSBenchmarkConfig'>,\n",
      " 'm2s': <class 'gpusims.multi2sim.Multi2SimBenchmarkConfig'>,\n",
      " 'macsim': <class 'gpusims.macsim.MacSimBenchmarkConfig'>,\n",
      " 'native': <class 'gpusims.native.NativeBenchmarkConfig'>,\n",
      " 'tejas': <class 'gpusims.tejas.TejasBenchmarkConfig'>}\n"
     ]
    }
   ],
   "source": [
    "configs = parse_configs(benchmark_dir / \"configs\" / \"configs.yml\")\n",
    "benchmarks = parse_benchmarks(benchmark_dir / \"benchmarks.yml\")\n",
    "\n",
    "pprint(configs)\n",
    "pprint(benchmarks)\n",
    "pprint(gpusims.SIMULATORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68244716-1464-4238-83d5-29c944414f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accelsim-ptx': <class 'gpusims.accelsim.AccelSimPTXBenchmarkConfig'>,\n",
      " 'accelsim-sass': <class 'gpusims.accelsim_sass.AccelSimSASSBenchmarkConfig'>,\n",
      " 'm2s': <class 'gpusims.multi2sim.Multi2SimBenchmarkConfig'>,\n",
      " 'macsim': <class 'gpusims.macsim.MacSimBenchmarkConfig'>,\n",
      " 'native': <class 'gpusims.native.NativeBenchmarkConfig'>,\n",
      " 'tejas': <class 'gpusims.tejas.TejasBenchmarkConfig'>}\n",
      "{'sm6_gtx1080': Config(key='sm6_gtx1080', name='GTX 1080', path=PosixPath('/Users/roman/dev/gpgpusims/benchmarks/configs/SM6_GTX1080'), spec={'sm_count': 20, 'clock_speed': 1607}),\n",
      " 'sm86_a4000': Config(key='sm86_a4000', name='A4000', path=PosixPath('/Users/roman/dev/gpgpusims/benchmarks/configs/SM86_A4000'), spec={'sm_count': 48, 'clock_speed': 735})}\n",
      "{'babelstream': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/BabelStream),\n",
      " 'cuda10-matrixmul': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/CUDA10-matrixMul),\n",
      " 'cuda10-transpose': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/CUDA10-transpose),\n",
      " 'cuda4-matrixmul': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/CUDA4-matrixMul),\n",
      " 'cuda6-transpose': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/CUDA6-transpose),\n",
      " 'vectoradd': Benchmark(/Users/roman/dev/gpgpusims/benchmarks/vectorAdd)}\n"
     ]
    }
   ],
   "source": [
    "selected_simulators = copy(gpusims.SIMULATORS)\n",
    "selected_configs = copy(configs)\n",
    "selected_benchmarks = copy(benchmarks)\n",
    "\n",
    "# for testing\n",
    "if True:\n",
    "    testing_simulators = None\n",
    "    testing_configs = None\n",
    "    testing_benchmarks = None\n",
    "    # testing_simulators = list(gpusims.SIMULATORS.keys())\n",
    "    # testing_simulators = [gpusims.NATIVE]\n",
    "    # testing_simulators = [gpusims.MULTI2SIM]\n",
    "    testing_configs = [\"sm6_gtx1080\", \"sm86_a4000\"]\n",
    "    # testing_benchmarks = [\"babelstream\"] # \"cuda6-transpose\"]\n",
    "    \n",
    "    if testing_simulators is not None:\n",
    "        selected_simulators = {k: v for k, v in gpusims.SIMULATORS.items() if k in testing_simulators}\n",
    "    if testing_configs is not None:\n",
    "        selected_configs = {k: v for k, v in configs.items() if k in testing_configs}\n",
    "    if testing_benchmarks is not None:\n",
    "        selected_benchmarks = {k: v for k, v in benchmarks.items() if k in testing_benchmarks}\n",
    "\n",
    "pprint(selected_simulators)\n",
    "pprint(selected_configs)\n",
    "pprint(selected_benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e78b6eb-5b35-4fff-896a-b3f76c2159ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#5F34FA\", \"#49DFE3\", \"#8CFA5D\", \"#E3BC49\", \"#FF7357\", \"#EE34FA\"]\n",
    "sim_color = {\n",
    "    \"GPUTejas\": \"#7E61FA\", # colors[0],\n",
    "    \"AccelSim PTX\": colors[1],\n",
    "    \"AccelSim SASS\": colors[2],\n",
    "    \"Hardware\": \"#FF3C1E\", # colors[3],\n",
    "    \"Multi2Sim\": colors[4],\n",
    "    \"MacSim\": colors[5],\n",
    "}\n",
    "abbr = {\n",
    "    \"GPUTejas\": \"Tejas\",\n",
    "    \"AccelSim PTX\": \"Accel PTX\",\n",
    "    \"AccelSim SASS\": \"Accel SASS\",\n",
    "    \"Hardware\": \"HW\",\n",
    "    \"Multi2Sim\": \"M2S\",\n",
    "    \"MacSim\": \"MS\",\n",
    "}\n",
    "margin = 50\n",
    "default_layout_options = dict(\n",
    "    plot_bgcolor=\"white\",\n",
    "    margin=dict(\n",
    "        pad=10,\n",
    "        autoexpand=True,\n",
    "        l=margin, r=margin, t=1.5*margin, b=margin\n",
    "    ),\n",
    "    width=900,\n",
    "    height=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c8a5639-1634-4b28-bd4f-edb45f207fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_format(num, round_to=2):\n",
    "    magnitude = 0\n",
    "    while abs(num) >= 1000:\n",
    "        magnitude += 1\n",
    "        num = round(num / 1000.0, round_to)\n",
    "    return '{:.{}f}{}'.format(num, round_to, ['', 'K', 'M', 'G', 'T', 'P'][magnitude])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "139f789d-26b1-4980-acdc-f2287c72c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars(\n",
    "    data, config,\n",
    "    title=None, fontsize=14, font_family=\"Helvetica\", round_to=1,\n",
    "    ylabel=None, log=False,\n",
    "):\n",
    "    bars = []\n",
    "    \n",
    "    def sort_by_bench_size(key):\n",
    "        # print(key)\n",
    "        # print(bench)\n",
    "        # print(data.iloc[key.index][\"Value\"])\n",
    "        values = data.iloc[key.index][\"Value\"]\n",
    "        return values\n",
    "    \n",
    "    data = data.sort_values(\n",
    "        by=[\"Simulator\", \"Benchmark\"], key=sort_by_bench_size)\n",
    "    \n",
    "    data = data.set_index([\"Simulator\"])\n",
    "    \n",
    "    data[\"ValueStr\"] = data[\"Value\"].apply(lambda v: human_format(v, round_to=round_to))\n",
    "    simulators = data.index.get_level_values(\"Simulator\").unique().tolist()\n",
    "    benchmarks = data[\"Benchmark\"].unique().tolist()\n",
    "    \n",
    "    for i, sim in enumerate(simulators):\n",
    "        # add hardware GPU name\n",
    "        name = sim\n",
    "        if sim == \"Hardware\":\n",
    "            name += f\" ({config.name})\"\n",
    "        \n",
    "        sim_data = data.loc[[sim]]\n",
    "        \n",
    "        bars.append(go.Bar(\n",
    "            x = sim_data[\"Benchmark\"],\n",
    "            y = sim_data[\"Value\"],\n",
    "            text = sim_data[\"ValueStr\"],\n",
    "            textposition='auto',\n",
    "            textangle=0,\n",
    "            textfont = dict(\n",
    "                size=fontsize - 2,\n",
    "                color=\"black\",\n",
    "            ),\n",
    "            hovertemplate = (\n",
    "                \"<b>%{x}</b><br>\" +\n",
    "                \"%{y:.2f}<br>\"\n",
    "            ),\n",
    "            name=str(name),\n",
    "            marker=dict(\n",
    "                color=sim_color[sim],\n",
    "                line=dict(\n",
    "                    color='rgba(50, 171, 96, 1.0)',\n",
    "                    width=0\n",
    "                ),\n",
    "            ),\n",
    "        ))\n",
    "\n",
    "    layout = go.Layout(\n",
    "        font_family=font_family,\n",
    "        font_color=\"black\",\n",
    "        font_size=fontsize,\n",
    "        title=dict(\n",
    "            text=title,\n",
    "            x=0.5,\n",
    "            y=0.95,\n",
    "            xanchor=\"center\",\n",
    "            yanchor=\"top\",\n",
    "        ),\n",
    "        yaxis=go.layout.YAxis(\n",
    "            title=ylabel,\n",
    "            gridcolor=\"gray\",\n",
    "            zerolinecolor=\"gray\",\n",
    "        ),\n",
    "        xaxis=go.layout.XAxis(\n",
    "            tickfont=dict(\n",
    "                size=0.8 * fontsize,\n",
    "            ),\n",
    "            dividerwidth=0,\n",
    "            dividercolor=\"white\",\n",
    "        ),\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=\"white\",\n",
    "            font_size=fontsize,\n",
    "            font_family=font_family,\n",
    "        ),\n",
    "        barmode=\"group\",\n",
    "        bargroupgap=0.1,\n",
    "        bargap=0.25,\n",
    "        showlegend=True,\n",
    "        **default_layout_options,\n",
    "    )\n",
    "    if log:\n",
    "        layout.yaxis.type = \"log\"\n",
    "    fig = go.Figure(data=bars, layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a19da4-75dd-451f-b447-d5d703c1454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bars_exec_time(\n",
    "    data, config,\n",
    "    title=None, fontsize=14, font_family=\"Helvetica\", round_to=1,\n",
    "    ylabel=None, log=False,\n",
    "):\n",
    "    bars = []\n",
    "    def sort_by_bench_size(key):\n",
    "        # print(key)\n",
    "        # print(bench)\n",
    "        # print(data.iloc[key.index][\"Value\"])\n",
    "        values = data.iloc[key.index][\"Value\"]\n",
    "        return values\n",
    "    \n",
    "    data = data.sort_values(\n",
    "        by=[\"Simulator\", \"Benchmark\"], key=sort_by_bench_size)\n",
    "    \n",
    "    data = data.set_index([\"Simulator\", \"Kind\"])\n",
    "    # data = data.set_index([\"Simulator\", \"Kind\"])\n",
    "    # data = data.sort_values(by=\"Benchmark\")\n",
    "    # data = data.sort_index()\n",
    "    simulators = data.index.get_level_values(\"Simulator\").unique().tolist()\n",
    "    # data.index.get_level_values(\"Simulator\")\n",
    "    # simulators = [s for s in simulators if [\"Value\"]]\n",
    "    \n",
    "    for i, sim in enumerate(simulators):\n",
    "        # add hardware GPU name\n",
    "        name = sim\n",
    "        if sim == \"Hardware\":\n",
    "            name += f\" ({config.name})\"\n",
    "        \n",
    "        # add bars\n",
    "        trace_time = data.loc[data.index == (sim, \"Trace\")]\n",
    "        sim_time = data.loc[data.index == (sim, \"Sim\")]\n",
    "        total_time = trace_time[\"Value\"].values +  sim_time[\"Value\"].values\n",
    "        if total_time.sum() == 0:\n",
    "            # skip simulator\n",
    "            continue\n",
    "        \n",
    "        benchmarks = trace_time[\"Benchmark\"].values\n",
    "        x = [benchmarks, [abbr[sim]] * len(benchmarks)]\n",
    "        # flat_x = [item for sublist in x for item in sublist]\n",
    "        # y = [10] * len(flat_x)\n",
    "        y = trace_time[\"Value\"]\n",
    "        if sim != \"Hardware\":\n",
    "            y = y.round(round_to)\n",
    "        \n",
    "        bars.append(go.Bar(\n",
    "            x = x,\n",
    "            y = y,\n",
    "            text = y.apply(lambda v: f\"tracing<br>{v}\"),\n",
    "            textposition='auto',\n",
    "            textangle=0,\n",
    "            showlegend=False,\n",
    "            textfont = dict(\n",
    "                size=fontsize - 2,\n",
    "                color=\"black\",\n",
    "            ),\n",
    "            hovertemplate = (\n",
    "                \"<b>%{x}</b><br>\" +\n",
    "                \"%{y:.2f}<br>\"\n",
    "            ),\n",
    "            name=str(name),\n",
    "            marker=dict(\n",
    "                color=sim_color[sim],\n",
    "                line=dict(\n",
    "                    color=\"white\",\n",
    "                    width=2,\n",
    "                ),\n",
    "            ),\n",
    "        ))\n",
    "        \n",
    "        # continue\n",
    "        if sim != \"Hardware\":\n",
    "            total_time = total_time.round(round_to)\n",
    "        # print(total_time)\n",
    "        bars.append(go.Bar(\n",
    "            x = x,\n",
    "            y = total_time,\n",
    "            text = total_time,\n",
    "            textposition='auto',\n",
    "            textangle=0,\n",
    "            textfont = dict(\n",
    "                size=fontsize - 2,\n",
    "                color=\"black\",\n",
    "            ),\n",
    "            hovertemplate = (\n",
    "                \"<b>%{x}</b><br>\" +\n",
    "                \"%{y:.2f}<br>\"\n",
    "            ),\n",
    "            name=str(name),\n",
    "            marker=dict(\n",
    "                color=sim_color[sim],\n",
    "                line=dict(\n",
    "                    color=\"white\",\n",
    "                    width=2,\n",
    "                ),\n",
    "            ),\n",
    "        ))\n",
    "    \n",
    "    # add empty separator\n",
    "    x = [benchmarks, [\"\"] * len(benchmarks)]\n",
    "    y = [0] * len([item for sublist in x for item in sublist])\n",
    "    bars.append(go.Bar(\n",
    "        x = x,\n",
    "        y = y,\n",
    "        showlegend=False,\n",
    "    ))\n",
    "    \n",
    "    margin = 50\n",
    "    layout = go.Layout(\n",
    "        font_family=font_family,\n",
    "        font_color=\"black\",\n",
    "        font_size=fontsize,\n",
    "        title=dict(\n",
    "            text=title,\n",
    "            x=0.5,\n",
    "            y=0.95,\n",
    "            xanchor=\"center\",\n",
    "            yanchor=\"top\",\n",
    "        ),\n",
    "        yaxis=go.layout.YAxis(\n",
    "            title=ylabel,\n",
    "            gridcolor=\"gray\",\n",
    "            zerolinecolor=\"gray\",\n",
    "            # range=[min_axis_val * 0.9 ,max_axis_val*1.1]\n",
    "        ),\n",
    "        xaxis=go.layout.XAxis(\n",
    "            # title=\"Benchmark\",\n",
    "            tickfont=dict(\n",
    "                size=0.8 * fontsize,\n",
    "            ),\n",
    "            dividerwidth=0,\n",
    "            dividercolor=\"white\",\n",
    "        ),\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=\"white\",\n",
    "            font_size=fontsize,\n",
    "            font_family=font_family,\n",
    "        ),\n",
    "        barmode=\"stack\",\n",
    "        # bargroupgap=0.1,\n",
    "        bargap=0.1,\n",
    "        showlegend=True,\n",
    "        **default_layout_options,\n",
    "    )\n",
    "    if log:\n",
    "        layout.yaxis.type = \"log\"\n",
    "    return go.Figure(data=bars, layout=layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "112fe699-4448-4391-a842-f7b923f2e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_slowdown(df):\n",
    "    slowdown_df = df\n",
    "    # print(slowdown_df.shape)\n",
    "    slowdown_df = slowdown_df.drop(columns=[\"Kind\"])\n",
    "    slowdown_df = slowdown_df.groupby([\n",
    "        \"Simulator\", \"Benchmark\", \"Config\"]).sum().reset_index()\n",
    "    slowdown_df = slowdown_df[slowdown_df[\"Value\"] > 0]\n",
    "\n",
    "    hw = slowdown_df[slowdown_df[\"Simulator\"] == \"Hardware\"]\n",
    "    hw = hw[[\"Benchmark\", \"Config\", \"Value\"]]\n",
    "    hw = hw.rename(columns={\"Value\": \"HardwareValue\"})\n",
    "\n",
    "    final_slowdown_df = []\n",
    "\n",
    "    # slowdown_df = slowdown_df[slowdown_df[\"Value\"] > 0]\n",
    "    # print(slowdown_df.shape)\n",
    "    # [[\"Simulator\", \"Value\"]]\n",
    "    # slowdown_df_group = slowdown_df.groupby(\"Simulator\")\n",
    "    for sim, sim_df in slowdown_df.groupby(\"Simulator\"):\n",
    "        if sim == \"Hardware\":\n",
    "            continue\n",
    "        # print(sim)\n",
    "        # sim_df = sim_df[sim_df[\"Value\"] > 0]\n",
    "        # get all the benchmarks\n",
    "        # Value_x\tValue_y\n",
    "\n",
    "        # hw = hw[[\"Benchmark\", \"Config\", \"Value\"]]\n",
    "        # hw = hw.groupby([\"Benchmark\", \"Config\"]).sum()\n",
    "        # hw = hw[\"Benchmark\", \"Config\", \"Value\"]\n",
    "        # hw = hw.reset_index()\n",
    "        # print(hw.shape)\n",
    "\n",
    "        # print(sim_df.shape)\n",
    "        # sim_df = sim_df[[\"Benchmark\", \"Config\", \"Value\"]]\n",
    "        sim_df = sim_df.rename(columns={\"Value\": \"SimValue\"})\n",
    "        sim_df = sim_df.merge(hw, how=\"inner\", on=[\"Benchmark\", \"Config\"])\n",
    "        sim_df[\"Value\"] = sim_df[\"SimValue\"] / sim_df[\"HardwareValue\"]\n",
    "        # [[\"Config\", \"Slowdown\"]]\n",
    "        # [[\"Config\", \"Slowdown\"]]\n",
    "        sim_df = sim_df[[\"Simulator\", \"Config\", \"Value\"]]\n",
    "        sim_df = sim_df.groupby([\"Simulator\", \"Config\"]).mean()\n",
    "        sim_df = sim_df.reset_index()\n",
    "        # [\"Slowdown\"]\n",
    "        # print(sim_df.shape)\n",
    "        final_slowdown_df.append(sim_df)\n",
    "        # join based on the benchmarks\n",
    "        # break\n",
    "    # hw\n",
    "    final_slowdown_df = pd.concat(final_slowdown_df)\n",
    "    final_slowdown_df = final_slowdown_df.rename(columns={\"Config\": \"Benchmark\"})\n",
    "    return final_slowdown_df, plot_bars(\n",
    "        data=final_slowdown_df,\n",
    "        config=config,\n",
    "        ylabel=\"Slowdown factor\",\n",
    "        title=f\"Mean simulation slowdown\",\n",
    "        log=True,\n",
    "    )\n",
    "\n",
    "# final_slowdown_df, fig = plot_mean_slowdown(all_benches_metric_df)\n",
    "# fig.show()\n",
    "# final_slowdown_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eec3a28b-74d8-4db4-8ea2-39be89bd67b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time\n",
      "Cycles\n",
      "Total L2 Read Hits\n",
      "Total DRAM Reads\n",
      "Total DRAM Writes\n",
      "Total IPC\n",
      "Total Instruction Count\n",
      "Total L2 Writes\n"
     ]
    }
   ],
   "source": [
    "# => per config, benchmark and input, plot bars for each simulator\n",
    "\n",
    "metrics = {\n",
    "    gpusims.plot.metrics.ExecutionTime: plot_bars_exec_time,\n",
    "    gpusims.plot.metrics.Cycles: plot_bars,\n",
    "    gpusims.plot.metrics.L2ReadHit: plot_bars,\n",
    "    gpusims.plot.metrics.DRAMReads: plot_bars,\n",
    "    gpusims.plot.metrics.DRAMWrites: plot_bars,\n",
    "    gpusims.plot.metrics.IPC: plot_bars,\n",
    "    gpusims.plot.metrics.InstructionCount: plot_bars,\n",
    "    gpusims.plot.metrics.L2Writes: plot_bars,\n",
    "}\n",
    "if False:\n",
    "    metrics = {\n",
    "        # gpusims.plot.metrics.L2Writes: plot_bars,\n",
    "        gpusims.plot.metrics.ExecutionTime: plot_bars_exec_time,\n",
    "        # gpusims.plot.metrics.Cycles: plot_bars,\n",
    "        # gpusims.plot.metrics.IPC: plot_bars,\n",
    "        # gpusims.plot.metrics.InstructionCount: plot_bars,\n",
    "    }\n",
    "\n",
    "for metric_cls, metrics_plot_func in metrics.items():\n",
    "    print(metric_cls.name)\n",
    "    ylabel = metric_cls.name\n",
    "    if metric_cls.unit is not None:\n",
    "        ylabel += f\" [{metric_cls.unit}]\"\n",
    "\n",
    "    all_benches_metric_df = []\n",
    "    for config_name, config in selected_configs.items():\n",
    "        for bench_name, bench in selected_benchmarks.items():\n",
    "            # print(config_name, bench_name)\n",
    "            all_metric_df = []\n",
    "            for inp in bench.inputs:\n",
    "                plot_data = PlotData(benchmark=bench, config=config, inp=inp)\n",
    "                for (sim_name, sim) in selected_simulators.items():\n",
    "                    if not bench.enabled(sim_name):\n",
    "                        continue\n",
    "                    if not inp.enabled(sim_name):\n",
    "                        continue\n",
    "                    # print(sim_name, config_name, bench_name)\n",
    "                    bench_config = sim(\n",
    "                        run_dir=run_dir / sim_name.lower(),\n",
    "                        benchmark=bench,\n",
    "                        config=config,\n",
    "                    )\n",
    "                    if not bench_config.input_path(inp).is_dir():\n",
    "                        print(f\"WARN: {bench_config.input_path(inp)} does not exist\")\n",
    "                        continue\n",
    "\n",
    "                    plot_data[sim_name] = bench_config.load_dataframe(inp)\n",
    "\n",
    "                metric = metric_cls(plot_data)\n",
    "                metric_df = metric.compute()\n",
    "                metric_df[\"Benchmark\"] = f\"{bench.name}<br>{inp.args}\"\n",
    "                metric_df[\"Config\"] = config.name\n",
    "\n",
    "                all_metric_df.append(metric_df)\n",
    "                all_benches_metric_df.append(metric_df)\n",
    "                # continue\n",
    "\n",
    "                # print(metric_df)\n",
    "                fig = metrics_plot_func(\n",
    "                    data=metric_df,\n",
    "                    config=config,\n",
    "                    ylabel=ylabel,\n",
    "                    title=f\"{metric_cls.name} for {bench.name} {inp.args} ({config.name})\",\n",
    "                    log=metric_cls.log,\n",
    "                )\n",
    "                filename = [\"bar\", metric.name, bench.name, config.key, inp.sanitized_name()]\n",
    "                filename = Path(\"./figs\") / gpusims.utils.slugify(\"_\".join(filename))\n",
    "                filename = filename.with_suffix(\".pdf\")\n",
    "                filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "                fig.write_image(filename, format='pdf')\n",
    "                # print(\"wrote\", filename)\n",
    "\n",
    "            all_metric_df = pd.concat(all_metric_df)\n",
    "            fig = metrics_plot_func(\n",
    "                data=all_metric_df,\n",
    "                config=config,\n",
    "                ylabel=ylabel,\n",
    "                title=f\"{metric_cls.name} for {bench.name} ({config.name})\",\n",
    "                log=metric_cls.log,\n",
    "            )\n",
    "            filename = [\"all_inputs_bar\", metric_cls.name, bench.name, config.key]\n",
    "            filename = Path(\"./figs\") / gpusims.utils.slugify(\"_\".join(filename))\n",
    "            filename = filename.with_suffix(\".pdf\")\n",
    "            filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "            fig.write_image(filename, format='pdf')\n",
    "            # print(\"wrote\", filename)\n",
    "            # break\n",
    "\n",
    "    if metric_cls is gpusims.plot.metrics.ExecutionTime:\n",
    "        all_benches_metric_df = pd.concat(all_benches_metric_df)\n",
    "        _, fig = plot_mean_slowdown(all_benches_metric_df)\n",
    "        filename = Path(\"./figs\") / \"mean_slowdown.pdf\"\n",
    "        filename.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.write_image(filename, format='pdf')\n",
    "\n",
    "# all_metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5668cdd-e46f-4ab3-87e6-e4e54e2d9bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9cf393-b104-4ffb-a26f-70f9eef07f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a897def-4415-487d-a2f7-7ff2f3d8b12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39488e3f-cce4-4174-8b25-e42eacc1b43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f54e60-59af-41b6-b859-50a83da99038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbd7674-1491-4397-9968-a972e6bcf541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1a465-7019-4505-be28-e767fe83db6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ffef77-fe2c-44ab-bb86-83f4bbf89580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a18aa-28b8-4bd7-83bd-de33aa9aedd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82aad90-5656-4227-8dd8-d6f8498c2fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f217469b-8750-4c0c-83f5-efd707122025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ef378-1eff-475c-a537-9b9739d8380f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc44028-1b0e-43b4-bd51-e8daf6abfa74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4461ef77-b517-43b5-ba9a-51a4f594f477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74959fce-8bf3-43d4-9a2b-f3c4b737c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelsim-ptx vectorAdd 1000000\n",
      "(1, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l2_cache_read_hit</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "stat                  \n",
       "l2_cache_read_hit  0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# debug dataframe\n",
    "# sim = gpusims.MULTI2SIM\n",
    "# sim = gpusims.MACSIM\n",
    "# sim = gpusims.TEJAS\n",
    "# sim = gpusims.ACCELSIM_SASS\n",
    "sim = gpusims.ACCELSIM_PTX\n",
    "# sim = gpusims.NATIVE\n",
    "# benchmark = benchmarks[\"babelstream\"]\n",
    "# benchmark = benchmarks[\"cuda4-matrixmul\"]\n",
    "benchmark = benchmarks[\"cuda6-transpose\"]\n",
    "benchmark = benchmarks[\"vectoradd\"]\n",
    "# config=configs[\"sm86_rtx3070\"]\n",
    "config=configs[\"sm6_gtx1080\"]\n",
    "# config=configs[\"sm86_a4000\"]\n",
    "bench_config = gpusims.SIMULATORS[sim](\n",
    "    run_dir=run_dir / sim.lower(),\n",
    "    benchmark=benchmark,\n",
    "    config=config,\n",
    ")\n",
    "assert bench_config.benchmark.enabled(sim)\n",
    "bench_input = bench_config.benchmark.inputs[-1]\n",
    "print(sim, benchmark.name, bench_input.args)\n",
    "df = bench_config.load_dataframe(bench_input)\n",
    "df = df.round(0)\n",
    "# pprint(df.columns.tolist())\n",
    "# print(df.index)\n",
    "print(df.shape)\n",
    "# df.T[~df.T.index.str.contains(r\"^Config.|SM \\d+\", re.IGNORECASE)] # multi2sim\n",
    "# df.T[~df.T.index.str.contains(r\"_CORE_\\d+$\", re.IGNORECASE)] # macsim\n",
    "# df.T[df.T.index.str.contains(r\"tex_op_read.sum\", re.IGNORECASE)] # filtering\n",
    "df.T[df.T.index.str.contains(r\"l2_cache_read_hit\", re.IGNORECASE)] # filtering\n",
    "# df.T\n",
    "# df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbafab6-9daf-4f98-b8eb-fbc6376aa98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe50e64-54f3-4462-ad9b-3713d4917120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66301f33-c0a0-4fb5-bc72-d132d0faf147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c373d-9b74-4f82-98ef-3719835ea83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f6bd0d-cacf-4310-8a22-799b4b045d2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484ae451-31ea-4cc8-85c5-e109b7ba6274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65a462-ab23-4d4b-871b-86225cb26b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6ed2af-36c5-47e5-ba1b-4bee5caeba19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b3cab-74b4-4215-b3f7-dc6846cfeccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90db303-50a1-44fe-bc98-dd1086539f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4d519-0768-4fc3-b62e-1fd07bd73a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03932b-4be7-44c6-83ff-c1b989e10688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
