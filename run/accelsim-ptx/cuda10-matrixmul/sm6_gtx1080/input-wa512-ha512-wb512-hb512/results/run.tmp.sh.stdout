GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded


        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim PTX: overriding embedded ptx with ptx file (PTX_SIM_USE_PTX_FILE is set)
GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:2962.0:1607.0:2750.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:2962000000.000000:1607000000.000000:2750000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000033760972316:0.00000000062227753578:0.00000000036363636364
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
46c62f3a5d4483ced560c28c2bf4c16b  /benchrun/accelsim-ptx/cuda10-matrixmul/sm6_gtx1080/input-wa512-ha512-wb512-hb512/matrixMul
Extracting PTX file and ptxas options    1: matrixMul.1.sm_30.ptx -arch=sm_30
GPGPU-Sim uArch: performance model initialization complete.
self exe links to: /benchrun/accelsim-ptx/cuda10-matrixmul/sm6_gtx1080/input-wa512-ha512-wb512-hb512/matrixMul
self exe links to: /benchrun/accelsim-ptx/cuda10-matrixmul/sm6_gtx1080/input-wa512-ha512-wb512-hb512/matrixMul
10.1
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=default
self exe links to: /benchrun/accelsim-ptx/cuda10-matrixmul/sm6_gtx1080/input-wa512-ha512-wb512-hb512/matrixMul
Running md5sum using "md5sum /benchrun/accelsim-ptx/cuda10-matrixmul/sm6_gtx1080/input-wa512-ha512-wb512-hb512/matrixMul "
self exe links to: /benchrun/accelsim-ptx/cuda10-matrixmul/sm6_gtx1080/input-wa512-ha512-wb512-hb512/matrixMul
Extracting specific PTX file named matrixMul.1.sm_30.ptx 
GPGPU-Sim PTX: __cudaRegisterFunction _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii : hostFun 0x0x55a3e920373a, fat_cubin_handle = 1
GPGPU-Sim PTX: Parsing matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: allocating shared region for "_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As" from 0x0 to 0x400 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs" from 0x400 to 0x800 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii'...   done.
GPGPU-Sim PTX: allocating shared region for "_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As" from 0x0 to 0x1000 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs" from 0x1000 to 0x2000 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...   done.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
GPGPU-Sim PTX: Loading PTXInfo from matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: Kernel '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii' : regs=29, lmem=0, smem=8192, cmem=352
GPGPU-Sim PTX: Kernel '_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii' : regs=29, lmem=0, smem=2048, cmem=352
GPGPU-Sim PTX: __cudaRegisterFunction _Z13MatrixMulCUDAILi16EEvPfS0_S0_ii : hostFun 0x0x55a3e92036fd, fat_cubin_handle = 1
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "Volta" with compute capability 7.0

MatrixA(512,512), MatrixB(512,512)
GPGPU-Sim PTX: cudaStreamCreate
Computing result using CUDA Kernel...
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7fff8131e958..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7fff8131e950..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7fff8131e948..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7fff8131e944..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7fff8131e940..

GPGPU-Sim PTX: cudaLaunch for 0x0x55a3e920373a (mode=performance simulation) on stream 1
GPGPU-Sim PTX: finding reconvergence points for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: Finding dominators for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: Finding postdominators for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: reconvergence points for _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x3c8 (matrixMul.1.sm_30.ptx:182) @%p1 bra BB1_3;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x7e0 (matrixMul.1.sm_30.ptx:318) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX:  2 (potential) branch divergence @  PC=0x7d8 (matrixMul.1.sm_30.ptx:315) @%p2 bra BB1_2;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x7e0 (matrixMul.1.sm_30.ptx:318) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX: ... end of reconvergence points for _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'.
GPGPU-Sim PTX: pushing kernel '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii' to stream 1, gridDim= (16,16,1) blockDim = (32,32,1) 
event update
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim API:    stream 1 has 2 operations
GPGPU-Sim API:       0 :  stream operation kernel
GPGPU-Sim API:       1 :  stream operation event
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads shmem regs
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 16 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 17 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 18 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 19 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
Destroy streams for kernel 1: size 0
event update
kernel_name = _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii 
kernel_launch_uid = 1 
gpu_sim_cycle = 527931
gpu_sim_insn = 480772096
gpu_ipc =     910.6722
gpu_tot_sim_cycle = 527931
gpu_tot_sim_insn = 480772096
gpu_tot_ipc =     910.6722
gpu_tot_issued_cta = 256
gpu_occupancy = 96.1508% 
gpu_tot_occupancy = 96.1508% 
max_total_param_size = 0
gpu_stall_dramfull = 366326
gpu_stall_icnt2sh    = 201232
partiton_level_parallism =       0.5125
partiton_level_parallism_total  =       0.5125
partiton_level_parallism_util =       1.2632
partiton_level_parallism_util_total  =       1.2632
L2_BW  =      48.5788 GB/Sec
L2_BW_total  =      48.5788 GB/Sec
gpu_total_sim_rate=445159

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 7643136
	L1I_total_cache_misses = 7771
	L1I_total_cache_miss_rate = 0.0010
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 85659
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 40960
	L1C_total_cache_misses = 1280
	L1C_total_cache_miss_rate = 0.0312
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 3592
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 39680
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 1280
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 3592
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 1260
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 7635365
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 7771
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 85659
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 7551
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 40960
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 7643136

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[CONST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 3592
	Total_core_cache_fail_stats_breakdown[INST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 85659
ctas_completed 256, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
distro:
13351, 13341, 13290, 13283, 13289, 13226, 13182, 13175, 13179, 13156, 13177, 13119, 13192, 13230, 13210, 13195, 13143, 13177, 13146, 13154, 13168, 13159, 13213, 13197, 13258, 13279, 13288, 13286, 13289, 13317, 13397, 13442, 11441, 11431, 11411, 11391, 11355, 11367, 11321, 11306, 11281, 11256, 11272, 11271, 11334, 11334, 11334, 11326, 11320, 11310, 11284, 11277, 11265, 11297, 11318, 11308, 11383, 11371, 11392, 11385, 11404, 11420, 11483, 11484, 
gpgpu_n_tot_thrd_icount = 481296384
gpgpu_n_tot_w_icount = 15040512
gpgpu_n_stall_shd_mem = 199889
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 262144
gpgpu_n_mem_write_global = 8192
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 20
gpgpu_n_load_insn  = 8388608
gpgpu_n_store_insn = 262144
gpgpu_n_shmem_insn = 276824064
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 1310720
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 3592
gpgpu_stall_shd_mem[c_mem][resource_stall] = 3592
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 0
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:5027144	W0_Idle:171661	W0_Scoreboard:890669	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:15040512
single_issue_nums: WS0:7064350	WS1:7063262	
dual_issue_nums: WS0:227953	WS1:228497	
traffic_breakdown_coretomem[CONST_ACC_R] = 160 {8:20,}
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 2097152 {8:262144,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 1114112 {136:8192,}
traffic_breakdown_coretomem[INST_ACC_R] = 1760 {8:220,}
traffic_breakdown_memtocore[CONST_ACC_R] = 1440 {72:20,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 35651584 {136:262144,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 65536 {8:8192,}
traffic_breakdown_memtocore[INST_ACC_R] = 29920 {136:220,}
maxmflatency = 2255 
max_icnt2mem_latency = 6040 
maxmrqlatency = 758 
max_icnt2sh_latency = 42 
averagemflatency = 200 
avg_icnt2mem_latency = 31 
avg_mrq_latency = 149 
avg_icnt2sh_latency = 7 
mrq_lat_table:1670 	257 	483 	1290 	3077 	3069 	2832 	4837 	5491 	377 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	223320 	39979 	4917 	1611 	529 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	217689 	13295 	8905 	7344 	8451 	9446 	2545 	1039 	1842 	0 	20 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	209244 	46588 	14081 	443 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	966 	59 	8 	11 	4 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[5]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[6]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[7]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     79032     67221     78243     66282     78708     83077     76560     83136     91835     98736     96844     98829     78459     85403     76611     86788 
dram[1]:     65409     77213     65547     77239    100543    104390    100565    104448     96535    108475     96549    108501     97243    106647     97234    106665 
dram[2]:     80768     84262     80752     84260     97632     98901     97718     98996     99133     99082     99334     99271    100415    103476    100478    103535 
dram[3]:     87912     90245     87879     90212     96581     95127     96676     95237     92641     90670     92605     90725    106647    109745    106729    109801 
dram[4]:     92901     96757     92904     96758     95978     95059     96068     95086     90448     94009     90419     93981    112942    116118    113004    116176 
dram[5]:     99029    101284     98993    101215     98354     99929     98448     99921     97257     99601     97269     99584    119271    122276    119330    122376 
dram[6]:    104343    106693    104311    106669    107142    106252    107146    106212    101651    105310    101653    105273    125368    128485    125422    128544 
dram[7]:    111404    113047    111409    113020    110744    113341    110705    113262    107531    110219    107529    110194    131552    134571    131624    134629 
average row accesses per activate:
dram[0]: 19.888889 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 22.125000 25.142857 25.142857 25.142857 23.875000 24.000000 24.000000 24.000000 
dram[1]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 
dram[2]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 
dram[3]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[4]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[5]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[6]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[7]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
average row locality = 23383/971 = 24.081360
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       460       448       448       448       448       448       448       448       452       448       448       448       508       512       512       512 
dram[1]:       448       448       448       448       448       448       448       448       448       448       448       448       512       512       512       512 
dram[2]:       448       448       448       448       448       448       448       448       448       448       448       448       512       512       512       512 
dram[3]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[4]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[5]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[6]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[7]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
total dram reads = 60764
bank skew: 512/448 = 1.14
chip skew: 7696/7424 = 1.04
number of total write accesses:
dram[0]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[1]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[2]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[3]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[4]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[5]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[6]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[7]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
total dram writes = 32768
bank skew: 256/256 = 1.00
chip skew: 4096/4096 = 1.00
average mf latency per bank:
dram[0]:        738       787      1181      1224      1089       785      1173       934       830       578       839       622       458       491       460       532
dram[1]:        739       622      1019       745       632       634       693       665       668       588       688       614       497       500       563       550
dram[2]:        589       546       682       608       555       570       592       590       539       531       575       561       482       468       522       502
dram[3]:        496       508       529       562       541       555       561       593       480       485       514       517       470       502       505       536
dram[4]:        549       506       605       550       572       566       608       609       487       472       533       507       475       474       521       517
dram[5]:        529       535       576       582       526       548       559       588       495       477       510       515       471       502       519       551
dram[6]:        538       572       581       624       504       574       535       615       494       487       512       524       461       469       487       502
dram[7]:        571       558       616       608       539       517       583       544       478       498       510       524       507       508       572       569
maximum mf latency per bank:
dram[0]:       1702      1975      2255      2186      2242      2179      2242      2181      2243      1316      2233       841       960       935       906       885
dram[1]:       1625      1259      1908      1375      1885      1398      1886      1371      1895      1363      1677       760       825       941       761       797
dram[2]:        828       828       972       864      1392      1403       963       900      1312      1346      1102      1042       997      1008       976      1003
dram[3]:        769       738       751       774      1391      1398       691       705      1306      1306       593       621       709       696       572       571
dram[4]:        735       850       825       793      1420      1389       766       704       609      1306       681       652       781       691       700       745
dram[5]:        704       838       810       756      1401      1397       760      1092      1336      1318       756       795       610       690       668       617
dram[6]:        644       688       624       634      1401      1397       756       568      1328      1308       622       617       775       830       793       765
dram[7]:        844       808       807       849      1757      1879       605       736       694       659       628       617       829       870       846       947
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=903428 n_nop=891676 n_act=120 n_pre=104 n_ref_event=0 n_req=2883 n_rd=3340 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02553
n_activity=35911 dram_eff=0.6423
bk0: 460a 899005i bk1: 448a 899347i bk2: 448a 898747i bk3: 448a 899426i bk4: 448a 898258i bk5: 448a 898764i bk6: 448a 898026i bk7: 448a 898756i bk8: 452a 898787i bk9: 448a 898987i bk10: 448a 899001i bk11: 448a 898743i bk12: 508a 898412i bk13: 512a 898658i bk14: 512a 898554i bk15: 512a 898493i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.958724
Row_Buffer_Locality_read = 0.970414
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.431159
Bank_Level_Parallism_Col = 2.443083
Bank_Level_Parallism_Ready = 1.723773
write_to_read_ratio_blp_rw_average = 0.399447
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.025529 
total_CMD = 903428 
util_bw = 23064 
Wasted_Col = 8568 
Wasted_Row = 661 
Idle = 871135 

BW Util Bottlenecks: 
RCDc_limit = 566 
RCDWRc_limit = 285 
WTRc_limit = 9399 
RTWc_limit = 9957 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9399 
RTWc_limit_alone = 9957 

Commands details: 
total_CMD = 903428 
n_nop = 891676 
Read = 3340 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 120 
n_pre = 104 
n_ref = 0 
n_req = 2883 
total_req = 11532 

Dual Bus Interface Util: 
issued_total_row = 224 
issued_total_col = 11532 
Row_Bus_Util =  0.000248 
CoL_Bus_Util = 0.012765 
Either_Row_CoL_Bus_Util = 0.013008 
Issued_on_Two_Bus_Simul_Util = 0.000004 
issued_two_Eff = 0.000340 
queue_avg = 0.972441 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.972441
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=903428 n_nop=891695 n_act=116 n_pre=100 n_ref_event=0 n_req=2880 n_rd=3328 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.0255
n_activity=35508 dram_eff=0.6489
bk0: 448a 899597i bk1: 448a 899271i bk2: 448a 899241i bk3: 448a 899359i bk4: 448a 899763i bk5: 448a 899940i bk6: 448a 899572i bk7: 448a 899815i bk8: 448a 899820i bk9: 448a 899446i bk10: 448a 899549i bk11: 448a 899663i bk12: 512a 899346i bk13: 512a 899510i bk14: 512a 899281i bk15: 512a 899175i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959722
Row_Buffer_Locality_read = 0.971983
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.911234
Bank_Level_Parallism_Col = 1.903131
Bank_Level_Parallism_Ready = 1.453828
write_to_read_ratio_blp_rw_average = 0.404845
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.025503 
total_CMD = 903428 
util_bw = 23040 
Wasted_Col = 10706 
Wasted_Row = 513 
Idle = 869169 

BW Util Bottlenecks: 
RCDc_limit = 410 
RCDWRc_limit = 270 
WTRc_limit = 9308 
RTWc_limit = 9859 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9308 
RTWc_limit_alone = 9859 

Commands details: 
total_CMD = 903428 
n_nop = 891695 
Read = 3328 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 116 
n_pre = 100 
n_ref = 0 
n_req = 2880 
total_req = 11520 

Dual Bus Interface Util: 
issued_total_row = 216 
issued_total_col = 11520 
Row_Bus_Util =  0.000239 
CoL_Bus_Util = 0.012751 
Either_Row_CoL_Bus_Util = 0.012987 
Issued_on_Two_Bus_Simul_Util = 0.000003 
issued_two_Eff = 0.000256 
queue_avg = 0.812418 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.812418
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=903428 n_nop=891694 n_act=116 n_pre=100 n_ref_event=0 n_req=2880 n_rd=3328 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.0255
n_activity=34122 dram_eff=0.6752
bk0: 448a 899452i bk1: 448a 899701i bk2: 448a 899397i bk3: 448a 899568i bk4: 448a 899659i bk5: 448a 899330i bk6: 448a 899518i bk7: 448a 898913i bk8: 448a 899137i bk9: 448a 898787i bk10: 448a 898902i bk11: 448a 898952i bk12: 512a 899185i bk13: 512a 898975i bk14: 512a 898810i bk15: 512a 898914i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959722
Row_Buffer_Locality_read = 0.971983
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.109314
Bank_Level_Parallism_Col = 2.100609
Bank_Level_Parallism_Ready = 1.543869
write_to_read_ratio_blp_rw_average = 0.411049
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.025503 
total_CMD = 903428 
util_bw = 23040 
Wasted_Col = 9919 
Wasted_Row = 456 
Idle = 870013 

BW Util Bottlenecks: 
RCDc_limit = 366 
RCDWRc_limit = 252 
WTRc_limit = 9275 
RTWc_limit = 9873 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9275 
RTWc_limit_alone = 9873 

Commands details: 
total_CMD = 903428 
n_nop = 891694 
Read = 3328 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 116 
n_pre = 100 
n_ref = 0 
n_req = 2880 
total_req = 11520 

Dual Bus Interface Util: 
issued_total_row = 216 
issued_total_col = 11520 
Row_Bus_Util =  0.000239 
CoL_Bus_Util = 0.012751 
Either_Row_CoL_Bus_Util = 0.012988 
Issued_on_Two_Bus_Simul_Util = 0.000002 
issued_two_Eff = 0.000170 
queue_avg = 0.896115 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.896115
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=903428 n_nop=891404 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02611
n_activity=37152 dram_eff=0.6348
bk0: 456a 899814i bk1: 456a 899790i bk2: 448a 899729i bk3: 448a 899755i bk4: 448a 899819i bk5: 448a 900028i bk6: 448a 899853i bk7: 448a 899855i bk8: 512a 899951i bk9: 512a 900022i bk10: 512a 899897i bk11: 512a 899835i bk12: 512a 900045i bk13: 512a 899990i bk14: 512a 899881i bk15: 512a 899839i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.640039
Bank_Level_Parallism_Col = 1.630233
Bank_Level_Parallism_Ready = 1.318012
write_to_read_ratio_blp_rw_average = 0.399998
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026105 
total_CMD = 903428 
util_bw = 23584 
Wasted_Col = 12148 
Wasted_Row = 613 
Idle = 867083 

BW Util Bottlenecks: 
RCDc_limit = 426 
RCDWRc_limit = 285 
WTRc_limit = 9264 
RTWc_limit = 9808 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9264 
RTWc_limit_alone = 9808 

Commands details: 
total_CMD = 903428 
n_nop = 891404 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000257 
CoL_Bus_Util = 0.013053 
Either_Row_CoL_Bus_Util = 0.013309 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.749341 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.749341
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=903428 n_nop=891404 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02611
n_activity=36493 dram_eff=0.6463
bk0: 456a 899549i bk1: 456a 899544i bk2: 448a 899360i bk3: 448a 899426i bk4: 448a 900023i bk5: 448a 899843i bk6: 448a 899789i bk7: 448a 899832i bk8: 512a 899957i bk9: 512a 899742i bk10: 512a 899617i bk11: 512a 899683i bk12: 512a 899673i bk13: 512a 899830i bk14: 512a 899540i bk15: 512a 899580i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.759868
Bank_Level_Parallism_Col = 1.752013
Bank_Level_Parallism_Ready = 1.390504
write_to_read_ratio_blp_rw_average = 0.396968
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026105 
total_CMD = 903428 
util_bw = 23584 
Wasted_Col = 11465 
Wasted_Row = 613 
Idle = 867766 

BW Util Bottlenecks: 
RCDc_limit = 429 
RCDWRc_limit = 294 
WTRc_limit = 9278 
RTWc_limit = 9820 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9278 
RTWc_limit_alone = 9820 

Commands details: 
total_CMD = 903428 
n_nop = 891404 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000257 
CoL_Bus_Util = 0.013053 
Either_Row_CoL_Bus_Util = 0.013309 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.798934 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.798934
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=903428 n_nop=891406 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02611
n_activity=36634 dram_eff=0.6438
bk0: 456a 899857i bk1: 456a 899627i bk2: 448a 899663i bk3: 448a 899636i bk4: 448a 900178i bk5: 448a 900161i bk6: 448a 900093i bk7: 448a 900103i bk8: 512a 899268i bk9: 512a 899436i bk10: 512a 899172i bk11: 512a 899042i bk12: 512a 899986i bk13: 512a 899827i bk14: 512a 899752i bk15: 512a 899837i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.732368
Bank_Level_Parallism_Col = 1.725452
Bank_Level_Parallism_Ready = 1.369086
write_to_read_ratio_blp_rw_average = 0.397629
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026105 
total_CMD = 903428 
util_bw = 23584 
Wasted_Col = 11621 
Wasted_Row = 638 
Idle = 867585 

BW Util Bottlenecks: 
RCDc_limit = 461 
RCDWRc_limit = 272 
WTRc_limit = 9251 
RTWc_limit = 9818 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9251 
RTWc_limit_alone = 9818 

Commands details: 
total_CMD = 903428 
n_nop = 891406 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000257 
CoL_Bus_Util = 0.013053 
Either_Row_CoL_Bus_Util = 0.013307 
Issued_on_Two_Bus_Simul_Util = 0.000002 
issued_two_Eff = 0.000166 
queue_avg = 0.789421 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.789421
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=903428 n_nop=891404 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02611
n_activity=37137 dram_eff=0.6351
bk0: 456a 900047i bk1: 456a 900020i bk2: 448a 900006i bk3: 448a 899992i bk4: 448a 900179i bk5: 448a 900161i bk6: 448a 900135i bk7: 448a 900097i bk8: 512a 899939i bk9: 512a 899907i bk10: 512a 899765i bk11: 512a 899794i bk12: 512a 899444i bk13: 512a 899480i bk14: 512a 899280i bk15: 512a 899260i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.662497
Bank_Level_Parallism_Col = 1.655173
Bank_Level_Parallism_Ready = 1.330649
write_to_read_ratio_blp_rw_average = 0.398135
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026105 
total_CMD = 903428 
util_bw = 23584 
Wasted_Col = 11991 
Wasted_Row = 653 
Idle = 867200 

BW Util Bottlenecks: 
RCDc_limit = 486 
RCDWRc_limit = 283 
WTRc_limit = 9251 
RTWc_limit = 9828 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9251 
RTWc_limit_alone = 9828 

Commands details: 
total_CMD = 903428 
n_nop = 891404 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000257 
CoL_Bus_Util = 0.013053 
Either_Row_CoL_Bus_Util = 0.013309 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.754490 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.75449
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents

Cache L2_bank_015:
MSHR contents
MSHR: tag=0xc02fff80, atomic=0 1 entries : 0x7f57f82133c0 :  mf: uid=8051875, sid19:w31, part=7, addr=0xc02fff80, load , size=128, unknown  status = IN_PARTITION_DRAM (527930), 

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=903428 n_nop=891408 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4094 n_write=4096 n_wr_bk=0 bw_util=0.0261
n_activity=36092 dram_eff=0.6533
bk0: 456a 899361i bk1: 456a 899588i bk2: 448a 899480i bk3: 448a 899350i bk4: 448a 900182i bk5: 448a 900166i bk6: 448a 900153i bk7: 448a 900151i bk8: 512a 899923i bk9: 512a 899943i bk10: 512a 899829i bk11: 512a 899765i bk12: 512a 899002i bk13: 512a 898611i bk14: 512a 898720i bk15: 510a 898449i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.840660
Bank_Level_Parallism_Col = 1.832823
Bank_Level_Parallism_Ready = 1.423664
write_to_read_ratio_blp_rw_average = 0.401173
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026101 
total_CMD = 903428 
util_bw = 23580 
Wasted_Col = 11171 
Wasted_Row = 587 
Idle = 868090 

BW Util Bottlenecks: 
RCDc_limit = 432 
RCDWRc_limit = 282 
WTRc_limit = 9271 
RTWc_limit = 9807 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9271 
RTWc_limit_alone = 9807 

Commands details: 
total_CMD = 903428 
n_nop = 891408 
Read = 3600 
Write = 4096 
L2_Alloc = 4094 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11790 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11790 
Row_Bus_Util =  0.000257 
CoL_Bus_Util = 0.013050 
Either_Row_CoL_Bus_Util = 0.013305 
Issued_on_Two_Bus_Simul_Util = 0.000002 
issued_two_Eff = 0.000166 
queue_avg = 0.812545 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.812545

========= L2 cache stats =========
L2_cache_bank[0]: Access = 16936, Miss = 931, Miss_rate = 0.055, Pending_hits = 92, Reservation_fails = 9
L2_cache_bank[1]: Access = 16896, Miss = 928, Miss_rate = 0.055, Pending_hits = 82, Reservation_fails = 3
L2_cache_bank[2]: Access = 16896, Miss = 928, Miss_rate = 0.055, Pending_hits = 38, Reservation_fails = 0
L2_cache_bank[3]: Access = 16896, Miss = 928, Miss_rate = 0.055, Pending_hits = 22, Reservation_fails = 16
L2_cache_bank[4]: Access = 16896, Miss = 928, Miss_rate = 0.055, Pending_hits = 51, Reservation_fails = 7
L2_cache_bank[5]: Access = 16896, Miss = 928, Miss_rate = 0.055, Pending_hits = 88, Reservation_fails = 5
L2_cache_bank[6]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 150, Reservation_fails = 0
L2_cache_bank[7]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 166, Reservation_fails = 3
L2_cache_bank[8]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 147, Reservation_fails = 0
L2_cache_bank[9]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 146, Reservation_fails = 0
L2_cache_bank[10]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 252, Reservation_fails = 0
L2_cache_bank[11]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 222, Reservation_fails = 0
L2_cache_bank[12]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 185, Reservation_fails = 0
L2_cache_bank[13]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 400, Reservation_fails = 0
L2_cache_bank[14]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 464, Reservation_fails = 29
L2_cache_bank[15]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 390, Reservation_fails = 42
L2_total_cache_accesses = 270576
L2_total_cache_misses = 15191
L2_total_cache_miss_rate = 0.0561
L2_total_cache_pending_hits = 2895
L2_total_cache_reservation_fails = 114
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 252440
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 2717
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 6987
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 2717
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 19
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 1
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 19
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 8192
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 114
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 50
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 159
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 11
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 159
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 262144
	L2_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 20
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 8192
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 220
L2_total_cache_reservation_fail_breakdown:
	L2_cache_stats_fail_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 114
L2_cache_data_port_util = 0.120
L2_cache_fill_port_util = 0.007

icnt_total_pkts_mem_to_simt=1320072
icnt_total_pkts_simt_to_mem=303344
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 26.4772
	minimum = 6
	maximum = 3302
Network latency average = 18.9565
	minimum = 6
	maximum = 2073
Slowest packet = 411
Flit latency average = 10.8628
	minimum = 6
	maximum = 2073
Slowest flit = 827
Fragmentation average = 0.00617387
	minimum = 0
	maximum = 455
Injected packet rate average = 0.0111225
	minimum = 0 (at node 36)
	maximum = 0.0174046 (at node 20)
Accepted packet rate average = 0.0111225
	minimum = 0 (at node 36)
	maximum = 0.0174046 (at node 20)
Injected flit rate average = 0.0333668
	minimum = 0 (at node 36)
	maximum = 0.0848774 (at node 20)
Accepted flit rate average= 0.0333668
	minimum = 0 (at node 36)
	maximum = 0.0688889 (at node 0)
Injected packet length average = 2.99993
Accepted packet length average = 2.99993
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 26.4772 (1 samples)
	minimum = 6 (1 samples)
	maximum = 3302 (1 samples)
Network latency average = 18.9565 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2073 (1 samples)
Flit latency average = 10.8628 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2073 (1 samples)
Fragmentation average = 0.00617387 (1 samples)
	minimum = 0 (1 samples)
	maximum = 455 (1 samples)
Injected packet rate average = 0.0111225 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0174046 (1 samples)
Accepted packet rate average = 0.0111225 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0174046 (1 samples)
Injected flit rate average = 0.0333668 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0848774 (1 samples)
Accepted flit rate average = 0.0333668 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0688889 (1 samples)
Injected packet size average = 2.99993 (1 samples)
Accepted packet size average = 2.99993 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 18 min, 0 sec (1080 sec)
gpgpu_simulation_rate = 445159 (inst/sec)
gpgpu_simulation_rate = 488 (cycle/sec)
gpgpu_silicon_slowdown = 3293032x
GPGPU-Sim: detected inactive GPU simulation thread
Performance= 0.00 GFlop/s, Time= 1080000.000 msec, Size= 268435456 Ops, WorkgroupSize= 1024 threads/block
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim API:    stream 1 has 1 operations
GPGPU-Sim API:       0 :  stream operation memcpy device-to-host
GPGPU-Sim: detected inactive GPU simulation thread
Checking computed result for correctness: Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
GPGPU-Sim: *** exit detected ***
