GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded


        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim PTX: overriding embedded ptx with ptx file (PTX_SIM_USE_PTX_FILE is set)
GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:1607.0:1607.0:2500.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:1607000000.000000:1607000000.000000:2500000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000062227753578:0.00000000062227753578:0.00000000040000000000
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
9bbca5a97e8086fe9c680e1bbeffbca4  /benchrun/accelsim-ptx/sm6_gtx1080/cuda10-matrixmul/input-wa512-ha512-wb512-hb512/matrixMul
Extracting PTX file and ptxas options    1: matrixMul.1.sm_30.ptx -arch=sm_30
GPGPU-Sim uArch: performance model initialization complete.
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/cuda10-matrixmul/input-wa512-ha512-wb512-hb512/matrixMul
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/cuda10-matrixmul/input-wa512-ha512-wb512-hb512/matrixMul
10.1
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=default
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/cuda10-matrixmul/input-wa512-ha512-wb512-hb512/matrixMul
Running md5sum using "md5sum /benchrun/accelsim-ptx/sm6_gtx1080/cuda10-matrixmul/input-wa512-ha512-wb512-hb512/matrixMul "
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/cuda10-matrixmul/input-wa512-ha512-wb512-hb512/matrixMul
Extracting specific PTX file named matrixMul.1.sm_30.ptx 
GPGPU-Sim PTX: __cudaRegisterFunction _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii : hostFun 0x0x56530d80373a, fat_cubin_handle = 1
GPGPU-Sim PTX: Parsing matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: allocating shared region for "_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2As" from 0x0 to 0x400 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "_ZZ13MatrixMulCUDAILi16EEvPfS0_S0_iiE2Bs" from 0x400 to 0x800 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii'...   done.
GPGPU-Sim PTX: allocating shared region for "_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2As" from 0x0 to 0x1000 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "_ZZ13MatrixMulCUDAILi32EEvPfS0_S0_iiE2Bs" from 0x1000 to 0x2000 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...   done.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
GPGPU-Sim PTX: Loading PTXInfo from matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: Kernel '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii' : regs=29, lmem=0, smem=8192, cmem=352
GPGPU-Sim PTX: Kernel '_Z13MatrixMulCUDAILi16EEvPfS0_S0_ii' : regs=29, lmem=0, smem=2048, cmem=352
GPGPU-Sim PTX: __cudaRegisterFunction _Z13MatrixMulCUDAILi16EEvPfS0_S0_ii : hostFun 0x0x56530d8036fd, fat_cubin_handle = 1
[Matrix Multiply Using CUDA] - Starting...
GPU Device 0: "Volta" with compute capability 7.0

MatrixA(512,512), MatrixB(512,512)
GPGPU-Sim PTX: cudaStreamCreate
Computing result using CUDA Kernel...
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffe41d36fc8..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffe41d36fc0..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffe41d36fb8..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7ffe41d36fb4..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7ffe41d36fb0..

GPGPU-Sim PTX: cudaLaunch for 0x0x56530d80373a (mode=performance simulation) on stream 1
GPGPU-Sim PTX: finding reconvergence points for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: Finding dominators for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: Finding postdominators for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'...
GPGPU-Sim PTX: reconvergence points for _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x3c8 (matrixMul.1.sm_30.ptx:182) @%p1 bra BB1_3;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x7e0 (matrixMul.1.sm_30.ptx:318) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX:  2 (potential) branch divergence @  PC=0x7d8 (matrixMul.1.sm_30.ptx:315) @%p2 bra BB1_2;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x7e0 (matrixMul.1.sm_30.ptx:318) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX: ... end of reconvergence points for _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'.
GPGPU-Sim PTX: pushing kernel '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii' to stream 1, gridDim= (16,16,1) blockDim = (32,32,1) 
event update
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim API:    stream 1 has 2 operations
GPGPU-Sim API:       0 :  stream operation kernel
GPGPU-Sim API:       1 :  stream operation event
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads shmem regs
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 16 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 17 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 18 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: Shader 19 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
Destroy streams for kernel 1: size 0
event update
kernel_name = _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii 
kernel_launch_uid = 1 
gpu_sim_cycle = 545879
gpu_sim_insn = 480772096
gpu_ipc =     880.7302
gpu_tot_sim_cycle = 545879
gpu_tot_sim_insn = 480772096
gpu_tot_ipc =     880.7302
gpu_tot_issued_cta = 256
gpu_occupancy = 96.2383% 
gpu_tot_occupancy = 96.2383% 
max_total_param_size = 0
gpu_stall_dramfull = 491647
gpu_stall_icnt2sh    = 1051766
partiton_level_parallism =       0.4957
partiton_level_parallism_total  =       0.4957
partiton_level_parallism_util =       1.2602
partiton_level_parallism_util_total  =       1.2602
L2_BW  =      25.4893 GB/Sec
L2_BW_total  =      25.4893 GB/Sec
gpu_total_sim_rate=516959

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 7643136
	L1I_total_cache_misses = 7711
	L1I_total_cache_miss_rate = 0.0010
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 117234
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 40960
	L1C_total_cache_misses = 1280
	L1C_total_cache_miss_rate = 0.0312
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 3620
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 39680
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 1280
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 3620
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 1260
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 7635425
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 7711
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 117234
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 7491
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 40960
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 7643136

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[CONST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 3620
	Total_core_cache_fail_stats_breakdown[INST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 117234
ctas_completed 256, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
distro:
11473, 11442, 11402, 11390, 11335, 11368, 11299, 11292, 11268, 11262, 11256, 11258, 11357, 11339, 11317, 11328, 11306, 11313, 11286, 11288, 11256, 11281, 11313, 11311, 11366, 11372, 11390, 11376, 11398, 11408, 11474, 11489, 11453, 11445, 11389, 11388, 11356, 11346, 11295, 11288, 11279, 11256, 11302, 11284, 11314, 11355, 11330, 11336, 11318, 11314, 11297, 11291, 11301, 11299, 11323, 11331, 11359, 11378, 11433, 11420, 11453, 11450, 11553, 11555, 
gpgpu_n_tot_thrd_icount = 481296384
gpgpu_n_tot_w_icount = 15040512
gpgpu_n_stall_shd_mem = 341031
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 262144
gpgpu_n_mem_write_global = 8192
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 20
gpgpu_n_load_insn  = 8388608
gpgpu_n_store_insn = 262144
gpgpu_n_shmem_insn = 276824064
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 1310720
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 3620
gpgpu_stall_shd_mem[c_mem][resource_stall] = 3620
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 0
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:5235368	W0_Idle:218511	W0_Scoreboard:1325563	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:15040512
single_issue_nums: WS0:7059640	WS1:7059320	
dual_issue_nums: WS0:230308	WS1:230468	
traffic_breakdown_coretomem[CONST_ACC_R] = 160 {8:20,}
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 2097152 {8:262144,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 1114112 {136:8192,}
traffic_breakdown_coretomem[INST_ACC_R] = 1760 {8:220,}
traffic_breakdown_memtocore[CONST_ACC_R] = 1440 {72:20,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 35651584 {136:262144,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 65536 {8:8192,}
traffic_breakdown_memtocore[INST_ACC_R] = 29920 {136:220,}
maxmflatency = 2955 
max_icnt2mem_latency = 8288 
maxmrqlatency = 773 
max_icnt2sh_latency = 78 
averagemflatency = 267 
avg_icnt2mem_latency = 53 
avg_mrq_latency = 152 
avg_icnt2sh_latency = 23 
mrq_lat_table:1584 	178 	361 	974 	3336 	3266 	2822 	4727 	5802 	299 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	185841 	61623 	19866 	1689 	1337 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	0 	199942 	29185 	10680 	7727 	9756 	8381 	2578 	1159 	1148 	18 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	0 	51198 	177534 	39034 	2590 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	687 	354 	22 	9 	11 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[5]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[6]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[7]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     80231     72400     80240     72497     79731     80504     79173     80429     96942    102811    103311    102908     79699     79434     79270     79453 
dram[1]:     69818     74194     69908     74205     89455    100912     89414    100892    102336    104632    102431    104635     91054    101068     91049    101054 
dram[2]:     80597     85207     80578     85196    107266    108424    107369    108533    103361    105746    103457    105852    107277    110747    107403    110817 
dram[3]:     87330     90066     87300     90024    106939    105274    107034    105388     89758     95977    107851     95938    114168    117387    114265    117418 
dram[4]:     95329     96279     95319     96242    104270    108283    104366    108384     92049     94565     92016     94534    120734    124035    120835    124132 
dram[5]:    102126    102837    102128    102842    107596    106025    107691    106120     96739    100355     96693    100291    127155    130216    127225    130317 
dram[6]:    106396    111583    106393    111590    105309    107592    105306    107687    101779    103802    101734    103801    133371    136596    133435    136660 
dram[7]:    112001    117435    111984    117396    115495    116697    115476    116694    107158    110622    107126    110586    139624    142878    139709    142946 
average row accesses per activate:
dram[0]: 19.888889 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 22.125000 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 
dram[1]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 
dram[2]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 23.500000 24.000000 
dram[3]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 22.125000 24.000000 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[4]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[5]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[6]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[7]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
average row locality = 23349/970 = 24.071135
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       460       448       448       448       448       448       448       448       452       448       448       448       512       512       512       512 
dram[1]:       448       448       448       448       448       448       448       448       448       448       448       448       512       512       512       512 
dram[2]:       448       448       448       448       448       448       448       448       448       448       448       448       512       512       496       512 
dram[3]:       456       456       448       448       448       448       448       448       452       512       448       512       512       512       512       512 
dram[4]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[5]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[6]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[7]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
total dram reads = 60628
bank skew: 512/448 = 1.14
chip skew: 7696/7408 = 1.04
number of total write accesses:
dram[0]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[1]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[2]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[3]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[4]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[5]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[6]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[7]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
total dram writes = 32768
bank skew: 256/256 = 1.00
chip skew: 4096/4096 = 1.00
average mf latency per bank:
dram[0]:       1001      1068      1606      1659      1385      1176      1546      1456      1066       861      1166       993       586       675       678       776
dram[1]:        931       790      1299       969       977       843      1194      1040       909       843      1065      1008       667       743       799       879
dram[2]:        840       653      1022       792       780       719       900       779       722       627       903       729       742       552       915       649
dram[3]:        658       676       781       827       715       628       800       696       689       607       769       696       545       629       632       730
dram[4]:        705       655       829       779       734       736       845       802       599       576       721       671       548       567       669       651
dram[5]:        675       652       792       771       675       688       750       785       600       579       679       721       555       615       644       725
dram[6]:        669       628       773       738       627       690       706       748       608       582       679       687       570       561       674       684
dram[7]:        712       647       867       755       662       644       717       722       617       566       721       643       628       596       752       686
maximum mf latency per bank:
dram[0]:       2282      2452      2825      2773      2825      2656      2830      2733      2955      1891      2825      1831       835       796       995       992
dram[1]:       2224      1110      2310      1572      2214      1855      2275      1568      2043      1735      1461      1505      1037      1155       966      1236
dram[2]:        973       797      1018       867      2248      2248       907      1263      1737      1735      1702      1241       937       808      1178       826
dram[3]:        902      1003       875      1053      2214      1885      1224       848      1761      1735      1157       782       807       852       736       911
dram[4]:        713       839       913       988      1865      2254       776      1282      1735      1733       777      1157       657      1240       775       668
dram[5]:       1076       803      1189       821      1871      2262       971       693       739       958       810       861      1200       946       832       803
dram[6]:        719       766       842       747      2218      1871       694       815      1745       742       775       746       636       715       705       879
dram[7]:        936       812       892       855      2254      2254       946       916       920       925       928       915       845       915       847       830
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=849220 n_nop=837462 n_act=120 n_pre=104 n_ref_event=0 n_req=2884 n_rd=3344 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02717
n_activity=38743 dram_eff=0.5955
bk0: 460a 845391i bk1: 448a 845389i bk2: 448a 845438i bk3: 448a 845423i bk4: 448a 845925i bk5: 448a 845616i bk6: 448a 845627i bk7: 448a 845633i bk8: 452a 845272i bk9: 448a 845436i bk10: 448a 845358i bk11: 448a 845288i bk12: 512a 846020i bk13: 512a 845713i bk14: 512a 845830i bk15: 512a 845730i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.958738
Row_Buffer_Locality_read = 0.970430
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.740973
Bank_Level_Parallism_Col = 1.740401
Bank_Level_Parallism_Ready = 1.375888
write_to_read_ratio_blp_rw_average = 0.405570
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027168 
total_CMD = 849220 
util_bw = 23072 
Wasted_Col = 11690 
Wasted_Row = 713 
Idle = 813745 

BW Util Bottlenecks: 
RCDc_limit = 570 
RCDWRc_limit = 280 
WTRc_limit = 9268 
RTWc_limit = 9807 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9268 
RTWc_limit_alone = 9807 

Commands details: 
total_CMD = 849220 
n_nop = 837462 
Read = 3344 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 120 
n_pre = 104 
n_ref = 0 
n_req = 2884 
total_req = 11536 

Dual Bus Interface Util: 
issued_total_row = 224 
issued_total_col = 11536 
Row_Bus_Util =  0.000264 
CoL_Bus_Util = 0.013584 
Either_Row_CoL_Bus_Util = 0.013846 
Issued_on_Two_Bus_Simul_Util = 0.000002 
issued_two_Eff = 0.000170 
queue_avg = 0.762962 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.762962
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=849220 n_nop=837485 n_act=116 n_pre=100 n_ref_event=0 n_req=2880 n_rd=3328 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02713
n_activity=36069 dram_eff=0.6388
bk0: 448a 845534i bk1: 448a 845556i bk2: 448a 845483i bk3: 448a 845504i bk4: 448a 845081i bk5: 448a 845039i bk6: 448a 845020i bk7: 448a 845056i bk8: 448a 845818i bk9: 448a 845810i bk10: 448a 845690i bk11: 448a 845686i bk12: 512a 845524i bk13: 512a 845237i bk14: 512a 845425i bk15: 512a 845407i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959722
Row_Buffer_Locality_read = 0.971983
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.820557
Bank_Level_Parallism_Col = 1.814231
Bank_Level_Parallism_Ready = 1.402309
write_to_read_ratio_blp_rw_average = 0.410283
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027131 
total_CMD = 849220 
util_bw = 23040 
Wasted_Col = 11313 
Wasted_Row = 566 
Idle = 814301 

BW Util Bottlenecks: 
RCDc_limit = 406 
RCDWRc_limit = 278 
WTRc_limit = 9358 
RTWc_limit = 9688 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9358 
RTWc_limit_alone = 9688 

Commands details: 
total_CMD = 849220 
n_nop = 837485 
Read = 3328 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 116 
n_pre = 100 
n_ref = 0 
n_req = 2880 
total_req = 11520 

Dual Bus Interface Util: 
issued_total_row = 216 
issued_total_col = 11520 
Row_Bus_Util =  0.000254 
CoL_Bus_Util = 0.013565 
Either_Row_CoL_Bus_Util = 0.013819 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000085 
queue_avg = 0.819425 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.819425
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=849220 n_nop=837501 n_act=116 n_pre=100 n_ref_event=0 n_req=2876 n_rd=3312 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02709
n_activity=35487 dram_eff=0.6484
bk0: 448a 845354i bk1: 448a 845401i bk2: 448a 845307i bk3: 448a 845275i bk4: 448a 845592i bk5: 448a 845779i bk6: 448a 845516i bk7: 448a 845753i bk8: 448a 845663i bk9: 448a 845503i bk10: 448a 845433i bk11: 448a 845532i bk12: 512a 845403i bk13: 512a 845505i bk14: 496a 845142i bk15: 512a 845129i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959666
Row_Buffer_Locality_read = 0.971922
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.811674
Bank_Level_Parallism_Col = 1.802278
Bank_Level_Parallism_Ready = 1.399218
write_to_read_ratio_blp_rw_average = 0.415398
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027093 
total_CMD = 849220 
util_bw = 23008 
Wasted_Col = 11279 
Wasted_Row = 515 
Idle = 814418 

BW Util Bottlenecks: 
RCDc_limit = 348 
RCDWRc_limit = 289 
WTRc_limit = 9290 
RTWc_limit = 9895 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9290 
RTWc_limit_alone = 9895 

Commands details: 
total_CMD = 849220 
n_nop = 837501 
Read = 3312 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 116 
n_pre = 100 
n_ref = 0 
n_req = 2876 
total_req = 11504 

Dual Bus Interface Util: 
issued_total_row = 216 
issued_total_col = 11504 
Row_Bus_Util =  0.000254 
CoL_Bus_Util = 0.013547 
Either_Row_CoL_Bus_Util = 0.013800 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000085 
queue_avg = 0.837043 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.837043
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=849220 n_nop=837323 n_act=123 n_pre=107 n_ref_event=0 n_req=2917 n_rd=3476 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02748
n_activity=36244 dram_eff=0.6439
bk0: 456a 845416i bk1: 456a 845434i bk2: 448a 845260i bk3: 448a 845355i bk4: 448a 845588i bk5: 448a 845816i bk6: 448a 845407i bk7: 448a 845581i bk8: 452a 845762i bk9: 512a 845301i bk10: 448a 845638i bk11: 512a 845312i bk12: 512a 845818i bk13: 512a 845669i bk14: 512a 845657i bk15: 512a 845554i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957833
Row_Buffer_Locality_read = 0.968833
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.740943
Bank_Level_Parallism_Col = 1.731834
Bank_Level_Parallism_Ready = 1.358385
write_to_read_ratio_blp_rw_average = 0.408363
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027479 
total_CMD = 849220 
util_bw = 23336 
Wasted_Col = 11560 
Wasted_Row = 593 
Idle = 813731 

BW Util Bottlenecks: 
RCDc_limit = 413 
RCDWRc_limit = 299 
WTRc_limit = 9310 
RTWc_limit = 9744 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9310 
RTWc_limit_alone = 9744 

Commands details: 
total_CMD = 849220 
n_nop = 837323 
Read = 3476 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 123 
n_pre = 107 
n_ref = 0 
n_req = 2917 
total_req = 11668 

Dual Bus Interface Util: 
issued_total_row = 230 
issued_total_col = 11668 
Row_Bus_Util =  0.000271 
CoL_Bus_Util = 0.013740 
Either_Row_CoL_Bus_Util = 0.014009 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000084 
queue_avg = 0.816927 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.816927
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=849220 n_nop=837196 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02777
n_activity=37294 dram_eff=0.6324
bk0: 456a 845830i bk1: 456a 845768i bk2: 448a 845805i bk3: 448a 845793i bk4: 448a 845882i bk5: 448a 845758i bk6: 448a 845758i bk7: 448a 845790i bk8: 512a 845751i bk9: 512a 845754i bk10: 512a 845687i bk11: 512a 845699i bk12: 512a 845775i bk13: 512a 845643i bk14: 512a 845667i bk15: 512a 845622i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.602392
Bank_Level_Parallism_Col = 1.592415
Bank_Level_Parallism_Ready = 1.290706
write_to_read_ratio_blp_rw_average = 0.400330
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027771 
total_CMD = 849220 
util_bw = 23584 
Wasted_Col = 12241 
Wasted_Row = 626 
Idle = 812769 

BW Util Bottlenecks: 
RCDc_limit = 410 
RCDWRc_limit = 295 
WTRc_limit = 9308 
RTWc_limit = 9677 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9308 
RTWc_limit_alone = 9677 

Commands details: 
total_CMD = 849220 
n_nop = 837196 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000273 
CoL_Bus_Util = 0.013886 
Either_Row_CoL_Bus_Util = 0.014159 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.753576 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=50 avg=0.753576
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=849220 n_nop=837196 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02777
n_activity=36592 dram_eff=0.6445
bk0: 456a 845733i bk1: 456a 845591i bk2: 448a 845600i bk3: 448a 845731i bk4: 448a 845837i bk5: 448a 845920i bk6: 448a 845888i bk7: 448a 845868i bk8: 512a 845522i bk9: 512a 845237i bk10: 512a 845141i bk11: 512a 845232i bk12: 512a 845555i bk13: 512a 845445i bk14: 512a 845336i bk15: 512a 845445i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.714846
Bank_Level_Parallism_Col = 1.705785
Bank_Level_Parallism_Ready = 1.356337
write_to_read_ratio_blp_rw_average = 0.397310
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027771 
total_CMD = 849220 
util_bw = 23584 
Wasted_Col = 11571 
Wasted_Row = 605 
Idle = 813460 

BW Util Bottlenecks: 
RCDc_limit = 426 
RCDWRc_limit = 273 
WTRc_limit = 9264 
RTWc_limit = 9701 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9264 
RTWc_limit_alone = 9701 

Commands details: 
total_CMD = 849220 
n_nop = 837196 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000273 
CoL_Bus_Util = 0.013886 
Either_Row_CoL_Bus_Util = 0.014159 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.807379 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.807379
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=849220 n_nop=837198 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02777
n_activity=37582 dram_eff=0.6275
bk0: 456a 845802i bk1: 456a 845872i bk2: 448a 845824i bk3: 448a 845883i bk4: 448a 845971i bk5: 448a 845922i bk6: 448a 845941i bk7: 448a 845764i bk8: 512a 845727i bk9: 512a 845605i bk10: 512a 845464i bk11: 512a 845636i bk12: 512a 845781i bk13: 512a 845781i bk14: 512a 845698i bk15: 512a 845718i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.577609
Bank_Level_Parallism_Col = 1.569767
Bank_Level_Parallism_Ready = 1.288331
write_to_read_ratio_blp_rw_average = 0.400638
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027771 
total_CMD = 849220 
util_bw = 23584 
Wasted_Col = 12510 
Wasted_Row = 674 
Idle = 812452 

BW Util Bottlenecks: 
RCDc_limit = 449 
RCDWRc_limit = 312 
WTRc_limit = 9267 
RTWc_limit = 9689 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9267 
RTWc_limit_alone = 9689 

Commands details: 
total_CMD = 849220 
n_nop = 837198 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000273 
CoL_Bus_Util = 0.013886 
Either_Row_CoL_Bus_Util = 0.014157 
Issued_on_Two_Bus_Simul_Util = 0.000002 
issued_two_Eff = 0.000166 
queue_avg = 0.751486 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=51 avg=0.751486
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents

Cache L2_bank_015:
MSHR contents
MSHR: tag=0xc02fff80, atomic=0 1 entries : 0x7f788b8ed960 :  mf: uid=8083478, sid03:w31, part=7, addr=0xc02fff80, load , size=128, unknown  status = IN_PARTITION_DRAM (545877), 

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=849220 n_nop=837201 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02777
n_activity=34792 dram_eff=0.6779
bk0: 456a 845254i bk1: 456a 845382i bk2: 448a 845167i bk3: 448a 845691i bk4: 448a 845066i bk5: 448a 845026i bk6: 448a 844921i bk7: 448a 845053i bk8: 512a 845006i bk9: 512a 844752i bk10: 512a 844648i bk11: 512a 844795i bk12: 512a 845106i bk13: 512a 845115i bk14: 512a 844956i bk15: 512a 845182i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.030131
Bank_Level_Parallism_Col = 2.021418
Bank_Level_Parallism_Ready = 1.511575
write_to_read_ratio_blp_rw_average = 0.399829
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027771 
total_CMD = 849220 
util_bw = 23584 
Wasted_Col = 10014 
Wasted_Row = 521 
Idle = 815101 

BW Util Bottlenecks: 
RCDc_limit = 418 
RCDWRc_limit = 274 
WTRc_limit = 9256 
RTWc_limit = 9856 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9256 
RTWc_limit_alone = 9856 

Commands details: 
total_CMD = 849220 
n_nop = 837201 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000273 
CoL_Bus_Util = 0.013886 
Either_Row_CoL_Bus_Util = 0.014153 
Issued_on_Two_Bus_Simul_Util = 0.000006 
issued_two_Eff = 0.000416 
queue_avg = 0.933826 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.933826

========= L2 cache stats =========
L2_cache_bank[0]: Access = 16936, Miss = 932, Miss_rate = 0.055, Pending_hits = 59, Reservation_fails = 14
L2_cache_bank[1]: Access = 16896, Miss = 928, Miss_rate = 0.055, Pending_hits = 59, Reservation_fails = 19
L2_cache_bank[2]: Access = 16896, Miss = 928, Miss_rate = 0.055, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[3]: Access = 16896, Miss = 928, Miss_rate = 0.055, Pending_hits = 24, Reservation_fails = 2
L2_cache_bank[4]: Access = 16896, Miss = 924, Miss_rate = 0.055, Pending_hits = 47, Reservation_fails = 9
L2_cache_bank[5]: Access = 16896, Miss = 928, Miss_rate = 0.055, Pending_hits = 58, Reservation_fails = 19
L2_cache_bank[6]: Access = 16916, Miss = 931, Miss_rate = 0.055, Pending_hits = 20, Reservation_fails = 2
L2_cache_bank[7]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 60, Reservation_fails = 0
L2_cache_bank[8]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 38, Reservation_fails = 0
L2_cache_bank[9]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 15, Reservation_fails = 0
L2_cache_bank[10]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 24, Reservation_fails = 0
L2_cache_bank[11]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 84, Reservation_fails = 0
L2_cache_bank[12]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 92, Reservation_fails = 3
L2_cache_bank[13]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 103, Reservation_fails = 4
L2_cache_bank[14]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 100, Reservation_fails = 34
L2_cache_bank[15]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 44, Reservation_fails = 9
L2_total_cache_accesses = 270576
L2_total_cache_misses = 15157
L2_total_cache_miss_rate = 0.0560
L2_total_cache_pending_hits = 827
L2_total_cache_reservation_fails = 115
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 254517
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 674
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 6953
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 674
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 19
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 1
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 19
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 8192
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 115
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 75
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 134
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 11
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 134
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 262144
	L2_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 20
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 8192
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 220
L2_total_cache_reservation_fail_breakdown:
	L2_cache_stats_fail_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 115
L2_cache_data_port_util = 0.117
L2_cache_fill_port_util = 0.007

icnt_total_pkts_mem_to_simt=1320072
icnt_total_pkts_simt_to_mem=303344
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 30.028
	minimum = 6
	maximum = 2566
Network latency average = 21.21
	minimum = 6
	maximum = 1120
Slowest packet = 195
Flit latency average = 14.321
	minimum = 6
	maximum = 1120
Slowest flit = 6285
Fragmentation average = 0.00445531
	minimum = 0
	maximum = 306
Injected packet rate average = 0.0198268
	minimum = 0 (at node 36)
	maximum = 0.0310252 (at node 20)
Accepted packet rate average = 0.0198268
	minimum = 0 (at node 36)
	maximum = 0.0310252 (at node 20)
Injected flit rate average = 0.059479
	minimum = 0 (at node 36)
	maximum = 0.151301 (at node 20)
Accepted flit rate average= 0.059479
	minimum = 0 (at node 36)
	maximum = 0.1228 (at node 2)
Injected packet length average = 2.99993
Accepted packet length average = 2.99993
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 30.028 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2566 (1 samples)
Network latency average = 21.21 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1120 (1 samples)
Flit latency average = 14.321 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1120 (1 samples)
Fragmentation average = 0.00445531 (1 samples)
	minimum = 0 (1 samples)
	maximum = 306 (1 samples)
Injected packet rate average = 0.0198268 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0310252 (1 samples)
Accepted packet rate average = 0.0198268 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0310252 (1 samples)
Injected flit rate average = 0.059479 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.151301 (1 samples)
Accepted flit rate average = 0.059479 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.1228 (1 samples)
Injected packet size average = 2.99993 (1 samples)
Accepted packet size average = 2.99993 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 15 min, 30 sec (930 sec)
gpgpu_simulation_rate = 516959 (inst/sec)
gpgpu_simulation_rate = 586 (cycle/sec)
gpgpu_silicon_slowdown = 2742320x
GPGPU-Sim: detected inactive GPU simulation thread
Performance= 0.00 GFlop/s, Time= 929000.000 msec, Size= 268435456 Ops, WorkgroupSize= 1024 threads/block
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim API:    stream 1 has 1 operations
GPGPU-Sim API:       0 :  stream operation memcpy device-to-host
GPGPU-Sim: detected inactive GPU simulation thread
Checking computed result for correctness: Result = PASS

NOTE: The CUDA Samples are not meant for performance measurements. Results may vary when GPU Boost is enabled.
GPGPU-Sim: *** exit detected ***
