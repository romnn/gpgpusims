GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded


        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim PTX: overriding embedded ptx with ptx file (PTX_SIM_USE_PTX_FILE is set)
GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:2962.0:1607.0:2750.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:2962000000.000000:1607000000.000000:2750000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000033760972316:0.00000000062227753578:0.00000000036363636364
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
4afaa8906a2f7270684a5acecb8aee41  /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-128/matrixMul
Extracting PTX file and ptxas options    1: matrixMul.1.sm_30.ptx -arch=sm_30
GPGPU-Sim uArch: performance model initialization complete.
self exe links to: /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-128/matrixMul
self exe links to: /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-128/matrixMul
10.1
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=default
self exe links to: /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-128/matrixMul
Running md5sum using "md5sum /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-128/matrixMul "
self exe links to: /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-128/matrixMul
Extracting specific PTX file named matrixMul.1.sm_30.ptx 
GPGPU-Sim PTX: __cudaRegisterFunction _Z8mult_gpuPfS_S_ii : hostFun 0x0x55ac650017d7, fat_cubin_handle = 1
GPGPU-Sim PTX: Parsing matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: allocating shared region for "_ZZ8mult_gpuPfS_S_iiE2As" from 0x0 to 0x1000 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "_ZZ8mult_gpuPfS_S_iiE2Bs" from 0x1000 to 0x2000 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z8mult_gpuPfS_S_ii'...   done.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
GPGPU-Sim PTX: Loading PTXInfo from matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: Kernel '_Z8mult_gpuPfS_S_ii' : regs=29, lmem=0, smem=8192, cmem=352
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
grid: (4,4,1)
threads: (32,32,1)
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffe14881368..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffe14881360..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffe14881358..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7ffe14881354..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7ffe14881350..

GPGPU-Sim PTX: cudaLaunch for 0x0x55ac650017d7 (mode=performance simulation) on stream 0
GPGPU-Sim PTX: finding reconvergence points for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding dominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding postdominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: reconvergence points for _Z8mult_gpuPfS_S_ii...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x068 (matrixMul.1.sm_30.ptx:47) @%p1 bra BB0_3;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x480 (matrixMul.1.sm_30.ptx:183) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX:  2 (potential) branch divergence @  PC=0x478 (matrixMul.1.sm_30.ptx:180) @%p2 bra BB0_2;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x480 (matrixMul.1.sm_30.ptx:183) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX: ... end of reconvergence points for _Z8mult_gpuPfS_S_ii
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z8mult_gpuPfS_S_ii'.
GPGPU-Sim PTX: pushing kernel '_Z8mult_gpuPfS_S_ii' to stream 0, gridDim= (4,4,1) blockDim = (32,32,1) 
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads shmem regs
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
Destroy streams for kernel 1: size 0
kernel_name = _Z8mult_gpuPfS_S_ii 
kernel_launch_uid = 1 
gpu_sim_cycle = 14759
gpu_sim_insn = 8028160
gpu_ipc =     543.9501
gpu_tot_sim_cycle = 14759
gpu_tot_sim_insn = 8028160
gpu_tot_ipc =     543.9501
gpu_tot_issued_cta = 16
gpu_occupancy = 49.4335% 
gpu_tot_occupancy = 49.4335% 
max_total_param_size = 0
gpu_stall_dramfull = 7618
gpu_stall_icnt2sh    = 8813
partiton_level_parallism =       0.3241
partiton_level_parallism_total  =       0.3241
partiton_level_parallism_util =       1.7931
partiton_level_parallism_util_total  =       1.7931
L2_BW  =      30.7234 GB/Sec
L2_BW_total  =      30.7234 GB/Sec
gpu_total_sim_rate=535210

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 127488
	L1I_total_cache_misses = 4904
	L1I_total_cache_miss_rate = 0.0385
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 0
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 2560
	L1C_total_cache_misses = 1024
	L1C_total_cache_miss_rate = 0.4000
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 3023
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 1536
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 1024
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 3023
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 1008
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 122584
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 4904
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 4744
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 2560
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 127488

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[CONST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 3023
ctas_completed 16, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 
distro:
516, 510, 510, 513, 512, 520, 503, 505, 505, 504, 504, 506, 504, 504, 508, 504, 506, 515, 506, 504, 505, 507, 512, 507, 513, 512, 517, 514, 519, 517, 521, 518, 
gpgpu_n_tot_thrd_icount = 8060928
gpgpu_n_tot_w_icount = 251904
gpgpu_n_stall_shd_mem = 3812
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 4096
gpgpu_n_mem_write_global = 512
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 16
gpgpu_n_load_insn  = 131072
gpgpu_n_store_insn = 16384
gpgpu_n_shmem_insn = 4325376
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 81920
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 3023
gpgpu_stall_shd_mem[c_mem][resource_stall] = 3023
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 0
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:77258	W0_Idle:46456	W0_Scoreboard:92329	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:251904
single_issue_nums: WS0:116736	WS1:116582	
dual_issue_nums: WS0:4608	WS1:4685	
traffic_breakdown_coretomem[CONST_ACC_R] = 128 {8:16,}
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 32768 {8:4096,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 69632 {136:512,}
traffic_breakdown_coretomem[INST_ACC_R] = 1280 {8:160,}
traffic_breakdown_memtocore[CONST_ACC_R] = 1152 {72:16,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 557056 {136:4096,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 4096 {8:512,}
traffic_breakdown_memtocore[INST_ACC_R] = 21760 {136:160,}
maxmflatency = 674 
max_icnt2mem_latency = 522 
maxmrqlatency = 319 
max_icnt2sh_latency = 38 
averagemflatency = 246 
avg_icnt2mem_latency = 41 
avg_mrq_latency = 85 
avg_icnt2sh_latency = 10 
mrq_lat_table:120 	26 	66 	83 	125 	128 	182 	240 	65 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	2795 	1527 	302 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	2974 	513 	204 	437 	306 	98 	249 	3 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	2137 	1855 	618 	14 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	9 	6 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:         1         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
maximum service time to same row:
dram[0]:       262       798         0         0         0         0         0         0     14052     13845     13464     14029         0         0         0         0 
dram[1]:      1280      2268         0         0         0         0         0         0     13454     13426     14247     14142         0         0         0         0 
dram[2]:      2690      3065         0         0         0         0         0         0     14057     13848     13455     14022         0         0         0         0 
dram[3]:      3452      3872         0         0         0         0         0         0     13447     13433     14239     14135         0         0         0         0 
dram[4]:      4246      4789         0         0         0         0         0         0     14047     13855     13467     14035         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0     13458     13423     14250     14146         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0     14054     13852     13460     14026         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0     13451     13429     14243     14139         0         0         0         0 
average row accesses per activate:
dram[0]:  1.000000  1.000000      -nan      -nan      -nan      -nan      -nan      -nan 32.000000 32.000000 32.000000 32.000000      -nan      -nan      -nan      -nan 
dram[1]:  1.000000  1.000000      -nan      -nan      -nan      -nan      -nan      -nan 32.000000 32.000000 32.000000 32.000000      -nan      -nan      -nan      -nan 
dram[2]:  1.000000  1.000000      -nan      -nan      -nan      -nan      -nan      -nan 32.000000 32.000000 32.000000 32.000000      -nan      -nan      -nan      -nan 
dram[3]:  1.000000  1.000000      -nan      -nan      -nan      -nan      -nan      -nan 32.000000 32.000000 32.000000 32.000000      -nan      -nan      -nan      -nan 
dram[4]:  1.000000  1.000000      -nan      -nan      -nan      -nan      -nan      -nan 32.000000 32.000000 32.000000 32.000000      -nan      -nan      -nan      -nan 
dram[5]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 32.000000 32.000000 32.000000 32.000000      -nan      -nan      -nan      -nan 
dram[6]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 32.000000 32.000000 32.000000 32.000000      -nan      -nan      -nan      -nan 
dram[7]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 32.000000 32.000000 32.000000 32.000000      -nan      -nan      -nan      -nan 
average row locality = 1035/43 = 24.069767
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:         8         4         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[1]:         4         4         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[2]:         4         4         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[3]:         4         4         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[4]:         4         4         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
total dram reads = 2092
min_bank_accesses = 0!
chip skew: 268/256 = 1.05
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0        64        64        64        64         0         0         0         0 
total dram writes = 2048
min_bank_accesses = 0!
chip skew: 256/256 = 1.00
average mf latency per bank:
dram[0]:       2915      5229    none      none      none      none      none      none          47        47        33        46    none      none      none      none  
dram[1]:       3381      3107    none      none      none      none      none      none          32        35        54        39    none      none      none      none  
dram[2]:       4837      5389    none      none      none      none      none      none          49        48        33        43    none      none      none      none  
dram[3]:       3491      3070    none      none      none      none      none      none          32        35        53        38    none      none      none      none  
dram[4]:       4908      5260    none      none      none      none      none      none          47        46        32        45    none      none      none      none  
dram[5]:     none      none      none      none      none      none      none      none          32        33        52        40    none      none      none      none  
dram[6]:     none      none      none      none      none      none      none      none          48        47        33        42    none      none      none      none  
dram[7]:     none      none      none      none      none      none      none      none          31        33        52        40    none      none      none      none  
maximum mf latency per bank:
dram[0]:        646       639       672       659       587       579       149       149       464       549       330       403         0         0         0         0
dram[1]:        383       336       484       360       140       140       421       296       285       355       546       408         0         0         0         0
dram[2]:        636       665       650       674       587       588       142       149       475       558       336       381         0         0         0         0
dram[3]:        485       299       491       330       138       140       470       270       283       347       533       400         0         0         0         0
dram[4]:        630       651       652       644       572       588       142       139       456       541       316       403         0         0         0         0
dram[5]:        405       344       486       361       140       142       444       304       283       337       534       419         0         0         0         0
dram[6]:        639       644       650       636       573       576       138       156       468       548       338       371         0         0         0         0
dram[7]:        386       329       478       365       145       142       398       311       269       328       532       415         0         0         0         0
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=25255 n_nop=24723 n_act=7 n_pre=1 n_ref_event=0 n_req=131 n_rd=12 n_rd_L2_A=256 n_write=256 n_wr_bk=0 bw_util=0.0415
n_activity=1763 dram_eff=0.5944
bk0: 8a 25205i bk1: 4a 25234i bk2: 0a 25254i bk3: 0a 25257i bk4: 0a 25257i bk5: 0a 25258i bk6: 0a 25258i bk7: 0a 25258i bk8: 64a 24309i bk9: 64a 24320i bk10: 64a 24555i bk11: 64a 24275i bk12: 0a 25252i bk13: 0a 25252i bk14: 0a 25252i bk15: 0a 25252i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.946565
Row_Buffer_Locality_read = 0.955224
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.294872
Bank_Level_Parallism_Col = 2.306601
Bank_Level_Parallism_Ready = 1.708015
write_to_read_ratio_blp_rw_average = 0.472959
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.041497 
total_CMD = 25255 
util_bw = 1048 
Wasted_Col = 587 
Wasted_Row = 12 
Idle = 23608 

BW Util Bottlenecks: 
RCDc_limit = 36 
RCDWRc_limit = 18 
WTRc_limit = 588 
RTWc_limit = 564 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 588 
RTWc_limit_alone = 564 

Commands details: 
total_CMD = 25255 
n_nop = 24723 
Read = 12 
Write = 256 
L2_Alloc = 256 
L2_WB = 0 
n_act = 7 
n_pre = 1 
n_ref = 0 
n_req = 131 
total_req = 524 

Dual Bus Interface Util: 
issued_total_row = 8 
issued_total_col = 524 
Row_Bus_Util =  0.000317 
CoL_Bus_Util = 0.020748 
Either_Row_CoL_Bus_Util = 0.021065 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.885805 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=27 avg=0.885805
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents
MSHR: tag=0xc002b900, atomic=0 1 entries : 0x7f344b8b22c0 :  mf: uid=138169, sid10:w28, part=1, addr=0xc002b900, load , size=128, unknown  status = IN_PARTITION_DRAM (14753), 

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=25255 n_nop=24729 n_act=6 n_pre=0 n_ref_event=0 n_req=130 n_rd=8 n_rd_L2_A=256 n_write=256 n_wr_bk=0 bw_util=0.04118
n_activity=1825 dram_eff=0.5699
bk0: 4a 25235i bk1: 4a 25236i bk2: 0a 25255i bk3: 0a 25256i bk4: 0a 25256i bk5: 0a 25257i bk6: 0a 25259i bk7: 0a 25259i bk8: 64a 24662i bk9: 64a 24391i bk10: 64a 24419i bk11: 64a 24443i bk12: 0a 25251i bk13: 0a 25252i bk14: 0a 25252i bk15: 0a 25252i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.953846
Row_Buffer_Locality_read = 0.969697
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.894036
Bank_Level_Parallism_Col = 1.894370
Bank_Level_Parallism_Ready = 1.514395
write_to_read_ratio_blp_rw_average = 0.479590
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.041180 
total_CMD = 25255 
util_bw = 1040 
Wasted_Col = 696 
Wasted_Row = 0 
Idle = 23519 

BW Util Bottlenecks: 
RCDc_limit = 24 
RCDWRc_limit = 24 
WTRc_limit = 589 
RTWc_limit = 541 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 589 
RTWc_limit_alone = 541 

Commands details: 
total_CMD = 25255 
n_nop = 24729 
Read = 8 
Write = 256 
L2_Alloc = 256 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 130 
total_req = 520 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 520 
Row_Bus_Util =  0.000238 
CoL_Bus_Util = 0.020590 
Either_Row_CoL_Bus_Util = 0.020828 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.678242 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=35 avg=0.678242
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=25255 n_nop=24729 n_act=6 n_pre=0 n_ref_event=0 n_req=130 n_rd=8 n_rd_L2_A=256 n_write=256 n_wr_bk=0 bw_util=0.04118
n_activity=1714 dram_eff=0.6068
bk0: 4a 25234i bk1: 4a 25236i bk2: 0a 25255i bk3: 0a 25257i bk4: 0a 25257i bk5: 0a 25257i bk6: 0a 25258i bk7: 0a 25258i bk8: 64a 24311i bk9: 64a 24301i bk10: 64a 24539i bk11: 64a 24290i bk12: 0a 25252i bk13: 0a 25252i bk14: 0a 25252i bk15: 0a 25252i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.953846
Row_Buffer_Locality_read = 0.969697
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.344180
Bank_Level_Parallism_Col = 2.346299
Bank_Level_Parallism_Ready = 1.728846
write_to_read_ratio_blp_rw_average = 0.474488
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.041180 
total_CMD = 25255 
util_bw = 1040 
Wasted_Col = 568 
Wasted_Row = 0 
Idle = 23647 

BW Util Bottlenecks: 
RCDc_limit = 24 
RCDWRc_limit = 21 
WTRc_limit = 590 
RTWc_limit = 554 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 590 
RTWc_limit_alone = 554 

Commands details: 
total_CMD = 25255 
n_nop = 24729 
Read = 8 
Write = 256 
L2_Alloc = 256 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 130 
total_req = 520 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 520 
Row_Bus_Util =  0.000238 
CoL_Bus_Util = 0.020590 
Either_Row_CoL_Bus_Util = 0.020828 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.868660 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=27 avg=0.86866
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=25255 n_nop=24729 n_act=6 n_pre=0 n_ref_event=0 n_req=130 n_rd=8 n_rd_L2_A=256 n_write=256 n_wr_bk=0 bw_util=0.04118
n_activity=1824 dram_eff=0.5702
bk0: 4a 25235i bk1: 4a 25236i bk2: 0a 25254i bk3: 0a 25256i bk4: 0a 25256i bk5: 0a 25257i bk6: 0a 25258i bk7: 0a 25258i bk8: 64a 24666i bk9: 64a 24383i bk10: 64a 24411i bk11: 64a 24462i bk12: 0a 25252i bk13: 0a 25252i bk14: 0a 25253i bk15: 0a 25253i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.953846
Row_Buffer_Locality_read = 0.969697
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.917792
Bank_Level_Parallism_Col = 1.918776
Bank_Level_Parallism_Ready = 1.510557
write_to_read_ratio_blp_rw_average = 0.479007
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.041180 
total_CMD = 25255 
util_bw = 1040 
Wasted_Col = 673 
Wasted_Row = 0 
Idle = 23542 

BW Util Bottlenecks: 
RCDc_limit = 24 
RCDWRc_limit = 17 
WTRc_limit = 578 
RTWc_limit = 537 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 578 
RTWc_limit_alone = 537 

Commands details: 
total_CMD = 25255 
n_nop = 24729 
Read = 8 
Write = 256 
L2_Alloc = 256 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 130 
total_req = 520 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 520 
Row_Bus_Util =  0.000238 
CoL_Bus_Util = 0.020590 
Either_Row_CoL_Bus_Util = 0.020828 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.652227 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=34 avg=0.652227
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=25255 n_nop=24729 n_act=6 n_pre=0 n_ref_event=0 n_req=130 n_rd=8 n_rd_L2_A=256 n_write=256 n_wr_bk=0 bw_util=0.04118
n_activity=1707 dram_eff=0.6093
bk0: 4a 25235i bk1: 4a 25235i bk2: 0a 25254i bk3: 0a 25257i bk4: 0a 25257i bk5: 0a 25257i bk6: 0a 25258i bk7: 0a 25258i bk8: 64a 24297i bk9: 64a 24324i bk10: 64a 24565i bk11: 64a 24265i bk12: 0a 25252i bk13: 0a 25252i bk14: 0a 25252i bk15: 0a 25253i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.953846
Row_Buffer_Locality_read = 0.969697
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.337922
Bank_Level_Parallism_Col = 2.339398
Bank_Level_Parallism_Ready = 1.734615
write_to_read_ratio_blp_rw_average = 0.478879
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.041180 
total_CMD = 25255 
util_bw = 1040 
Wasted_Col = 567 
Wasted_Row = 0 
Idle = 23648 

BW Util Bottlenecks: 
RCDc_limit = 24 
RCDWRc_limit = 17 
WTRc_limit = 576 
RTWc_limit = 568 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 576 
RTWc_limit_alone = 568 

Commands details: 
total_CMD = 25255 
n_nop = 24729 
Read = 8 
Write = 256 
L2_Alloc = 256 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 130 
total_req = 520 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 520 
Row_Bus_Util =  0.000238 
CoL_Bus_Util = 0.020590 
Either_Row_CoL_Bus_Util = 0.020828 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.849218 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=26 avg=0.849218
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents
MSHR: tag=0xc002bd00, atomic=0 1 entries : 0x7f344551fce0 :  mf: uid=138182, sid10:w30, part=5, addr=0xc002bd00, load , size=128, unknown  status = IN_PARTITION_DRAM (14758), 

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=25255 n_nop=24741 n_act=4 n_pre=0 n_ref_event=0 n_req=128 n_rd=0 n_rd_L2_A=254 n_write=256 n_wr_bk=0 bw_util=0.04039
n_activity=1736 dram_eff=0.5876
bk0: 0a 25253i bk1: 0a 25254i bk2: 0a 25254i bk3: 0a 25256i bk4: 0a 25257i bk5: 0a 25258i bk6: 0a 25259i bk7: 0a 25259i bk8: 64a 24692i bk9: 64a 24492i bk10: 62a 24415i bk11: 64a 24403i bk12: 0a 25251i bk13: 0a 25251i bk14: 0a 25252i bk15: 0a 25252i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.968750
Row_Buffer_Locality_read = 1.000000
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.918293
Bank_Level_Parallism_Col = 1.919365
Bank_Level_Parallism_Ready = 1.521569
write_to_read_ratio_blp_rw_average = 0.480656
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.040388 
total_CMD = 25255 
util_bw = 1020 
Wasted_Col = 629 
Wasted_Row = 0 
Idle = 23606 

BW Util Bottlenecks: 
RCDc_limit = 0 
RCDWRc_limit = 18 
WTRc_limit = 581 
RTWc_limit = 475 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 581 
RTWc_limit_alone = 475 

Commands details: 
total_CMD = 25255 
n_nop = 24741 
Read = 0 
Write = 256 
L2_Alloc = 254 
L2_WB = 0 
n_act = 4 
n_pre = 0 
n_ref = 0 
n_req = 128 
total_req = 510 

Dual Bus Interface Util: 
issued_total_row = 4 
issued_total_col = 510 
Row_Bus_Util =  0.000158 
CoL_Bus_Util = 0.020194 
Either_Row_CoL_Bus_Util = 0.020352 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.633657 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=35 avg=0.633657
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=25255 n_nop=24739 n_act=4 n_pre=0 n_ref_event=0 n_req=128 n_rd=0 n_rd_L2_A=256 n_write=256 n_wr_bk=0 bw_util=0.04055
n_activity=1634 dram_eff=0.6267
bk0: 0a 25252i bk1: 0a 25255i bk2: 0a 25256i bk3: 0a 25256i bk4: 0a 25256i bk5: 0a 25257i bk6: 0a 25258i bk7: 0a 25258i bk8: 64a 24299i bk9: 64a 24301i bk10: 64a 24539i bk11: 64a 24290i bk12: 0a 25252i bk13: 0a 25252i bk14: 0a 25252i bk15: 0a 25252i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.968750
Row_Buffer_Locality_read = 1.000000
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.387676
Bank_Level_Parallism_Col = 2.388175
Bank_Level_Parallism_Ready = 1.750000
write_to_read_ratio_blp_rw_average = 0.485433
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.040546 
total_CMD = 25255 
util_bw = 1024 
Wasted_Col = 541 
Wasted_Row = 0 
Idle = 23690 

BW Util Bottlenecks: 
RCDc_limit = 0 
RCDWRc_limit = 28 
WTRc_limit = 590 
RTWc_limit = 560 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 590 
RTWc_limit_alone = 560 

Commands details: 
total_CMD = 25255 
n_nop = 24739 
Read = 0 
Write = 256 
L2_Alloc = 256 
L2_WB = 0 
n_act = 4 
n_pre = 0 
n_ref = 0 
n_req = 128 
total_req = 512 

Dual Bus Interface Util: 
issued_total_row = 4 
issued_total_col = 512 
Row_Bus_Util =  0.000158 
CoL_Bus_Util = 0.020273 
Either_Row_CoL_Bus_Util = 0.020432 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.821263 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=26 avg=0.821263
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents
MSHR: tag=0xc002bf00, atomic=0 1 entries : 0x7f34446b4fe0 :  mf: uid=138180, sid10:w31, part=7, addr=0xc002bf00, load , size=128, unknown  status = IN_PARTITION_DRAM (14755), 

Cache L2_bank_015:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=25255 n_nop=24739 n_act=4 n_pre=0 n_ref_event=0 n_req=128 n_rd=0 n_rd_L2_A=256 n_write=256 n_wr_bk=0 bw_util=0.04055
n_activity=1716 dram_eff=0.5967
bk0: 0a 25253i bk1: 0a 25254i bk2: 0a 25254i bk3: 0a 25255i bk4: 0a 25257i bk5: 0a 25258i bk6: 0a 25259i bk7: 0a 25259i bk8: 64a 24704i bk9: 64a 24419i bk10: 64a 24412i bk11: 64a 24408i bk12: 0a 25251i bk13: 0a 25252i bk14: 0a 25252i bk15: 0a 25252i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.968750
Row_Buffer_Locality_read = 1.000000
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.960245
Bank_Level_Parallism_Col = 1.960196
Bank_Level_Parallism_Ready = 1.533203
write_to_read_ratio_blp_rw_average = 0.482956
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.040546 
total_CMD = 25255 
util_bw = 1024 
Wasted_Col = 619 
Wasted_Row = 0 
Idle = 23612 

BW Util Bottlenecks: 
RCDc_limit = 0 
RCDWRc_limit = 23 
WTRc_limit = 576 
RTWc_limit = 511 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 576 
RTWc_limit_alone = 511 

Commands details: 
total_CMD = 25255 
n_nop = 24739 
Read = 0 
Write = 256 
L2_Alloc = 256 
L2_WB = 0 
n_act = 4 
n_pre = 0 
n_ref = 0 
n_req = 128 
total_req = 512 

Dual Bus Interface Util: 
issued_total_row = 4 
issued_total_col = 512 
Row_Bus_Util =  0.000158 
CoL_Bus_Util = 0.020273 
Either_Row_CoL_Bus_Util = 0.020432 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.606098 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=34 avg=0.606098

========= L2 cache stats =========
L2_cache_bank[0]: Access = 320, Miss = 34, Miss_rate = 0.106, Pending_hits = 30, Reservation_fails = 0
L2_cache_bank[1]: Access = 304, Miss = 33, Miss_rate = 0.109, Pending_hits = 15, Reservation_fails = 0
L2_cache_bank[2]: Access = 304, Miss = 33, Miss_rate = 0.109, Pending_hits = 15, Reservation_fails = 0
L2_cache_bank[3]: Access = 304, Miss = 33, Miss_rate = 0.109, Pending_hits = 4, Reservation_fails = 0
L2_cache_bank[4]: Access = 304, Miss = 33, Miss_rate = 0.109, Pending_hits = 8, Reservation_fails = 0
L2_cache_bank[5]: Access = 304, Miss = 33, Miss_rate = 0.109, Pending_hits = 15, Reservation_fails = 0
L2_cache_bank[6]: Access = 304, Miss = 33, Miss_rate = 0.109, Pending_hits = 15, Reservation_fails = 0
L2_cache_bank[7]: Access = 304, Miss = 33, Miss_rate = 0.109, Pending_hits = 15, Reservation_fails = 0
L2_cache_bank[8]: Access = 304, Miss = 33, Miss_rate = 0.109, Pending_hits = 15, Reservation_fails = 0
L2_cache_bank[9]: Access = 304, Miss = 33, Miss_rate = 0.109, Pending_hits = 15, Reservation_fails = 0
L2_cache_bank[10]: Access = 288, Miss = 32, Miss_rate = 0.111, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[11]: Access = 288, Miss = 32, Miss_rate = 0.111, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[12]: Access = 288, Miss = 32, Miss_rate = 0.111, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[13]: Access = 288, Miss = 32, Miss_rate = 0.111, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[14]: Access = 288, Miss = 32, Miss_rate = 0.111, Pending_hits = 0, Reservation_fails = 0
L2_cache_bank[15]: Access = 288, Miss = 32, Miss_rate = 0.111, Pending_hits = 0, Reservation_fails = 0
L2_total_cache_accesses = 4784
L2_total_cache_misses = 523
L2_total_cache_miss_rate = 0.1093
L2_total_cache_pending_hits = 147
L2_total_cache_reservation_fails = 0
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 4096
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 15
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 1
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 15
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 512
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 18
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 132
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 10
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 132
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 4096
	L2_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 16
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 512
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 160
L2_total_cache_reservation_fail_breakdown:
L2_cache_data_port_util = 0.070
L2_cache_fill_port_util = 0.009

icnt_total_pkts_mem_to_simt=21840
icnt_total_pkts_simt_to_mem=6832
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 28.4888
	minimum = 6
	maximum = 816
Network latency average = 22.9701
	minimum = 6
	maximum = 767
Slowest packet = 638
Flit latency average = 13.9585
	minimum = 6
	maximum = 767
Slowest flit = 862
Fragmentation average = 0
	minimum = 0
	maximum = 0
Injected packet rate average = 0.00703478
	minimum = 0 (at node 16)
	maximum = 0.0117638 (at node 20)
Accepted packet rate average = 0.00703478
	minimum = 0 (at node 16)
	maximum = 0.0117638 (at node 20)
Injected flit rate average = 0.0210808
	minimum = 0 (at node 16)
	maximum = 0.0529373 (at node 20)
Accepted flit rate average= 0.0210808
	minimum = 0 (at node 16)
	maximum = 0.0501801 (at node 0)
Injected packet length average = 2.99666
Accepted packet length average = 2.99666
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 28.4888 (1 samples)
	minimum = 6 (1 samples)
	maximum = 816 (1 samples)
Network latency average = 22.9701 (1 samples)
	minimum = 6 (1 samples)
	maximum = 767 (1 samples)
Flit latency average = 13.9585 (1 samples)
	minimum = 6 (1 samples)
	maximum = 767 (1 samples)
Fragmentation average = 0 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0 (1 samples)
Injected packet rate average = 0.00703478 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0117638 (1 samples)
Accepted packet rate average = 0.00703478 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0117638 (1 samples)
Injected flit rate average = 0.0210808 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0529373 (1 samples)
Accepted flit rate average = 0.0210808 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0501801 (1 samples)
Injected packet size average = 2.99666 (1 samples)
Accepted packet size average = 2.99666 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 15 sec (15 sec)
gpgpu_simulation_rate = 535210 (inst/sec)
gpgpu_simulation_rate = 983 (cycle/sec)
gpgpu_silicon_slowdown = 1634791x
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
The GPU Elapsed Time:14.816799 Sec.
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
The CPU Elapsed Time:0.010230 Sec.
Verifying
PASS
GPGPU-Sim: *** exit detected ***
