GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded


        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim PTX: overriding embedded ptx with ptx file (PTX_SIM_USE_PTX_FILE is set)
GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:2962.0:1607.0:2750.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:2962000000.000000:1607000000.000000:2750000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000033760972316:0.00000000062227753578:0.00000000036363636364
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
4afaa8906a2f7270684a5acecb8aee41  /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-512/matrixMul
Extracting PTX file and ptxas options    1: matrixMul.1.sm_30.ptx -arch=sm_30
GPGPU-Sim uArch: performance model initialization complete.
self exe links to: /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-512/matrixMul
self exe links to: /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-512/matrixMul
10.1
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=default
self exe links to: /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-512/matrixMul
Running md5sum using "md5sum /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-512/matrixMul "
self exe links to: /benchrun/accelsim-ptx/cuda4-matrixmul/sm6_gtx1080/input-512/matrixMul
Extracting specific PTX file named matrixMul.1.sm_30.ptx 
GPGPU-Sim PTX: __cudaRegisterFunction _Z8mult_gpuPfS_S_ii : hostFun 0x0x5611b86017d7, fat_cubin_handle = 1
GPGPU-Sim PTX: Parsing matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: allocating shared region for "_ZZ8mult_gpuPfS_S_iiE2As" from 0x0 to 0x1000 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "_ZZ8mult_gpuPfS_S_iiE2Bs" from 0x1000 to 0x2000 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z8mult_gpuPfS_S_ii'...   done.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
GPGPU-Sim PTX: Loading PTXInfo from matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: Kernel '_Z8mult_gpuPfS_S_ii' : regs=29, lmem=0, smem=8192, cmem=352
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
grid: (16,16,1)
threads: (32,32,1)
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffc5c486498..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffc5c486490..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffc5c486488..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7ffc5c486484..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7ffc5c486480..

GPGPU-Sim PTX: cudaLaunch for 0x0x5611b86017d7 (mode=performance simulation) on stream 0
GPGPU-Sim PTX: finding reconvergence points for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding dominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding postdominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: reconvergence points for _Z8mult_gpuPfS_S_ii...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x068 (matrixMul.1.sm_30.ptx:47) @%p1 bra BB0_3;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x480 (matrixMul.1.sm_30.ptx:183) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX:  2 (potential) branch divergence @  PC=0x478 (matrixMul.1.sm_30.ptx:180) @%p2 bra BB0_2;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x480 (matrixMul.1.sm_30.ptx:183) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX: ... end of reconvergence points for _Z8mult_gpuPfS_S_ii
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z8mult_gpuPfS_S_ii'.
GPGPU-Sim PTX: pushing kernel '_Z8mult_gpuPfS_S_ii' to stream 0, gridDim= (16,16,1) blockDim = (32,32,1) 
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads shmem regs
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 16 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 17 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 18 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 19 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
Destroy streams for kernel 1: size 0
kernel_name = _Z8mult_gpuPfS_S_ii 
kernel_launch_uid = 1 
gpu_sim_cycle = 523870
gpu_sim_insn = 480772096
gpu_ipc =     917.7317
gpu_tot_sim_cycle = 523870
gpu_tot_sim_insn = 480772096
gpu_tot_ipc =     917.7317
gpu_tot_issued_cta = 256
gpu_occupancy = 96.1186% 
gpu_tot_occupancy = 96.1186% 
max_total_param_size = 0
gpu_stall_dramfull = 359663
gpu_stall_icnt2sh    = 213056
partiton_level_parallism =       0.5165
partiton_level_parallism_total  =       0.5165
partiton_level_parallism_util =       1.2576
partiton_level_parallism_util_total  =       1.2576
L2_BW  =      48.9518 GB/Sec
L2_BW_total  =      48.9518 GB/Sec
gpu_total_sim_rate=497693

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 7643136
	L1I_total_cache_misses = 5952
	L1I_total_cache_miss_rate = 0.0008
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 4923
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 40960
	L1C_total_cache_misses = 1280
	L1C_total_cache_miss_rate = 0.0312
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 3735
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 39680
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 1280
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 3735
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 1260
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 7637184
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 5952
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 4923
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 5752
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 40960
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 7643136

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[CONST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 3735
	Total_core_cache_fail_stats_breakdown[INST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 4923
ctas_completed 256, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
distro:
13368, 13329, 13285, 13334, 13237, 13263, 13207, 13178, 13156, 13153, 13171, 13160, 13224, 13230, 13220, 13245, 13164, 13210, 13175, 13142, 13167, 13155, 13238, 13215, 13262, 13286, 13301, 13321, 13325, 13360, 13438, 13449, 11474, 11453, 11399, 11393, 11344, 11359, 11310, 11300, 11239, 11279, 11270, 11298, 11339, 11352, 11357, 11319, 11318, 11339, 11294, 11290, 11268, 11293, 11324, 11307, 11385, 11340, 11397, 11374, 11397, 11438, 11507, 11488, 
gpgpu_n_tot_thrd_icount = 481296384
gpgpu_n_tot_w_icount = 15040512
gpgpu_n_stall_shd_mem = 180893
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 262144
gpgpu_n_mem_write_global = 8192
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 20
gpgpu_n_load_insn  = 8388608
gpgpu_n_store_insn = 262144
gpgpu_n_shmem_insn = 276824064
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 1310720
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 3735
gpgpu_stall_shd_mem[c_mem][resource_stall] = 3735
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 0
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:5039485	W0_Idle:61632	W0_Scoreboard:871662	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:15040512
single_issue_nums: WS0:7062548	WS1:7063178	
dual_issue_nums: WS0:228854	WS1:228539	
traffic_breakdown_coretomem[CONST_ACC_R] = 160 {8:20,}
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 2097152 {8:262144,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 1114112 {136:8192,}
traffic_breakdown_coretomem[INST_ACC_R] = 1600 {8:200,}
traffic_breakdown_memtocore[CONST_ACC_R] = 1440 {72:20,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 35651584 {136:262144,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 65536 {8:8192,}
traffic_breakdown_memtocore[INST_ACC_R] = 27200 {136:200,}
maxmflatency = 2255 
max_icnt2mem_latency = 1809 
maxmrqlatency = 771 
max_icnt2sh_latency = 42 
averagemflatency = 197 
avg_icnt2mem_latency = 28 
avg_mrq_latency = 153 
avg_icnt2sh_latency = 7 
mrq_lat_table:1671 	276 	485 	1389 	3154 	2907 	2583 	4671 	5900 	350 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	224505 	38887 	5107 	1602 	255 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	219612 	13513 	8439 	6841 	8141 	9083 	2065 	1282 	1580 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	207200 	47991 	14587 	578 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	981 	46 	9 	8 	1 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[5]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[6]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[7]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     79245     66567     78230     66536     78841     82334     77700     82346     91616     82971     96533     97284    135118     84073    135163     84115 
dram[1]:     65501     75890     65555     75901     94529    106604     94529    106579     94659    104053     95701    104037     96107    105844     96188    105838 
dram[2]:     80654     83935     80654     83938     96938     91325     97053     91416     81241     84800     97457     84778     97849    101076     97905    101140 
dram[3]:     86933     90249     86900     90251     91036     95055     91127     95147     87429     90798     87398     90785    104246    107179    104301    107258 
dram[4]:     92388     95627     92350     95599     93495     96238     93582     96235     91197     94904     91172     94877    110268    113361    110358    113423 
dram[5]:     98495    101373     98483    101341     99991    100008     99994     99990     96922     99080     96915     99065    116415    119470    116499    119523 
dram[6]:    103263    106902    103235    106864    105553    106391    105507    106368    101510    104789    101500    104777    122512    125607    122603    125704 
dram[7]:    109115    112031    109125    111991    108625    112045    108618    112044    107190    111257    107157    111282    128717    131811    128790    131884 
average row accesses per activate:
dram[0]: 17.900000 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 22.125000 22.125000 25.142857 25.142857 25.142857 24.000000 25.142857 24.000000 
dram[1]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 22.125000 22.125000 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 
dram[2]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 22.125000 24.000000 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[3]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[4]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[5]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[6]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[7]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
average row locality = 23386/974 = 24.010267
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       460       456       448       448       448       448       448       448       452       452       448       448       448       512       448       512 
dram[1]:       456       456       448       448       448       448       448       448       452       452       448       448       512       512       512       512 
dram[2]:       456       456       448       448       448       448       448       448       452       512       448       512       512       512       512       512 
dram[3]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[4]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[5]:       448       448       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[6]:       448       448       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[7]:       448       448       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
total dram reads = 60776
bank skew: 512/448 = 1.14
chip skew: 7696/7324 = 1.05
number of total write accesses:
dram[0]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[1]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[2]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[3]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[4]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[5]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[6]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[7]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
total dram writes = 32768
bank skew: 256/256 = 1.00
chip skew: 4096/4096 = 1.00
average mf latency per bank:
dram[0]:        785       742      1205       950       907       706      1044       808       691       549       752       596       469       483       489       534
dram[1]:        694       622       832       712       660       614       718       625       544       539       590       593       489       526       549       607
dram[2]:        588       570       627       598       535       546       589       568       524       473       554       506       475       461       516       506
dram[3]:        546       526       569       561       524       558       560       577       473       475       515       508       467       478       502       525
dram[4]:        563       544       612       577       546       563       593       595       495       478       551       519       470       465       511       515
dram[5]:        544       553       565       588       534       540       574       571       537       478       582       517       453       493       493       536
dram[6]:        596       591       649       652       518       551       553       587       519       496       560       539       474       500       513       551
dram[7]:        578       561       631       604       525       516       556       544       509       477       541       525       508       499       554       544
maximum mf latency per bank:
dram[0]:       2094      1893      2246      1985      2208      1865      2255      1974      2230       801      2224       835       906       854       845       862
dram[1]:       1464      1463      1847      1886      1468      1351      1516      1151       953      1145       789       824      1128       808      1369      1063
dram[2]:       1421      1421      1407      1475      1351       757       692       672       943       788       889       764      1021       958       987       987
dram[3]:       1420      1420      1406      1845       840      1351       800       818       771      1131       746       744       779       826       769       752
dram[4]:       1420      1420      1420      1412       703      1343       755       716       592       644       613       596       795       681       719       745
dram[5]:       1420      1420      1434      1374      1352      1337       713       728       752       657       666       697       587       627       571       595
dram[6]:       1422      1420      1888      1411      1245      1246       558       567      1227       790       764       719       594       651       608       601
dram[7]:       1421      1421      1413      1891      1339      1341       835       802      1175       789       819       838       967       910       824       821
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=896478 n_nop=884835 n_act=121 n_pre=105 n_ref_event=0 n_req=2855 n_rd=3228 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02548
n_activity=35955 dram_eff=0.6352
bk0: 460a 892340i bk1: 456a 892319i bk2: 448a 892310i bk3: 448a 892260i bk4: 448a 892088i bk5: 448a 892193i bk6: 448a 892080i bk7: 448a 892037i bk8: 452a 892266i bk9: 452a 892402i bk10: 448a 892351i bk11: 448a 892193i bk12: 448a 891640i bk13: 512a 891279i bk14: 448a 891363i bk15: 512a 891336i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957618
Row_Buffer_Locality_read = 0.968869
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.305037
Bank_Level_Parallism_Col = 2.314886
Bank_Level_Parallism_Ready = 1.658466
write_to_read_ratio_blp_rw_average = 0.397832
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.025477 
total_CMD = 896478 
util_bw = 22840 
Wasted_Col = 8918 
Wasted_Row = 674 
Idle = 864046 

BW Util Bottlenecks: 
RCDc_limit = 610 
RCDWRc_limit = 279 
WTRc_limit = 9288 
RTWc_limit = 9916 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9288 
RTWc_limit_alone = 9916 

Commands details: 
total_CMD = 896478 
n_nop = 884835 
Read = 3228 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 121 
n_pre = 105 
n_ref = 0 
n_req = 2855 
total_req = 11420 

Dual Bus Interface Util: 
issued_total_row = 226 
issued_total_col = 11420 
Row_Bus_Util =  0.000252 
CoL_Bus_Util = 0.012739 
Either_Row_CoL_Bus_Util = 0.012987 
Issued_on_Two_Bus_Simul_Util = 0.000003 
issued_two_Eff = 0.000258 
queue_avg = 0.932593 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.932593
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=896478 n_nop=884710 n_act=122 n_pre=106 n_ref_event=0 n_req=2886 n_rd=3352 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02575
n_activity=35729 dram_eff=0.6462
bk0: 456a 892639i bk1: 456a 892687i bk2: 448a 892596i bk3: 448a 892645i bk4: 448a 893082i bk5: 448a 892912i bk6: 448a 892945i bk7: 448a 892919i bk8: 452a 892167i bk9: 452a 892235i bk10: 448a 892148i bk11: 448a 892094i bk12: 512a 892565i bk13: 512a 892326i bk14: 512a 892206i bk15: 512a 892390i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957727
Row_Buffer_Locality_read = 0.968851
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.923630
Bank_Level_Parallism_Col = 1.919030
Bank_Level_Parallism_Ready = 1.470553
write_to_read_ratio_blp_rw_average = 0.399871
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.025754 
total_CMD = 896478 
util_bw = 23088 
Wasted_Col = 10672 
Wasted_Row = 593 
Idle = 862125 

BW Util Bottlenecks: 
RCDc_limit = 497 
RCDWRc_limit = 324 
WTRc_limit = 9333 
RTWc_limit = 9782 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9333 
RTWc_limit_alone = 9782 

Commands details: 
total_CMD = 896478 
n_nop = 884710 
Read = 3352 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 122 
n_pre = 106 
n_ref = 0 
n_req = 2886 
total_req = 11544 

Dual Bus Interface Util: 
issued_total_row = 228 
issued_total_col = 11544 
Row_Bus_Util =  0.000254 
CoL_Bus_Util = 0.012877 
Either_Row_CoL_Bus_Util = 0.013127 
Issued_on_Two_Bus_Simul_Util = 0.000004 
issued_two_Eff = 0.000340 
queue_avg = 0.837978 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.837978
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=896478 n_nop=884581 n_act=123 n_pre=107 n_ref_event=0 n_req=2917 n_rd=3476 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02603
n_activity=34695 dram_eff=0.6726
bk0: 456a 892436i bk1: 456a 892718i bk2: 448a 892664i bk3: 448a 892507i bk4: 448a 893027i bk5: 448a 892492i bk6: 448a 892365i bk7: 448a 892703i bk8: 452a 892217i bk9: 512a 892295i bk10: 448a 891805i bk11: 512a 892234i bk12: 512a 892056i bk13: 512a 892227i bk14: 512a 891904i bk15: 512a 891987i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957833
Row_Buffer_Locality_read = 0.968833
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.024366
Bank_Level_Parallism_Col = 2.015551
Bank_Level_Parallism_Ready = 1.487061
write_to_read_ratio_blp_rw_average = 0.410624
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026031 
total_CMD = 896478 
util_bw = 23336 
Wasted_Col = 10160 
Wasted_Row = 516 
Idle = 862466 

BW Util Bottlenecks: 
RCDc_limit = 394 
RCDWRc_limit = 302 
WTRc_limit = 9326 
RTWc_limit = 9838 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9326 
RTWc_limit_alone = 9838 

Commands details: 
total_CMD = 896478 
n_nop = 884581 
Read = 3476 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 123 
n_pre = 107 
n_ref = 0 
n_req = 2917 
total_req = 11668 

Dual Bus Interface Util: 
issued_total_row = 230 
issued_total_col = 11668 
Row_Bus_Util =  0.000257 
CoL_Bus_Util = 0.013015 
Either_Row_CoL_Bus_Util = 0.013271 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000084 
queue_avg = 0.887509 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.887509
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=896478 n_nop=884455 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02631
n_activity=34630 dram_eff=0.681
bk0: 456a 892471i bk1: 456a 892294i bk2: 448a 892300i bk3: 448a 892284i bk4: 448a 892523i bk5: 448a 892686i bk6: 448a 892532i bk7: 448a 892429i bk8: 512a 892365i bk9: 512a 892143i bk10: 512a 891980i bk11: 512a 892161i bk12: 512a 892393i bk13: 512a 892284i bk14: 512a 892093i bk15: 512a 892151i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.047245
Bank_Level_Parallism_Col = 2.038527
Bank_Level_Parallism_Ready = 1.524928
write_to_read_ratio_blp_rw_average = 0.390917
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026307 
total_CMD = 896478 
util_bw = 23584 
Wasted_Col = 9816 
Wasted_Row = 516 
Idle = 862562 

BW Util Bottlenecks: 
RCDc_limit = 439 
RCDWRc_limit = 304 
WTRc_limit = 9302 
RTWc_limit = 9817 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9302 
RTWc_limit_alone = 9817 

Commands details: 
total_CMD = 896478 
n_nop = 884455 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000259 
CoL_Bus_Util = 0.013154 
Either_Row_CoL_Bus_Util = 0.013411 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000083 
queue_avg = 0.906755 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.906755
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=896478 n_nop=884454 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02631
n_activity=36095 dram_eff=0.6534
bk0: 456a 892528i bk1: 456a 892475i bk2: 448a 892409i bk3: 448a 892420i bk4: 448a 892795i bk5: 448a 892534i bk6: 448a 892495i bk7: 448a 892608i bk8: 512a 893038i bk9: 512a 892966i bk10: 512a 892905i bk11: 512a 892915i bk12: 512a 892538i bk13: 512a 892863i bk14: 512a 892578i bk15: 512a 892407i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.815748
Bank_Level_Parallism_Col = 1.807200
Bank_Level_Parallism_Ready = 1.414074
write_to_read_ratio_blp_rw_average = 0.395931
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026307 
total_CMD = 896478 
util_bw = 23584 
Wasted_Col = 11114 
Wasted_Row = 577 
Idle = 861203 

BW Util Bottlenecks: 
RCDc_limit = 407 
RCDWRc_limit = 302 
WTRc_limit = 9277 
RTWc_limit = 9805 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9277 
RTWc_limit_alone = 9805 

Commands details: 
total_CMD = 896478 
n_nop = 884454 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000259 
CoL_Bus_Util = 0.013154 
Either_Row_CoL_Bus_Util = 0.013412 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.813433 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.813433
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=896478 n_nop=884478 n_act=120 n_pre=104 n_ref_event=0 n_req=2944 n_rd=3584 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02627
n_activity=36863 dram_eff=0.6389
bk0: 448a 893052i bk1: 448a 892817i bk2: 448a 892798i bk3: 448a 892875i bk4: 448a 892857i bk5: 448a 892997i bk6: 448a 892902i bk7: 448a 892791i bk8: 512a 892810i bk9: 512a 892964i bk10: 512a 892791i bk11: 512a 892676i bk12: 512a 893068i bk13: 512a 893045i bk14: 512a 892951i bk15: 512a 892913i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959239
Row_Buffer_Locality_read = 0.970833
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.667842
Bank_Level_Parallism_Col = 1.658299
Bank_Level_Parallism_Ready = 1.331833
write_to_read_ratio_blp_rw_average = 0.400151
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026272 
total_CMD = 896478 
util_bw = 23552 
Wasted_Col = 11965 
Wasted_Row = 577 
Idle = 860384 

BW Util Bottlenecks: 
RCDc_limit = 386 
RCDWRc_limit = 359 
WTRc_limit = 9290 
RTWc_limit = 9771 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9290 
RTWc_limit_alone = 9771 

Commands details: 
total_CMD = 896478 
n_nop = 884478 
Read = 3584 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 120 
n_pre = 104 
n_ref = 0 
n_req = 2944 
total_req = 11776 

Dual Bus Interface Util: 
issued_total_row = 224 
issued_total_col = 11776 
Row_Bus_Util =  0.000250 
CoL_Bus_Util = 0.013136 
Either_Row_CoL_Bus_Util = 0.013386 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.758633 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.758633
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=896478 n_nop=884478 n_act=120 n_pre=104 n_ref_event=0 n_req=2944 n_rd=3584 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02627
n_activity=36704 dram_eff=0.6417
bk0: 448a 893107i bk1: 448a 893240i bk2: 448a 893097i bk3: 448a 893070i bk4: 448a 893167i bk5: 448a 893135i bk6: 448a 893066i bk7: 448a 893113i bk8: 512a 892442i bk9: 512a 892314i bk10: 512a 892122i bk11: 512a 892182i bk12: 512a 893034i bk13: 512a 892998i bk14: 512a 892929i bk15: 512a 892949i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959239
Row_Buffer_Locality_read = 0.970833
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.693580
Bank_Level_Parallism_Col = 1.682020
Bank_Level_Parallism_Ready = 1.338738
write_to_read_ratio_blp_rw_average = 0.400204
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026272 
total_CMD = 896478 
util_bw = 23552 
Wasted_Col = 11700 
Wasted_Row = 529 
Idle = 860697 

BW Util Bottlenecks: 
RCDc_limit = 395 
RCDWRc_limit = 331 
WTRc_limit = 9265 
RTWc_limit = 9827 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9265 
RTWc_limit_alone = 9827 

Commands details: 
total_CMD = 896478 
n_nop = 884478 
Read = 3584 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 120 
n_pre = 104 
n_ref = 0 
n_req = 2944 
total_req = 11776 

Dual Bus Interface Util: 
issued_total_row = 224 
issued_total_col = 11776 
Row_Bus_Util =  0.000250 
CoL_Bus_Util = 0.013136 
Either_Row_CoL_Bus_Util = 0.013386 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.760850 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.76085
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents
MSHR: tag=0xc02fff00, atomic=0 1 entries : 0x7f0e45441e20 :  mf: uid=7971282, sid00:w31, part=7, addr=0xc02fff00, load , size=128, unknown  status = IN_PARTITION_DRAM (523869), 

Cache L2_bank_015:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=896478 n_nop=884481 n_act=120 n_pre=104 n_ref_event=0 n_req=2944 n_rd=3584 n_rd_L2_A=4094 n_write=4096 n_wr_bk=0 bw_util=0.02627
n_activity=33887 dram_eff=0.6949
bk0: 448a 892244i bk1: 448a 892015i bk2: 448a 892008i bk3: 448a 892039i bk4: 448a 892279i bk5: 448a 892048i bk6: 448a 891934i bk7: 448a 891981i bk8: 512a 892406i bk9: 512a 892518i bk10: 512a 892384i bk11: 512a 892256i bk12: 512a 892005i bk13: 512a 891620i bk14: 510a 891783i bk15: 512a 891566i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959239
Row_Buffer_Locality_read = 0.970833
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 2.212689
Bank_Level_Parallism_Col = 2.207513
Bank_Level_Parallism_Ready = 1.607692
write_to_read_ratio_blp_rw_average = 0.393320
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.026267 
total_CMD = 896478 
util_bw = 23547 
Wasted_Col = 9139 
Wasted_Row = 505 
Idle = 863287 

BW Util Bottlenecks: 
RCDc_limit = 380 
RCDWRc_limit = 323 
WTRc_limit = 9302 
RTWc_limit = 9870 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9302 
RTWc_limit_alone = 9870 

Commands details: 
total_CMD = 896478 
n_nop = 884481 
Read = 3584 
Write = 4096 
L2_Alloc = 4094 
L2_WB = 0 
n_act = 120 
n_pre = 104 
n_ref = 0 
n_req = 2944 
total_req = 11774 

Dual Bus Interface Util: 
issued_total_row = 224 
issued_total_col = 11774 
Row_Bus_Util =  0.000250 
CoL_Bus_Util = 0.013134 
Either_Row_CoL_Bus_Util = 0.013382 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000083 
queue_avg = 0.939746 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.939746

========= L2 cache stats =========
L2_cache_bank[0]: Access = 16936, Miss = 900, Miss_rate = 0.053, Pending_hits = 79, Reservation_fails = 11
L2_cache_bank[1]: Access = 16916, Miss = 931, Miss_rate = 0.055, Pending_hits = 70, Reservation_fails = 5
L2_cache_bank[2]: Access = 16916, Miss = 931, Miss_rate = 0.055, Pending_hits = 106, Reservation_fails = 5
L2_cache_bank[3]: Access = 16916, Miss = 931, Miss_rate = 0.055, Pending_hits = 21, Reservation_fails = 23
L2_cache_bank[4]: Access = 16916, Miss = 931, Miss_rate = 0.055, Pending_hits = 161, Reservation_fails = 9
L2_cache_bank[5]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 174, Reservation_fails = 24
L2_cache_bank[6]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 145, Reservation_fails = 0
L2_cache_bank[7]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 223, Reservation_fails = 0
L2_cache_bank[8]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 228, Reservation_fails = 0
L2_cache_bank[9]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 235, Reservation_fails = 0
L2_cache_bank[10]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 315, Reservation_fails = 0
L2_cache_bank[11]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 277, Reservation_fails = 0
L2_cache_bank[12]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 347, Reservation_fails = 2
L2_cache_bank[13]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 366, Reservation_fails = 1
L2_cache_bank[14]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 413, Reservation_fails = 30
L2_cache_bank[15]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 401, Reservation_fails = 72
L2_total_cache_accesses = 270556
L2_total_cache_misses = 15194
L2_total_cache_miss_rate = 0.0562
L2_total_cache_pending_hits = 3561
L2_total_cache_reservation_fails = 182
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 251689
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 3464
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 6991
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 3464
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 19
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 1
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 19
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 8192
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 182
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 112
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 78
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 10
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 78
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 262144
	L2_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 20
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 8192
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 200
L2_total_cache_reservation_fail_breakdown:
	L2_cache_stats_fail_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 182
L2_cache_data_port_util = 0.120
L2_cache_fill_port_util = 0.007

icnt_total_pkts_mem_to_simt=1319972
icnt_total_pkts_simt_to_mem=303324
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 24.1732
	minimum = 6
	maximum = 3302
Network latency average = 17.5394
	minimum = 6
	maximum = 2073
Slowest packet = 346
Flit latency average = 10.4367
	minimum = 6
	maximum = 2073
Slowest flit = 845
Fragmentation average = 0.00484003
	minimum = 0
	maximum = 423
Injected packet rate average = 0.0112079
	minimum = 0 (at node 36)
	maximum = 0.0175396 (at node 20)
Accepted packet rate average = 0.0112079
	minimum = 0 (at node 36)
	maximum = 0.0175396 (at node 20)
Injected flit rate average = 0.0336229
	minimum = 0 (at node 36)
	maximum = 0.0855354 (at node 20)
Accepted flit rate average= 0.0336229
	minimum = 0 (at node 36)
	maximum = 0.0694177 (at node 0)
Injected packet length average = 2.99993
Accepted packet length average = 2.99993
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 24.1732 (1 samples)
	minimum = 6 (1 samples)
	maximum = 3302 (1 samples)
Network latency average = 17.5394 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2073 (1 samples)
Flit latency average = 10.4367 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2073 (1 samples)
Fragmentation average = 0.00484003 (1 samples)
	minimum = 0 (1 samples)
	maximum = 423 (1 samples)
Injected packet rate average = 0.0112079 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0175396 (1 samples)
Accepted packet rate average = 0.0112079 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0175396 (1 samples)
Injected flit rate average = 0.0336229 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0855354 (1 samples)
Accepted flit rate average = 0.0336229 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0694177 (1 samples)
Injected packet size average = 2.99993 (1 samples)
Accepted packet size average = 2.99993 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 16 min, 6 sec (966 sec)
gpgpu_simulation_rate = 497693 (inst/sec)
gpgpu_simulation_rate = 542 (cycle/sec)
gpgpu_silicon_slowdown = 2964944x
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
The GPU Elapsed Time:966.049288 Sec.
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
The CPU Elapsed Time:0.671033 Sec.
Verifying
PASS
GPGPU-Sim: *** exit detected ***
