GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded


        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim PTX: overriding embedded ptx with ptx file (PTX_SIM_USE_PTX_FILE is set)
GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:1607.0:1607.0:2500.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:1607000000.000000:1607000000.000000:2500000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000062227753578:0.00000000062227753578:0.00000000040000000000
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
616438172cde9ba5cbeaa83fe1b352fe  /benchrun/accelsim-ptx/sm6_gtx1080/cuda4-matrixmul/input-512/matrixMul
Extracting PTX file and ptxas options    1: matrixMul.1.sm_30.ptx -arch=sm_30
GPGPU-Sim uArch: performance model initialization complete.
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/cuda4-matrixmul/input-512/matrixMul
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/cuda4-matrixmul/input-512/matrixMul
10.1
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=default
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/cuda4-matrixmul/input-512/matrixMul
Running md5sum using "md5sum /benchrun/accelsim-ptx/sm6_gtx1080/cuda4-matrixmul/input-512/matrixMul "
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/cuda4-matrixmul/input-512/matrixMul
Extracting specific PTX file named matrixMul.1.sm_30.ptx 
GPGPU-Sim PTX: __cudaRegisterFunction _Z8mult_gpuPfS_S_ii : hostFun 0x0x5636fbe017d7, fat_cubin_handle = 1
GPGPU-Sim PTX: Parsing matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: allocating shared region for "_ZZ8mult_gpuPfS_S_iiE2As" from 0x0 to 0x1000 (shared memory space)
GPGPU-Sim PTX: allocating shared region for "_ZZ8mult_gpuPfS_S_iiE2Bs" from 0x1000 to 0x2000 (shared memory space)
GPGPU-Sim PTX: instruction assembly for function '_Z8mult_gpuPfS_S_ii'...   done.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
GPGPU-Sim PTX: Loading PTXInfo from matrixMul.1.sm_30.ptx
GPGPU-Sim PTX: Kernel '_Z8mult_gpuPfS_S_ii' : regs=29, lmem=0, smem=8192, cmem=352
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
grid: (16,16,1)
threads: (32,32,1)
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7fff78776a88..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7fff78776a80..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7fff78776a78..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7fff78776a74..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7fff78776a70..

GPGPU-Sim PTX: cudaLaunch for 0x0x5636fbe017d7 (mode=performance simulation) on stream 0
GPGPU-Sim PTX: finding reconvergence points for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding dominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding postdominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z8mult_gpuPfS_S_ii'...
GPGPU-Sim PTX: reconvergence points for _Z8mult_gpuPfS_S_ii...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x068 (matrixMul.1.sm_30.ptx:47) @%p1 bra BB0_3;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x480 (matrixMul.1.sm_30.ptx:183) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX:  2 (potential) branch divergence @  PC=0x478 (matrixMul.1.sm_30.ptx:180) @%p2 bra BB0_2;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x480 (matrixMul.1.sm_30.ptx:183) mov.u32 %r31, %ctaid.x;
GPGPU-Sim PTX: ... end of reconvergence points for _Z8mult_gpuPfS_S_ii
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z8mult_gpuPfS_S_ii'.
GPGPU-Sim PTX: pushing kernel '_Z8mult_gpuPfS_S_ii' to stream 0, gridDim= (16,16,1) blockDim = (32,32,1) 
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads shmem regs
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 16 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 17 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 18 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: Shader 19 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
Destroy streams for kernel 1: size 0
kernel_name = _Z8mult_gpuPfS_S_ii 
kernel_launch_uid = 1 
gpu_sim_cycle = 542307
gpu_sim_insn = 480772096
gpu_ipc =     886.5312
gpu_tot_sim_cycle = 542307
gpu_tot_sim_insn = 480772096
gpu_tot_ipc =     886.5312
gpu_tot_issued_cta = 256
gpu_occupancy = 96.1779% 
gpu_tot_occupancy = 96.1779% 
max_total_param_size = 0
gpu_stall_dramfull = 474589
gpu_stall_icnt2sh    = 1024294
partiton_level_parallism =       0.4989
partiton_level_parallism_total  =       0.4989
partiton_level_parallism_util =       1.2536
partiton_level_parallism_util_total  =       1.2536
L2_BW  =      25.6553 GB/Sec
L2_BW_total  =      25.6553 GB/Sec
gpu_total_sim_rate=546953

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 7643136
	L1I_total_cache_misses = 6122
	L1I_total_cache_miss_rate = 0.0008
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 6041
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 40960
	L1C_total_cache_misses = 1280
	L1C_total_cache_miss_rate = 0.0312
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 3780
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 39680
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 1280
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 3780
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 1260
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 7637014
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 6122
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 6041
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 5922
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 40960
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 7643136

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[CONST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 3780
	Total_core_cache_fail_stats_breakdown[INST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 6041
ctas_completed 256, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
distro:
13374, 13314, 13295, 13287, 13256, 13229, 13216, 13189, 13172, 13138, 13191, 13149, 13226, 13238, 13235, 13267, 13193, 13206, 13162, 13152, 13162, 13191, 13202, 13210, 13261, 13266, 13316, 13318, 13354, 13330, 13454, 13435, 11435, 11457, 11396, 11405, 11347, 11345, 11309, 11322, 11280, 11272, 11291, 11297, 11370, 11331, 11349, 11338, 11314, 11305, 11318, 11276, 11302, 11301, 11321, 11327, 11347, 11386, 11401, 11399, 11411, 11403, 11461, 11501, 
gpgpu_n_tot_thrd_icount = 481296384
gpgpu_n_tot_w_icount = 15040512
gpgpu_n_stall_shd_mem = 316530
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 262144
gpgpu_n_mem_write_global = 8192
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 20
gpgpu_n_load_insn  = 8388608
gpgpu_n_store_insn = 262144
gpgpu_n_shmem_insn = 276824064
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 1310720
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 3780
gpgpu_stall_shd_mem[c_mem][resource_stall] = 3780
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 0
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:5255560	W0_Idle:64083	W0_Scoreboard:1304811	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:15040512
single_issue_nums: WS0:7059756	WS1:7060848	
dual_issue_nums: WS0:230250	WS1:229704	
traffic_breakdown_coretomem[CONST_ACC_R] = 160 {8:20,}
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 2097152 {8:262144,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 1114112 {136:8192,}
traffic_breakdown_coretomem[INST_ACC_R] = 1600 {8:200,}
traffic_breakdown_memtocore[CONST_ACC_R] = 1440 {72:20,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 35651584 {136:262144,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 65536 {8:8192,}
traffic_breakdown_memtocore[INST_ACC_R] = 27200 {136:200,}
maxmflatency = 2855 
max_icnt2mem_latency = 2637 
maxmrqlatency = 763 
max_icnt2sh_latency = 78 
averagemflatency = 260 
avg_icnt2mem_latency = 49 
avg_mrq_latency = 149 
avg_icnt2sh_latency = 23 
mrq_lat_table:1582 	195 	340 	916 	3463 	3368 	2870 	4720 	5616 	313 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	187504 	61482 	18800 	1621 	949 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	0 	201411 	29423 	9609 	7410 	10454 	8163 	2013 	1341 	732 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	0 	52176 	178162 	37782 	2236 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	705 	347 	11 	13 	6 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[5]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[6]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[7]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     80881     70485     80598     70500     79026     79798     78196     79736     98381     81212    104783    101551     82319     79628     81708     79648 
dram[1]:     63659     71985     63697     72011     91861    100987     91853    101790     90591    102772    102728    104165     92584    101316     92561    102477 
dram[2]:     83519     86778     83470     86748    102298    103885    102739    104020     84938     85472    101837     85479    143688    105607    143979    105667 
dram[3]:     89119     91113     89099     91066     99035     94709     99134     94805     88666     92308     88597     92265    108830    111956    108895    111981 
dram[4]:     95002     96675     94998     96672     95931     97864     96030     97961     92385     94487     92371     94473    115267    118503    115334    118614 
dram[5]:     99622    103728     99612    103732    100158    100521    100254    100520     95105    100030     95070     99987    121875    125150    121971    125247 
dram[6]:    104813    108886    104779    108871    104104    107225    104107    107223    103571    103861    103561    103854    128372    131461    128435    131535 
dram[7]:    109807    113786    109776    113800    110660    114009    110626    113975    107655    109983    107655    109985    134598    137789    134661    137852 
average row accesses per activate:
dram[0]: 17.900000 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 22.125000 22.125000 25.142857 25.142857 23.625000 24.000000 24.000000 24.000000 
dram[1]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 22.125000 22.125000 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 
dram[2]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 22.125000 24.000000 25.142857 24.000000 25.142857 24.000000 25.142857 24.000000 
dram[3]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[4]: 19.777779 19.777779 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[5]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[6]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
dram[7]: 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 25.142857 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 24.000000 
average row locality = 23383/974 = 24.007187
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       460       456       448       448       448       448       448       448       452       452       448       448       500       512       512       512 
dram[1]:       456       456       448       448       448       448       448       448       452       452       448       448       512       512       512       512 
dram[2]:       456       456       448       448       448       448       448       448       452       512       448       512       448       512       448       512 
dram[3]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[4]:       456       456       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[5]:       448       448       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[6]:       448       448       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
dram[7]:       448       448       448       448       448       448       448       448       512       512       512       512       512       512       512       512 
total dram reads = 60764
bank skew: 512/448 = 1.14
chip skew: 7696/7440 = 1.03
number of total write accesses:
dram[0]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[1]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[2]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[3]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[4]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[5]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[6]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[7]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
total dram writes = 32768
bank skew: 256/256 = 1.00
chip skew: 4096/4096 = 1.00
average mf latency per bank:
dram[0]:       1127      1056      1685      1430      1228      1012      1463      1174       896       736      1042       851       570       793       681       935
dram[1]:        920       900      1162      1087       779       820       952       926       790       783       945       917       655       694       771       808
dram[2]:        942       648      1108       742       804       667       934       746       802       597      1011       679       726       543       893       599
dram[3]:        694       742       791       835       649       660       730       741       619       568       691       678       527       622       607       709
dram[4]:        671       691       815       814       661       700       760       799       594       580       722       677       591       565       716       650
dram[5]:        689       681       764       775       597       633       695       733       617       606       727       719       603       600       707       719
dram[6]:        699       669       792       764       610       608       709       675       555       574       656       655       578       586       695       687
dram[7]:        650       705       727       794       596       650       665       749       573       626       665       738       550       618       664       728
maximum mf latency per bank:
dram[0]:       2849      2443      2855      2523      2837      2322      2825      2495      2765      1421      2851      1122       871      1042       888      1178
dram[1]:       2280      2278      2306      2306      1986      1751      1876      1127      1517      1327      1073      1180      1031      1127      1016      1148
dram[2]:       2278      2278      2306      2306      1514      1817       883       972       910       826       923       807      1113       683      1016       887
dram[3]:       2278      2278      2306      2298      1788      1791      1090      1047      1242       734      1046       854       896       797       851       854
dram[4]:       1903      1903      2306      2306      1786      1778       752       840       685       742       733       936       932       906       947       866
dram[5]:       1903      1903      2306      1903      1778      1786       651       728       760       735      1067       743       773       895      1016       980
dram[6]:       1903      2278      2282      2282      1753      1767       895       729      1218      1457       823       760       659       754       769       762
dram[7]:       2278      2278      2282      2286      1689      1786       621       820      1015      1456      1036      1057       772       827       711       810
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=843663 n_nop=831898 n_act=123 n_pre=107 n_ref_event=0 n_req=2884 n_rd=3344 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02735
n_activity=37805 dram_eff=0.6103
bk0: 460a 839019i bk1: 456a 839510i bk2: 448a 839089i bk3: 448a 839307i bk4: 448a 840017i bk5: 448a 839788i bk6: 448a 839323i bk7: 448a 839851i bk8: 452a 840322i bk9: 452a 839860i bk10: 448a 840109i bk11: 448a 839973i bk12: 500a 839928i bk13: 512a 839743i bk14: 512a 839735i bk15: 512a 839839i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957351
Row_Buffer_Locality_read = 0.968280
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.920944
Bank_Level_Parallism_Col = 1.924007
Bank_Level_Parallism_Ready = 1.472658
write_to_read_ratio_blp_rw_average = 0.405303
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027347 
total_CMD = 843663 
util_bw = 23072 
Wasted_Col = 10830 
Wasted_Row = 730 
Idle = 809031 

BW Util Bottlenecks: 
RCDc_limit = 551 
RCDWRc_limit = 287 
WTRc_limit = 9410 
RTWc_limit = 9760 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9410 
RTWc_limit_alone = 9760 

Commands details: 
total_CMD = 843663 
n_nop = 831898 
Read = 3344 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 123 
n_pre = 107 
n_ref = 0 
n_req = 2884 
total_req = 11536 

Dual Bus Interface Util: 
issued_total_row = 230 
issued_total_col = 11536 
Row_Bus_Util =  0.000273 
CoL_Bus_Util = 0.013674 
Either_Row_CoL_Bus_Util = 0.013945 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000085 
queue_avg = 0.863847 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.863847
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=843663 n_nop=831892 n_act=122 n_pre=106 n_ref_event=0 n_req=2886 n_rd=3352 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02737
n_activity=37094 dram_eff=0.6224
bk0: 456a 840276i bk1: 456a 840287i bk2: 448a 840303i bk3: 448a 840370i bk4: 448a 840332i bk5: 448a 840452i bk6: 448a 840321i bk7: 448a 840404i bk8: 452a 839732i bk9: 452a 839884i bk10: 448a 839699i bk11: 448a 839798i bk12: 512a 840041i bk13: 512a 839913i bk14: 512a 839934i bk15: 512a 839873i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957727
Row_Buffer_Locality_read = 0.968851
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.672571
Bank_Level_Parallism_Col = 1.666457
Bank_Level_Parallism_Ready = 1.342543
write_to_read_ratio_blp_rw_average = 0.405119
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027366 
total_CMD = 843663 
util_bw = 23088 
Wasted_Col = 12079 
Wasted_Row = 654 
Idle = 807842 

BW Util Bottlenecks: 
RCDc_limit = 474 
RCDWRc_limit = 305 
WTRc_limit = 9311 
RTWc_limit = 9677 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9311 
RTWc_limit_alone = 9677 

Commands details: 
total_CMD = 843663 
n_nop = 831892 
Read = 3352 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 122 
n_pre = 106 
n_ref = 0 
n_req = 2886 
total_req = 11544 

Dual Bus Interface Util: 
issued_total_row = 228 
issued_total_col = 11544 
Row_Bus_Util =  0.000270 
CoL_Bus_Util = 0.013683 
Either_Row_CoL_Bus_Util = 0.013952 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000085 
queue_avg = 0.768178 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.768178
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=843663 n_nop=831899 n_act=121 n_pre=105 n_ref_event=0 n_req=2885 n_rd=3348 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02736
n_activity=36400 dram_eff=0.6341
bk0: 456a 840054i bk1: 456a 840060i bk2: 448a 839973i bk3: 448a 839929i bk4: 448a 840558i bk5: 448a 840117i bk6: 448a 840443i bk7: 448a 840066i bk8: 452a 839921i bk9: 512a 839679i bk10: 448a 839830i bk11: 512a 839520i bk12: 448a 840275i bk13: 512a 840170i bk14: 448a 840316i bk15: 512a 839691i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.958059
Row_Buffer_Locality_read = 0.969371
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.712427
Bank_Level_Parallism_Col = 1.701205
Bank_Level_Parallism_Ready = 1.347280
write_to_read_ratio_blp_rw_average = 0.412337
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027357 
total_CMD = 843663 
util_bw = 23080 
Wasted_Col = 11907 
Wasted_Row = 541 
Idle = 808135 

BW Util Bottlenecks: 
RCDc_limit = 427 
RCDWRc_limit = 284 
WTRc_limit = 9272 
RTWc_limit = 9720 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9272 
RTWc_limit_alone = 9720 

Commands details: 
total_CMD = 843663 
n_nop = 831899 
Read = 3348 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 121 
n_pre = 105 
n_ref = 0 
n_req = 2885 
total_req = 11540 

Dual Bus Interface Util: 
issued_total_row = 226 
issued_total_col = 11540 
Row_Bus_Util =  0.000268 
CoL_Bus_Util = 0.013678 
Either_Row_CoL_Bus_Util = 0.013944 
Issued_on_Two_Bus_Simul_Util = 0.000002 
issued_two_Eff = 0.000170 
queue_avg = 0.779090 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.77909
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=843663 n_nop=831640 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02795
n_activity=36543 dram_eff=0.6454
bk0: 456a 840055i bk1: 456a 839710i bk2: 448a 839780i bk3: 448a 839699i bk4: 448a 839964i bk5: 448a 840227i bk6: 448a 839965i bk7: 448a 840198i bk8: 512a 840055i bk9: 512a 840110i bk10: 512a 839920i bk11: 512a 839982i bk12: 512a 839884i bk13: 512a 839904i bk14: 512a 839851i bk15: 512a 839654i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.744116
Bank_Level_Parallism_Col = 1.733728
Bank_Level_Parallism_Ready = 1.357131
write_to_read_ratio_blp_rw_average = 0.407964
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027954 
total_CMD = 843663 
util_bw = 23584 
Wasted_Col = 11691 
Wasted_Row = 565 
Idle = 807823 

BW Util Bottlenecks: 
RCDc_limit = 409 
RCDWRc_limit = 309 
WTRc_limit = 9361 
RTWc_limit = 9788 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9361 
RTWc_limit_alone = 9788 

Commands details: 
total_CMD = 843663 
n_nop = 831640 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000275 
CoL_Bus_Util = 0.013977 
Either_Row_CoL_Bus_Util = 0.014251 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000083 
queue_avg = 0.826766 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.826766
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=843663 n_nop=831640 n_act=124 n_pre=108 n_ref_event=0 n_req=2948 n_rd=3600 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02795
n_activity=36801 dram_eff=0.6409
bk0: 456a 839853i bk1: 456a 839607i bk2: 448a 839638i bk3: 448a 839745i bk4: 448a 840369i bk5: 448a 840345i bk6: 448a 840342i bk7: 448a 840323i bk8: 512a 840231i bk9: 512a 840205i bk10: 512a 840223i bk11: 512a 840203i bk12: 512a 839915i bk13: 512a 839703i bk14: 512a 839611i bk15: 512a 839725i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.957938
Row_Buffer_Locality_read = 0.968815
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.709220
Bank_Level_Parallism_Col = 1.701222
Bank_Level_Parallism_Ready = 1.354817
write_to_read_ratio_blp_rw_average = 0.396985
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027954 
total_CMD = 843663 
util_bw = 23584 
Wasted_Col = 11751 
Wasted_Row = 622 
Idle = 807706 

BW Util Bottlenecks: 
RCDc_limit = 482 
RCDWRc_limit = 305 
WTRc_limit = 9337 
RTWc_limit = 9663 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9337 
RTWc_limit_alone = 9663 

Commands details: 
total_CMD = 843663 
n_nop = 831640 
Read = 3600 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 124 
n_pre = 108 
n_ref = 0 
n_req = 2948 
total_req = 11792 

Dual Bus Interface Util: 
issued_total_row = 232 
issued_total_col = 11792 
Row_Bus_Util =  0.000275 
CoL_Bus_Util = 0.013977 
Either_Row_CoL_Bus_Util = 0.014251 
Issued_on_Two_Bus_Simul_Util = 0.000001 
issued_two_Eff = 0.000083 
queue_avg = 0.799685 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.799685
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=843663 n_nop=831663 n_act=120 n_pre=104 n_ref_event=0 n_req=2944 n_rd=3584 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02792
n_activity=37014 dram_eff=0.6363
bk0: 448a 840225i bk1: 448a 840023i bk2: 448a 840092i bk3: 448a 840134i bk4: 448a 840370i bk5: 448a 840376i bk6: 448a 840343i bk7: 448a 840381i bk8: 512a 840202i bk9: 512a 840231i bk10: 512a 840103i bk11: 512a 840129i bk12: 512a 840011i bk13: 512a 839702i bk14: 512a 839671i bk15: 512a 839780i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959239
Row_Buffer_Locality_read = 0.970833
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.652675
Bank_Level_Parallism_Col = 1.643644
Bank_Level_Parallism_Ready = 1.322945
write_to_read_ratio_blp_rw_average = 0.400787
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027916 
total_CMD = 843663 
util_bw = 23552 
Wasted_Col = 11989 
Wasted_Row = 600 
Idle = 807522 

BW Util Bottlenecks: 
RCDc_limit = 371 
RCDWRc_limit = 296 
WTRc_limit = 9274 
RTWc_limit = 9684 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9274 
RTWc_limit_alone = 9684 

Commands details: 
total_CMD = 843663 
n_nop = 831663 
Read = 3584 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 120 
n_pre = 104 
n_ref = 0 
n_req = 2944 
total_req = 11776 

Dual Bus Interface Util: 
issued_total_row = 224 
issued_total_col = 11776 
Row_Bus_Util =  0.000266 
CoL_Bus_Util = 0.013958 
Either_Row_CoL_Bus_Util = 0.014224 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.782647 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.782647
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=843663 n_nop=831663 n_act=120 n_pre=104 n_ref_event=0 n_req=2944 n_rd=3584 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02792
n_activity=37229 dram_eff=0.6326
bk0: 448a 840306i bk1: 448a 840350i bk2: 448a 840290i bk3: 448a 840313i bk4: 448a 840189i bk5: 448a 840334i bk6: 448a 840276i bk7: 448a 840168i bk8: 512a 840205i bk9: 512a 840203i bk10: 512a 840151i bk11: 512a 840125i bk12: 512a 840184i bk13: 512a 840059i bk14: 512a 839991i bk15: 512a 840110i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959239
Row_Buffer_Locality_read = 0.970833
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.596746
Bank_Level_Parallism_Col = 1.587894
Bank_Level_Parallism_Ready = 1.289208
write_to_read_ratio_blp_rw_average = 0.401705
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027916 
total_CMD = 843663 
util_bw = 23552 
Wasted_Col = 12296 
Wasted_Row = 619 
Idle = 807196 

BW Util Bottlenecks: 
RCDc_limit = 402 
RCDWRc_limit = 295 
WTRc_limit = 9286 
RTWc_limit = 9653 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9286 
RTWc_limit_alone = 9653 

Commands details: 
total_CMD = 843663 
n_nop = 831663 
Read = 3584 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 120 
n_pre = 104 
n_ref = 0 
n_req = 2944 
total_req = 11776 

Dual Bus Interface Util: 
issued_total_row = 224 
issued_total_col = 11776 
Row_Bus_Util =  0.000266 
CoL_Bus_Util = 0.013958 
Either_Row_CoL_Bus_Util = 0.014224 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.758664 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=53 avg=0.758664
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents
MSHR: tag=0xc02fff00, atomic=0 1 entries : 0x7f8cae9f2f30 :  mf: uid=7972445, sid00:w31, part=7, addr=0xc02fff00, load , size=128, unknown  status = IN_PARTITION_DRAM (542305), 

Cache L2_bank_015:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=843663 n_nop=831665 n_act=120 n_pre=104 n_ref_event=0 n_req=2944 n_rd=3584 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.02792
n_activity=36725 dram_eff=0.6413
bk0: 448a 839885i bk1: 448a 840064i bk2: 448a 839982i bk3: 448a 839952i bk4: 448a 840338i bk5: 448a 840197i bk6: 448a 840294i bk7: 448a 840153i bk8: 512a 839598i bk9: 512a 839570i bk10: 512a 839472i bk11: 512a 839834i bk12: 512a 839993i bk13: 512a 839970i bk14: 512a 840015i bk15: 512a 839630i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.959239
Row_Buffer_Locality_read = 0.970833
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.731796
Bank_Level_Parallism_Col = 1.723520
Bank_Level_Parallism_Ready = 1.351872
write_to_read_ratio_blp_rw_average = 0.413978
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.027916 
total_CMD = 843663 
util_bw = 23552 
Wasted_Col = 11968 
Wasted_Row = 584 
Idle = 807559 

BW Util Bottlenecks: 
RCDc_limit = 377 
RCDWRc_limit = 276 
WTRc_limit = 9330 
RTWc_limit = 9738 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9330 
RTWc_limit_alone = 9738 

Commands details: 
total_CMD = 843663 
n_nop = 831665 
Read = 3584 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 120 
n_pre = 104 
n_ref = 0 
n_req = 2944 
total_req = 11776 

Dual Bus Interface Util: 
issued_total_row = 224 
issued_total_col = 11776 
Row_Bus_Util =  0.000266 
CoL_Bus_Util = 0.013958 
Either_Row_CoL_Bus_Util = 0.014221 
Issued_on_Two_Bus_Simul_Util = 0.000002 
issued_two_Eff = 0.000167 
queue_avg = 0.834511 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.834511

========= L2 cache stats =========
L2_cache_bank[0]: Access = 16936, Miss = 929, Miss_rate = 0.055, Pending_hits = 146, Reservation_fails = 11
L2_cache_bank[1]: Access = 16916, Miss = 931, Miss_rate = 0.055, Pending_hits = 65, Reservation_fails = 3
L2_cache_bank[2]: Access = 16916, Miss = 931, Miss_rate = 0.055, Pending_hits = 43, Reservation_fails = 0
L2_cache_bank[3]: Access = 16916, Miss = 931, Miss_rate = 0.055, Pending_hits = 4, Reservation_fails = 1
L2_cache_bank[4]: Access = 16916, Miss = 899, Miss_rate = 0.053, Pending_hits = 76, Reservation_fails = 4
L2_cache_bank[5]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 10, Reservation_fails = 10
L2_cache_bank[6]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 46, Reservation_fails = 4
L2_cache_bank[7]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 59, Reservation_fails = 1
L2_cache_bank[8]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 62, Reservation_fails = 3
L2_cache_bank[9]: Access = 16916, Miss = 962, Miss_rate = 0.057, Pending_hits = 66, Reservation_fails = 0
L2_cache_bank[10]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 96, Reservation_fails = 5
L2_cache_bank[11]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 12, Reservation_fails = 0
L2_cache_bank[12]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 4, Reservation_fails = 2
L2_cache_bank[13]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 20, Reservation_fails = 0
L2_cache_bank[14]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 10, Reservation_fails = 6
L2_cache_bank[15]: Access = 16896, Miss = 960, Miss_rate = 0.057, Pending_hits = 70, Reservation_fails = 2
L2_total_cache_accesses = 270556
L2_total_cache_misses = 15191
L2_total_cache_miss_rate = 0.0561
L2_total_cache_pending_hits = 789
L2_total_cache_reservation_fails = 52
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 254463
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 693
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 6988
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 693
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 19
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 1
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 19
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 8192
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 52
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 113
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 77
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 10
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 77
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 262144
	L2_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 20
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 8192
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 200
L2_total_cache_reservation_fail_breakdown:
	L2_cache_stats_fail_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 52
L2_cache_data_port_util = 0.117
L2_cache_fill_port_util = 0.007

icnt_total_pkts_mem_to_simt=1319972
icnt_total_pkts_simt_to_mem=303324
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 27.9882
	minimum = 6
	maximum = 2598
Network latency average = 19.9616
	minimum = 6
	maximum = 1120
Slowest packet = 185
Flit latency average = 13.8388
	minimum = 6
	maximum = 1120
Slowest flit = 3224
Fragmentation average = 0.00457391
	minimum = 0
	maximum = 693
Injected packet rate average = 0.0199559
	minimum = 0 (at node 36)
	maximum = 0.0312295 (at node 20)
Accepted packet rate average = 0.0199559
	minimum = 0 (at node 36)
	maximum = 0.0312295 (at node 20)
Injected flit rate average = 0.0598663
	minimum = 0 (at node 36)
	maximum = 0.152297 (at node 20)
Accepted flit rate average= 0.0598663
	minimum = 0 (at node 36)
	maximum = 0.1236 (at node 0)
Injected packet length average = 2.99993
Accepted packet length average = 2.99993
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 27.9882 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2598 (1 samples)
Network latency average = 19.9616 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1120 (1 samples)
Flit latency average = 13.8388 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1120 (1 samples)
Fragmentation average = 0.00457391 (1 samples)
	minimum = 0 (1 samples)
	maximum = 693 (1 samples)
Injected packet rate average = 0.0199559 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0312295 (1 samples)
Accepted packet rate average = 0.0199559 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0312295 (1 samples)
Injected flit rate average = 0.0598663 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.152297 (1 samples)
Accepted flit rate average = 0.0598663 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.1236 (1 samples)
Injected packet size average = 2.99993 (1 samples)
Accepted packet size average = 2.99993 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 14 min, 39 sec (879 sec)
gpgpu_simulation_rate = 546953 (inst/sec)
gpgpu_simulation_rate = 616 (cycle/sec)
gpgpu_silicon_slowdown = 2608766x
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
The GPU Elapsed Time:879.420048 Sec.
GPGPU-Sim: synchronize waiting for inactive GPU simulation
GPGPU-Sim API: Stream Manager State
GPGPU-Sim: detected inactive GPU simulation thread
The CPU Elapsed Time:0.603060 Sec.
Verifying
PASS
GPGPU-Sim: *** exit detected ***
