GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded


        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim PTX: overriding embedded ptx with ptx file (PTX_SIM_USE_PTX_FILE is set)
GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:1607.0:1607.0:2500.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:1607000000.000000:1607000000.000000:2500000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000062227753578:0.00000000062227753578:0.00000000040000000000
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
ec99c02438e2d0de1d653ac8c90f6187  /benchrun/accelsim-ptx/sm6_gtx1080/vectoradd/input-1000000/vectorAdd
Extracting PTX file and ptxas options    1: vectorAdd.1.sm_30.ptx -arch=sm_30
GPGPU-Sim uArch: performance model initialization complete.
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/vectoradd/input-1000000/vectorAdd
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/vectoradd/input-1000000/vectorAdd
10.1
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=default
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/vectoradd/input-1000000/vectorAdd
Running md5sum using "md5sum /benchrun/accelsim-ptx/sm6_gtx1080/vectoradd/input-1000000/vectorAdd "
self exe links to: /benchrun/accelsim-ptx/sm6_gtx1080/vectoradd/input-1000000/vectorAdd
Extracting specific PTX file named vectorAdd.1.sm_30.ptx 
GPGPU-Sim PTX: __cudaRegisterFunction _Z6vecAddPdS_S_i : hostFun 0x0x55fdbc0015dd, fat_cubin_handle = 1
GPGPU-Sim PTX: Parsing vectorAdd.1.sm_30.ptx
GPGPU-Sim PTX: instruction assembly for function '_Z6vecAddPdS_S_i'...   done.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file vectorAdd.1.sm_30.ptx
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
GPGPU-Sim PTX: Loading PTXInfo from vectorAdd.1.sm_30.ptx
GPGPU-Sim PTX: Kernel '_Z6vecAddPdS_S_i' : regs=10, lmem=0, smem=0, cmem=348
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffca4e41488..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffca4e41480..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7ffca4e41478..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7ffca4e41474..

GPGPU-Sim PTX: cudaLaunch for 0x0x55fdbc0015dd (mode=performance simulation) on stream 0
GPGPU-Sim PTX: finding reconvergence points for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: Finding dominators for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: Finding postdominators for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: reconvergence points for _Z6vecAddPdS_S_i...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x048 (vectorAdd.1.sm_30.ptx:37) @%p1 bra BB0_2;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x0a8 (vectorAdd.1.sm_30.ptx:52) ret;
GPGPU-Sim PTX: ... end of reconvergence points for _Z6vecAddPdS_S_i
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z6vecAddPdS_S_i'.
GPGPU-Sim PTX: pushing kernel '_Z6vecAddPdS_S_i' to stream 0, gridDim= (977,1,1) blockDim = (1024,1,1) 
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 16 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 17 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 18 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 19 bind to kernel 1 '_Z6vecAddPdS_S_i'
Destroy streams for kernel 1: size 0
kernel_name = _Z6vecAddPdS_S_i 
kernel_launch_uid = 1 
gpu_sim_cycle = 175195
gpu_sim_insn = 21004928
gpu_ipc =     119.8946
gpu_tot_sim_cycle = 175195
gpu_tot_sim_insn = 21004928
gpu_tot_ipc =     119.8946
gpu_tot_issued_cta = 977
gpu_occupancy = 66.9129% 
gpu_tot_occupancy = 66.9129% 
max_total_param_size = 0
gpu_stall_dramfull = 920237
gpu_stall_icnt2sh    = 93895
partiton_level_parallism =       1.0706
partiton_level_parallism_total  =       1.0706
partiton_level_parallism_util =       2.3089
partiton_level_parallism_util_total  =       2.3089
L2_BW  =      55.0534 GB/Sec
L2_BW_total  =      55.0534 GB/Sec
gpu_total_sim_rate=143869

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 343848
	L1I_total_cache_misses = 1778
	L1I_total_cache_miss_rate = 0.0052
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 5480
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 125056
	L1C_total_cache_misses = 1280
	L1C_total_cache_miss_rate = 0.0102
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 3780
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 123776
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 1280
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 3780
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 1260
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 342070
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 1778
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 5480
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 1738
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 125056
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 343848

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[CONST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 3780
	Total_core_cache_fail_stats_breakdown[INST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 5480
ctas_completed 977, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
distro:
575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 
gpgpu_n_tot_thrd_icount = 22004928
gpgpu_n_tot_w_icount = 687654
gpgpu_n_stall_shd_mem = 3071140
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 125000
gpgpu_n_mem_write_global = 62500
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 20
gpgpu_n_load_insn  = 2000000
gpgpu_n_store_insn = 1000000
gpgpu_n_shmem_insn = 0
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 4001792
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 3780
gpgpu_stall_shd_mem[c_mem][resource_stall] = 3780
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 93750
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:5229788	W0_Idle:76011	W0_Scoreboard:1016679	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:687654
single_issue_nums: WS0:312577	WS1:312577	
dual_issue_nums: WS0:15625	WS1:15625	
traffic_breakdown_coretomem[CONST_ACC_R] = 160 {8:20,}
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 1000000 {8:125000,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 8500000 {136:62500,}
traffic_breakdown_coretomem[INST_ACC_R] = 320 {8:40,}
traffic_breakdown_memtocore[CONST_ACC_R] = 1440 {72:20,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 17000000 {136:125000,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 500000 {8:62500,}
traffic_breakdown_memtocore[INST_ACC_R] = 5440 {136:40,}
maxmflatency = 4683 
max_icnt2mem_latency = 1429 
maxmrqlatency = 3587 
max_icnt2sh_latency = 130 
averagemflatency = 1015 
avg_icnt2mem_latency = 193 
avg_mrq_latency = 333 
avg_icnt2sh_latency = 15 
mrq_lat_table:52940 	446 	2079 	4117 	9896 	16559 	25433 	34612 	45514 	39455 	17030 	1922 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	25 	24015 	91994 	60821 	10652 	13 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	0 	4436 	38260 	27585 	22939 	32897 	50208 	10820 	415 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	0 	124862 	53367 	8789 	500 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	0 	1 	194 	154 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        30        30        28        30        28        28        28        28        32        32        30        30        28        28        30        30 
dram[1]:        32        32        30        30        32        32        28        28        32        32        30        30        28        30        30        30 
dram[2]:        32        32        32        28        28        28        28        28        32        32        28        28        30        30        26        26 
dram[3]:        30        30        28        30        30        30        30        30        32        32        28        28        28        28        24        24 
dram[4]:        32        32        28        32        32        32        30        28        32        32        30        28        32        32        30        30 
dram[5]:        28        28        28        32        30        30        32        28        32        32        28        28        32        32        32        32 
dram[6]:        32        32        30        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[7]:        32        32        30        30        30        32        30        30        30        30        30        30        32        32        32        32 
maximum service time to same row:
dram[0]:      2578      2589      2430      2400      2369      2838      2746      2857      2994      2994      2930      2931      2460      2476      2800      2818 
dram[1]:      3263      3217      2696      2704      2883      2896      2599      2599      3315      3313      2577      2585      2749      2755      2756      2793 
dram[2]:      2705      2716      2585      2589      3177      3183      2244      2250      3198      3200      2400      2450      2799      2818      2214      2238 
dram[3]:      2460      2467      2821      2828      2713      2714      2461      2462      3782      3794      2438      2451      2414      2421      2503      2600 
dram[4]:      2872      2889      2887      3150      2980      3008      2622      2638      2605      2588      2565      2534      2673      2685      3074      3111 
dram[5]:      2574      2582      2657      2647      2799      2806      2886      2438      3509      3521      2702      2701      2568      2567      2921      2872 
dram[6]:      2687      2732      2694      2990      2955      2961      3335      3361      3119      3048      2877      2947      3020      3069      2694      2721 
dram[7]:      2815      2817      2565      2573      2399      3088      2593      2626      2767      2853      2664      2671      3493      3493      2740      2746 
average row accesses per activate:
dram[0]:  3.993902  4.196581  4.287582  4.432433  3.821359  4.057732  3.920319  4.082988  4.062500  4.276316  4.084388  4.199566  3.983539  4.084388  3.934959  4.181426 
dram[1]:  4.141350  4.258134  4.016326  4.178344  4.082988  4.169491  4.000000  4.196162  4.070981  4.352679  3.744681  3.879760  4.093023  4.321429  3.833663  3.951020 
dram[2]:  4.276689  4.431151  4.024540  4.169491  3.748571  3.881657  3.874016  3.936000  3.963415  4.175589  3.991753  4.163441  3.811024  3.864271  3.975359  3.959100 
dram[3]:  3.997963  4.141350  4.041068  4.287582  4.143158  4.315790  4.373333  4.392857  4.140127  4.304636  4.075789  4.199566  4.041754  4.208696  3.926978  4.101695 
dram[4]:  4.354767  4.578089  4.534562  4.835381  4.151899  4.442438  4.100000  4.278261  4.431818  4.599057  4.154506  4.292683  4.000000  4.217865  4.016598  4.302222 
dram[5]:  4.083160  4.269565  4.250540  4.462585  4.205128  4.259740  4.241379  4.325275  4.295154  4.362416  3.942974  4.016598  4.008282  4.181426  3.788650  3.942974 
dram[6]:  4.494279  4.610329  4.472727  4.871287  3.920319  4.108560  4.151899  4.325275  4.109704  4.300221  4.264317  4.653846  4.058700  4.245614  3.833663  4.024948 
dram[7]:  4.187633  4.325991  3.836257  3.975758  4.250540  4.503432  4.143158  4.334802  3.903808  4.135881  4.283186  4.380091  4.410023  4.512821  3.879760  3.975359 
average row locality = 250003/60165 = 4.155290
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:      5896      5892      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[1]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[2]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[3]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[4]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[5]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[6]:      5888      5888      5888      5888      5888      5888      5888      5888      5848      5848      5824      5824      5824      5824      5824      5824 
dram[7]:      5888      5888      5888      5888      5888      5888      5888      5888      5848      5848      5824      5824      5824      5824      5824      5824 
total dram reads = 750012
bank skew: 5896/5824 = 1.01
chip skew: 93764/93744 = 1.00
number of total write accesses:
dram[0]:      1964      1964      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[1]:      1964      1964      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[2]:      1964      1964      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[3]:      1964      1964      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[4]:      1968      1968      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[5]:      1968      1968      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[6]:      1968      1968      1984      1984      1984      1984      1984      1984      1944      1944      1920      1920      1920      1920      1920      1920 
dram[7]:      1968      1968      1984      1984      1984      1984      1984      1984      1944      1944      1920      1920      1920      1920      1920      1920 
total dram writes = 250000
bank skew: 1984/1920 = 1.03
chip skew: 31256/31248 = 1.00
average mf latency per bank:
dram[0]:        160       168       161       170       148       158       154       166       160       170       157       165       150       158       153       164
dram[1]:        179       188       176       187       176       185       175       185       173       183       172       178       179       188       175       184
dram[2]:        158       168       153       159       147       154       151       157       152       161       156       163       148       153       159       166
dram[3]:        152       161       157       170       152       161       158       165       154       164       155       163       149       158       155       165
dram[4]:        214       226       213       227       206       216       206       215       209       220       205       216       206       217       214       228
dram[5]:        190       199       202       211       195       204       198       205       188       197       193       201       190       200       196       203
dram[6]:        228       236       234       244       215       222       233       241       220       228       229       240       220       225       224       232
dram[7]:        211       220       207       217       213       226       219       228       208       217       223       232       226       235       219       226
maximum mf latency per bank:
dram[0]:       3111      3185      4272      4363      2938      3436      2890      3101      3479      3666      3579      3603      3045      3221      3300      3416
dram[1]:       3477      3468      3506      3516      3057      3518      3074      3126      3351      3331      3299      3381      3604      3616      3543      3588
dram[2]:       3733      3582      3496      3320      3513      3549      2882      2909      3264      3290      3842      3869      3284      3377      2842      3139
dram[3]:       3112      3129      3401      3550      3137      3193      2969      3082      2852      3053      3232      3255      2747      2819      2726      2999
dram[4]:       3856      4074      4683      4166      3831      3890      3446      3502      3505      3517      3151      3619      3646      3722      4348      4358
dram[5]:       3510      3785      3466      3480      3758      3830      4051      3351      3502      3509      3626      3724      3552      3588      3473      3404
dram[6]:       3820      3838      3546      3765      3448      3573      4108      4208      3626      3918      3644      3727      3670      3489      3696      3734
dram[7]:       3924      3945      3419      3459      3190      3868      3563      3593      3189      3245      3502      3534      4262      4324      3373      3429
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272549 n_nop=135017 n_act=7633 n_pre=7617 n_ref_event=0 n_req=31253 n_rd=62516 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9174
n_activity=270339 dram_eff=0.9249
bk0: 5896a 97934i bk1: 5892a 91257i bk2: 5888a 101314i bk3: 5888a 96964i bk4: 5888a 100556i bk5: 5888a 94044i bk6: 5888a 99184i bk7: 5888a 93888i bk8: 5852a 99734i bk9: 5852a 93542i bk10: 5824a 101210i bk11: 5824a 95324i bk12: 5824a 100731i bk13: 5824a 93095i bk14: 5824a 100959i bk15: 5824a 94539i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.755767
Row_Buffer_Locality_read = 0.766179
Row_Buffer_Locality_write = 0.724526
Bank_Level_Parallism = 10.505088
Bank_Level_Parallism_Col = 10.061733
Bank_Level_Parallism_Ready = 5.157573
write_to_read_ratio_blp_rw_average = 0.481633
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.917354 
total_CMD = 272549 
util_bw = 250024 
Wasted_Col = 20159 
Wasted_Row = 63 
Idle = 2303 

BW Util Bottlenecks: 
RCDc_limit = 3833 
RCDWRc_limit = 1306 
WTRc_limit = 89361 
RTWc_limit = 86509 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 89361 
RTWc_limit_alone = 86509 

Commands details: 
total_CMD = 272549 
n_nop = 135017 
Read = 62516 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7633 
n_pre = 7617 
n_ref = 0 
n_req = 31253 
total_req = 125012 

Dual Bus Interface Util: 
issued_total_row = 15250 
issued_total_col = 125012 
Row_Bus_Util =  0.055953 
CoL_Bus_Util = 0.458677 
Either_Row_CoL_Bus_Util = 0.504614 
Issued_on_Two_Bus_Simul_Util = 0.010017 
issued_two_Eff = 0.019850 
queue_avg = 56.811241 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=56.8112
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272549 n_nop=135025 n_act=7670 n_pre=7654 n_ref_event=0 n_req=31250 n_rd=62504 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9173
n_activity=269988 dram_eff=0.926
bk0: 5888a 96821i bk1: 5888a 90120i bk2: 5888a 96289i bk3: 5888a 88580i bk4: 5888a 95377i bk5: 5888a 88838i bk6: 5888a 96658i bk7: 5888a 90209i bk8: 5852a 96336i bk9: 5852a 90626i bk10: 5824a 96014i bk11: 5824a 90489i bk12: 5824a 100358i bk13: 5824a 94101i bk14: 5824a 98090i bk15: 5824a 91877i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.754560
Row_Buffer_Locality_read = 0.762352
Row_Buffer_Locality_write = 0.731183
Bank_Level_Parallism = 10.715886
Bank_Level_Parallism_Col = 10.257485
Bank_Level_Parallism_Ready = 5.196635
write_to_read_ratio_blp_rw_average = 0.488971
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.917266 
total_CMD = 272549 
util_bw = 250000 
Wasted_Col = 19923 
Wasted_Row = 15 
Idle = 2611 

BW Util Bottlenecks: 
RCDc_limit = 3749 
RCDWRc_limit = 1136 
WTRc_limit = 89731 
RTWc_limit = 88273 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 89731 
RTWc_limit_alone = 88273 

Commands details: 
total_CMD = 272549 
n_nop = 135025 
Read = 62504 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7670 
n_pre = 7654 
n_ref = 0 
n_req = 31250 
total_req = 125000 

Dual Bus Interface Util: 
issued_total_row = 15324 
issued_total_col = 125000 
Row_Bus_Util =  0.056225 
CoL_Bus_Util = 0.458633 
Either_Row_CoL_Bus_Util = 0.504584 
Issued_on_Two_Bus_Simul_Util = 0.010273 
issued_two_Eff = 0.020360 
queue_avg = 59.972191 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=59.9722
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents
MSHR: tag=0xc16dfa00, atomic=0 1 entries : 0x7fca85e55bc0 :  mf: uid=728162, sid03:w22, part=2, addr=0xc16dfa00, load , size=128, unknown  status = IN_PARTITION_DRAM (175193), 

Cache L2_bank_005:
MSHR contents
MSHR: tag=0xc16dfa80, atomic=0 1 entries : 0x7fca85d8b530 :  mf: uid=728161, sid03:w22, part=2, addr=0xc16dfa80, load , size=128, unknown  status = IN_PARTITION_DRAM (175194), 

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272549 n_nop=134675 n_act=7797 n_pre=7781 n_ref_event=0 n_req=31250 n_rd=62504 n_rd_L2_A=31245 n_write=31248 n_wr_bk=0 bw_util=0.9172
n_activity=270103 dram_eff=0.9256
bk0: 5888a 99095i bk1: 5888a 89961i bk2: 5888a 97516i bk3: 5888a 89245i bk4: 5888a 101610i bk5: 5888a 93364i bk6: 5888a 99791i bk7: 5885a 92130i bk8: 5852a 98705i bk9: 5852a 90977i bk10: 5824a 98302i bk11: 5824a 93209i bk12: 5824a 99074i bk13: 5824a 95046i bk14: 5824a 102787i bk15: 5824a 94218i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.750496
Row_Buffer_Locality_read = 0.774981
Row_Buffer_Locality_write = 0.677035
Bank_Level_Parallism = 10.585727
Bank_Level_Parallism_Col = 10.135601
Bank_Level_Parallism_Ready = 5.236914
write_to_read_ratio_blp_rw_average = 0.479006
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.917244 
total_CMD = 272549 
util_bw = 249993 
Wasted_Col = 19903 
Wasted_Row = 83 
Idle = 2570 

BW Util Bottlenecks: 
RCDc_limit = 3583 
RCDWRc_limit = 1494 
WTRc_limit = 87007 
RTWc_limit = 85091 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 87007 
RTWc_limit_alone = 85091 

Commands details: 
total_CMD = 272549 
n_nop = 134675 
Read = 62504 
Write = 31248 
L2_Alloc = 31245 
L2_WB = 0 
n_act = 7797 
n_pre = 7781 
n_ref = 0 
n_req = 31250 
total_req = 124997 

Dual Bus Interface Util: 
issued_total_row = 15578 
issued_total_col = 124997 
Row_Bus_Util =  0.057157 
CoL_Bus_Util = 0.458622 
Either_Row_CoL_Bus_Util = 0.505869 
Issued_on_Two_Bus_Simul_Util = 0.009910 
issued_two_Eff = 0.019590 
queue_avg = 54.533737 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=54.5337
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272549 n_nop=135170 n_act=7504 n_pre=7488 n_ref_event=0 n_req=31250 n_rd=62504 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9173
n_activity=270098 dram_eff=0.9256
bk0: 5888a 100154i bk1: 5888a 93962i bk2: 5888a 99303i bk3: 5888a 90399i bk4: 5888a 99291i bk5: 5888a 91920i bk6: 5888a 99427i bk7: 5888a 92939i bk8: 5852a 100563i bk9: 5852a 92039i bk10: 5824a 101220i bk11: 5824a 94604i bk12: 5824a 101860i bk13: 5824a 94526i bk14: 5824a 101337i bk15: 5824a 92761i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.759872
Row_Buffer_Locality_read = 0.778778
Row_Buffer_Locality_write = 0.703149
Bank_Level_Parallism = 10.541185
Bank_Level_Parallism_Col = 10.107108
Bank_Level_Parallism_Ready = 5.119624
write_to_read_ratio_blp_rw_average = 0.488812
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.917266 
total_CMD = 272549 
util_bw = 250000 
Wasted_Col = 19946 
Wasted_Row = 58 
Idle = 2545 

BW Util Bottlenecks: 
RCDc_limit = 3532 
RCDWRc_limit = 1288 
WTRc_limit = 88222 
RTWc_limit = 85820 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 88222 
RTWc_limit_alone = 85820 

Commands details: 
total_CMD = 272549 
n_nop = 135170 
Read = 62504 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7504 
n_pre = 7488 
n_ref = 0 
n_req = 31250 
total_req = 125000 

Dual Bus Interface Util: 
issued_total_row = 14992 
issued_total_col = 125000 
Row_Bus_Util =  0.055007 
CoL_Bus_Util = 0.458633 
Either_Row_CoL_Bus_Util = 0.504052 
Issued_on_Two_Bus_Simul_Util = 0.009587 
issued_two_Eff = 0.019020 
queue_avg = 55.767418 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=55.7674
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272549 n_nop=135723 n_act=7234 n_pre=7218 n_ref_event=0 n_req=31252 n_rd=62496 n_rd_L2_A=31256 n_write=31256 n_wr_bk=0 bw_util=0.9173
n_activity=269546 dram_eff=0.9275
bk0: 5888a 97959i bk1: 5888a 89283i bk2: 5888a 97935i bk3: 5888a 90629i bk4: 5888a 99759i bk5: 5888a 91611i bk6: 5888a 98230i bk7: 5888a 91480i bk8: 5852a 99921i bk9: 5852a 93056i bk10: 5824a 100766i bk11: 5824a 94674i bk12: 5824a 99256i bk13: 5824a 93127i bk14: 5824a 95404i bk15: 5824a 90375i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.768527
Row_Buffer_Locality_read = 0.782917
Row_Buffer_Locality_write = 0.725365
Bank_Level_Parallism = 10.645658
Bank_Level_Parallism_Col = 10.219397
Bank_Level_Parallism_Ready = 5.225764
write_to_read_ratio_blp_rw_average = 0.486453
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.917325 
total_CMD = 272549 
util_bw = 250016 
Wasted_Col = 19431 
Wasted_Row = 29 
Idle = 3073 

BW Util Bottlenecks: 
RCDc_limit = 3447 
RCDWRc_limit = 1214 
WTRc_limit = 88299 
RTWc_limit = 84501 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 88299 
RTWc_limit_alone = 84501 

Commands details: 
total_CMD = 272549 
n_nop = 135723 
Read = 62496 
Write = 31256 
L2_Alloc = 31256 
L2_WB = 0 
n_act = 7234 
n_pre = 7218 
n_ref = 0 
n_req = 31252 
total_req = 125008 

Dual Bus Interface Util: 
issued_total_row = 14452 
issued_total_col = 125008 
Row_Bus_Util =  0.053025 
CoL_Bus_Util = 0.458662 
Either_Row_CoL_Bus_Util = 0.502024 
Issued_on_Two_Bus_Simul_Util = 0.009664 
issued_two_Eff = 0.019251 
queue_avg = 61.458294 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=61.4583
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272549 n_nop=135228 n_act=7516 n_pre=7500 n_ref_event=0 n_req=31252 n_rd=62496 n_rd_L2_A=31256 n_write=31256 n_wr_bk=0 bw_util=0.9173
n_activity=269990 dram_eff=0.926
bk0: 5888a 97157i bk1: 5888a 93257i bk2: 5888a 97818i bk3: 5888a 92102i bk4: 5888a 98551i bk5: 5888a 91227i bk6: 5888a 98818i bk7: 5888a 90577i bk8: 5852a 100547i bk9: 5852a 91766i bk10: 5824a 97505i bk11: 5824a 92243i bk12: 5824a 102471i bk13: 5824a 94654i bk14: 5824a 98246i bk15: 5824a 91501i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.759503
Row_Buffer_Locality_read = 0.774298
Row_Buffer_Locality_write = 0.715127
Bank_Level_Parallism = 10.608464
Bank_Level_Parallism_Col = 10.170721
Bank_Level_Parallism_Ready = 5.128565
write_to_read_ratio_blp_rw_average = 0.492354
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.917325 
total_CMD = 272549 
util_bw = 250016 
Wasted_Col = 19841 
Wasted_Row = 43 
Idle = 2649 

BW Util Bottlenecks: 
RCDc_limit = 3928 
RCDWRc_limit = 1208 
WTRc_limit = 89412 
RTWc_limit = 86777 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 89412 
RTWc_limit_alone = 86777 

Commands details: 
total_CMD = 272549 
n_nop = 135228 
Read = 62496 
Write = 31256 
L2_Alloc = 31256 
L2_WB = 0 
n_act = 7516 
n_pre = 7500 
n_ref = 0 
n_req = 31252 
total_req = 125008 

Dual Bus Interface Util: 
issued_total_row = 15016 
issued_total_col = 125008 
Row_Bus_Util =  0.055095 
CoL_Bus_Util = 0.458662 
Either_Row_CoL_Bus_Util = 0.503840 
Issued_on_Two_Bus_Simul_Util = 0.009917 
issued_two_Eff = 0.019684 
queue_avg = 61.031525 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=61.0315
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272549 n_nop=135489 n_act=7333 n_pre=7317 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9172
n_activity=270169 dram_eff=0.9253
bk0: 5888a 105339i bk1: 5888a 97679i bk2: 5888a 96154i bk3: 5888a 89395i bk4: 5888a 102486i bk5: 5888a 97372i bk6: 5888a 100363i bk7: 5888a 93121i bk8: 5848a 102937i bk9: 5848a 99699i bk10: 5824a 100136i bk11: 5824a 94220i bk12: 5824a 103156i bk13: 5824a 99788i bk14: 5824a 105579i bk15: 5824a 96622i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.765329
Row_Buffer_Locality_read = 0.778290
Row_Buffer_Locality_write = 0.726447
Bank_Level_Parallism = 10.394424
Bank_Level_Parallism_Col = 9.975441
Bank_Level_Parallism_Ready = 5.089009
write_to_read_ratio_blp_rw_average = 0.487054
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.917208 
total_CMD = 272549 
util_bw = 249984 
Wasted_Col = 20111 
Wasted_Row = 24 
Idle = 2430 

BW Util Bottlenecks: 
RCDc_limit = 4101 
RCDWRc_limit = 1433 
WTRc_limit = 89707 
RTWc_limit = 86362 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 89707 
RTWc_limit_alone = 86362 

Commands details: 
total_CMD = 272549 
n_nop = 135489 
Read = 62496 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7333 
n_pre = 7317 
n_ref = 0 
n_req = 31248 
total_req = 124992 

Dual Bus Interface Util: 
issued_total_row = 14650 
issued_total_col = 124992 
Row_Bus_Util =  0.053752 
CoL_Bus_Util = 0.458604 
Either_Row_CoL_Bus_Util = 0.502882 
Issued_on_Two_Bus_Simul_Util = 0.009474 
issued_two_Eff = 0.018838 
queue_avg = 62.779186 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=62.7792
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents

Cache L2_bank_015:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272549 n_nop=135457 n_act=7478 n_pre=7462 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9172
n_activity=270183 dram_eff=0.9252
bk0: 5888a 99656i bk1: 5888a 92927i bk2: 5888a 97463i bk3: 5888a 92743i bk4: 5888a 103809i bk5: 5888a 96170i bk6: 5888a 97832i bk7: 5888a 90597i bk8: 5848a 102442i bk9: 5848a 96776i bk10: 5824a 103063i bk11: 5824a 96460i bk12: 5824a 102805i bk13: 5824a 96594i bk14: 5824a 101228i bk15: 5824a 96498i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.760689
Row_Buffer_Locality_read = 0.774108
Row_Buffer_Locality_write = 0.720430
Bank_Level_Parallism = 10.459931
Bank_Level_Parallism_Col = 10.017000
Bank_Level_Parallism_Ready = 5.117230
write_to_read_ratio_blp_rw_average = 0.485708
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.917208 
total_CMD = 272549 
util_bw = 249984 
Wasted_Col = 20092 
Wasted_Row = 31 
Idle = 2442 

BW Util Bottlenecks: 
RCDc_limit = 3941 
RCDWRc_limit = 1357 
WTRc_limit = 89942 
RTWc_limit = 86680 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 89942 
RTWc_limit_alone = 86680 

Commands details: 
total_CMD = 272549 
n_nop = 135457 
Read = 62496 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7478 
n_pre = 7462 
n_ref = 0 
n_req = 31248 
total_req = 124992 

Dual Bus Interface Util: 
issued_total_row = 14940 
issued_total_col = 124992 
Row_Bus_Util =  0.054816 
CoL_Bus_Util = 0.458604 
Either_Row_CoL_Bus_Util = 0.502999 
Issued_on_Two_Bus_Simul_Util = 0.010420 
issued_two_Eff = 0.020716 
queue_avg = 62.432949 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=62.4329

========= L2 cache stats =========
L2_cache_bank[0]: Access = 11759, Miss = 11721, Miss_rate = 0.997, Pending_hits = 38, Reservation_fails = 14
L2_cache_bank[1]: Access = 11739, Miss = 11720, Miss_rate = 0.998, Pending_hits = 19, Reservation_fails = 16
L2_cache_bank[2]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 47
L2_cache_bank[3]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 58
L2_cache_bank[4]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 20
L2_cache_bank[5]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 23
L2_cache_bank[6]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 11
L2_cache_bank[7]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 12
L2_cache_bank[8]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 75
L2_cache_bank[9]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 75
L2_cache_bank[10]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 96
L2_cache_bank[11]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 90
L2_cache_bank[12]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 122
L2_cache_bank[13]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 124
L2_cache_bank[14]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 116
L2_cache_bank[15]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 116
L2_total_cache_accesses = 187560
L2_total_cache_misses = 187503
L2_total_cache_miss_rate = 0.9997
L2_total_cache_pending_hits = 57
L2_total_cache_reservation_fails = 1015
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 125000
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 19
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 1
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 19
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 62500
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 1015
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 38
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 2
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 38
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 125000
	L2_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 20
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 62500
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 40
L2_total_cache_reservation_fail_breakdown:
	L2_cache_stats_fail_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 1015
L2_cache_data_port_util = 0.000
L2_cache_fill_port_util = 0.268

icnt_total_pkts_mem_to_simt=687760
icnt_total_pkts_simt_to_mem=437560
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 91.441
	minimum = 6
	maximum = 1365
Network latency average = 55.4421
	minimum = 6
	maximum = 1224
Slowest packet = 2311
Flit latency average = 32.582
	minimum = 6
	maximum = 1224
Slowest flit = 3003
Fragmentation average = 0.596012
	minimum = 0
	maximum = 556
Injected packet rate average = 0.0428231
	minimum = 0 (at node 36)
	maximum = 0.0671195 (at node 20)
Accepted packet rate average = 0.0428231
	minimum = 0 (at node 36)
	maximum = 0.0671195 (at node 20)
Injected flit rate average = 0.128465
	minimum = 0 (at node 36)
	maximum = 0.246189 (at node 20)
Accepted flit rate average= 0.128465
	minimum = 0 (at node 36)
	maximum = 0.205012 (at node 3)
Injected packet length average = 2.99989
Accepted packet length average = 2.99989
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 91.441 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1365 (1 samples)
Network latency average = 55.4421 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1224 (1 samples)
Flit latency average = 32.582 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1224 (1 samples)
Fragmentation average = 0.596012 (1 samples)
	minimum = 0 (1 samples)
	maximum = 556 (1 samples)
Injected packet rate average = 0.0428231 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0671195 (1 samples)
Accepted packet rate average = 0.0428231 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0671195 (1 samples)
Injected flit rate average = 0.128465 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.246189 (1 samples)
Accepted flit rate average = 0.128465 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.205012 (1 samples)
Injected packet size average = 2.99989 (1 samples)
Accepted packet size average = 2.99989 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 2 min, 26 sec (146 sec)
gpgpu_simulation_rate = 143869 (inst/sec)
gpgpu_simulation_rate = 1199 (cycle/sec)
gpgpu_silicon_slowdown = 1340283x
Final sum = 1000000.000000; sum/n = 1.000000 (should be ~1)
GPGPU-Sim: *** exit detected ***
