GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded


        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim PTX: simulation mode 0 (can change with PTX_SIM_MODE_FUNC environment variable:
               1=functional simulation only, 0=detailed performance simulator)
GPGPU-Sim PTX: overriding embedded ptx with ptx file (PTX_SIM_USE_PTX_FILE is set)
GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:2962.0:1607.0:2750.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:2962000000.000000:1607000000.000000:2750000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000033760972316:0.00000000062227753578:0.00000000036363636364
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
e4fe8aeaa3cbb0f2edd942968a8388a5  /benchrun/accelsim-ptx/vectoradd/sm6_gtx1080/input-1000000/vectorAdd
Extracting PTX file and ptxas options    1: vectorAdd.1.sm_30.ptx -arch=sm_30
GPGPU-Sim uArch: performance model initialization complete.
self exe links to: /benchrun/accelsim-ptx/vectoradd/sm6_gtx1080/input-1000000/vectorAdd
self exe links to: /benchrun/accelsim-ptx/vectoradd/sm6_gtx1080/input-1000000/vectorAdd
10.1
GPGPU-Sim PTX: __cudaRegisterFatBinary, fat_cubin_handle = 1, filename=default
self exe links to: /benchrun/accelsim-ptx/vectoradd/sm6_gtx1080/input-1000000/vectorAdd
Running md5sum using "md5sum /benchrun/accelsim-ptx/vectoradd/sm6_gtx1080/input-1000000/vectorAdd "
self exe links to: /benchrun/accelsim-ptx/vectoradd/sm6_gtx1080/input-1000000/vectorAdd
Extracting specific PTX file named vectorAdd.1.sm_30.ptx 
GPGPU-Sim PTX: __cudaRegisterFunction _Z6vecAddPdS_S_i : hostFun 0x0x55adf7c015dd, fat_cubin_handle = 1
GPGPU-Sim PTX: Parsing vectorAdd.1.sm_30.ptx
GPGPU-Sim PTX: instruction assembly for function '_Z6vecAddPdS_S_i'...   done.
GPGPU-Sim PTX: finished parsing EMBEDDED .ptx file vectorAdd.1.sm_30.ptx
GPGPU-Sim PTX: loading globals with explicit initializers... 
GPGPU-Sim PTX: finished loading globals (0 bytes total).
GPGPU-Sim PTX: loading constants with explicit initializers...  done.
GPGPU-Sim PTX: Loading PTXInfo from vectorAdd.1.sm_30.ptx
GPGPU-Sim PTX: Kernel '_Z6vecAddPdS_S_i' : regs=10, lmem=0, smem=0, cmem=348
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7fff5ddafa98..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7fff5ddafa90..
GPGPU-Sim PTX: Setting up arguments for 8 bytes starting at 0x7fff5ddafa88..
GPGPU-Sim PTX: Setting up arguments for 4 bytes starting at 0x7fff5ddafa84..

GPGPU-Sim PTX: cudaLaunch for 0x0x55adf7c015dd (mode=performance simulation) on stream 0
GPGPU-Sim PTX: finding reconvergence points for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: Finding dominators for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: Finding immediate dominators for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: Finding postdominators for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: Finding immediate postdominators for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: pre-decoding instructions for '_Z6vecAddPdS_S_i'...
GPGPU-Sim PTX: reconvergence points for _Z6vecAddPdS_S_i...
GPGPU-Sim PTX:  1 (potential) branch divergence @  PC=0x048 (vectorAdd.1.sm_30.ptx:37) @%p1 bra BB0_2;
GPGPU-Sim PTX:    immediate post dominator      @  PC=0x0a8 (vectorAdd.1.sm_30.ptx:52) ret;
GPGPU-Sim PTX: ... end of reconvergence points for _Z6vecAddPdS_S_i
GPGPU-Sim PTX: ... done pre-decoding instructions for '_Z6vecAddPdS_S_i'.
GPGPU-Sim PTX: pushing kernel '_Z6vecAddPdS_S_i' to stream 0, gridDim= (977,1,1) blockDim = (1024,1,1) 
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 16 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 17 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 18 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: Shader 19 bind to kernel 1 '_Z6vecAddPdS_S_i'
Destroy streams for kernel 1: size 0
kernel_name = _Z6vecAddPdS_S_i 
kernel_launch_uid = 1 
gpu_sim_cycle = 159439
gpu_sim_insn = 21004928
gpu_ipc =     131.7427
gpu_tot_sim_cycle = 159439
gpu_tot_sim_insn = 21004928
gpu_tot_ipc =     131.7427
gpu_tot_issued_cta = 977
gpu_occupancy = 67.7916% 
gpu_tot_occupancy = 67.7916% 
max_total_param_size = 0
gpu_stall_dramfull = 854737
gpu_stall_icnt2sh    = 2093
partiton_level_parallism =       1.1764
partiton_level_parallism_total  =       1.1764
partiton_level_parallism_util =       2.6422
partiton_level_parallism_util_total  =       2.6422
L2_BW  =     111.5015 GB/Sec
L2_BW_total  =     111.5015 GB/Sec
gpu_total_sim_rate=136395

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 343848
	L1I_total_cache_misses = 1724
	L1I_total_cache_miss_rate = 0.0050
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 4745
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 125056
	L1C_total_cache_misses = 1280
	L1C_total_cache_miss_rate = 0.0102
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 3735
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 123776
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 1280
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 3735
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 1260
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 342124
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 1724
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 4745
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 1684
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 125056
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 343848

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[CONST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 3735
	Total_core_cache_fail_stats_breakdown[INST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 4745
ctas_completed 977, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
distro:
575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 575, 
gpgpu_n_tot_thrd_icount = 22004928
gpgpu_n_tot_w_icount = 687654
gpgpu_n_stall_shd_mem = 2720960
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 125000
gpgpu_n_mem_write_global = 62500
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 20
gpgpu_n_load_insn  = 2000000
gpgpu_n_store_insn = 1000000
gpgpu_n_shmem_insn = 0
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 4001792
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 3735
gpgpu_stall_shd_mem[c_mem][resource_stall] = 3735
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 93750
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:4639061	W0_Idle:83941	W0_Scoreboard:957482	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:687654
single_issue_nums: WS0:312577	WS1:312577	
dual_issue_nums: WS0:15625	WS1:15625	
traffic_breakdown_coretomem[CONST_ACC_R] = 160 {8:20,}
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 1000000 {8:125000,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 8500000 {136:62500,}
traffic_breakdown_coretomem[INST_ACC_R] = 320 {8:40,}
traffic_breakdown_memtocore[CONST_ACC_R] = 1440 {72:20,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 17000000 {136:125000,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 500000 {8:62500,}
traffic_breakdown_memtocore[INST_ACC_R] = 5440 {136:40,}
maxmflatency = 4327 
max_icnt2mem_latency = 1254 
maxmrqlatency = 2962 
max_icnt2sh_latency = 55 
averagemflatency = 951 
avg_icnt2mem_latency = 173 
avg_mrq_latency = 299 
avg_icnt2sh_latency = 5 
mrq_lat_table:51145 	531 	2067 	5299 	9925 	18228 	26853 	38235 	47172 	35748 	13924 	876 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	270 	30303 	93137 	55951 	7857 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	7884 	38248 	27067 	17496 	13851 	26447 	43383 	13143 	41 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	167228 	19372 	884 	36 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	0 	1 	245 	71 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        30        30        32        32        32        32        32        32        30        30        32        32        28        30        30        30 
dram[1]:        28        28        32        32        32        32        32        32        30        30        30        30        30        30        26        26 
dram[2]:        30        30        32        32        30        30        32        32        32        32        30        30        26        26        28        28 
dram[3]:        30        30        32        32        32        32        30        30        28        28        28        30        30        30        26        26 
dram[4]:        32        32        32        32        28        28        32        32        30        30        30        30        32        32        28        28 
dram[5]:        32        32        32        32        30        30        32        32        32        32        32        30        30        30        28        28 
dram[6]:        30        30        32        32        32        28        32        32        32        32        30        30        30        30        30        30 
dram[7]:        32        32        32        32        30        30        32        32        32        32        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:      2416      2423      2692      2376      2371      2377      2294      2240      2503      2496      2720      2720      2319      2635      2459      2500 
dram[1]:      2465      2471      2330      2284      2313      2672      2155      2129      2641      2651      2408      2415      2993      2956      2574      2580 
dram[2]:      2509      2496      2258      2266      2208      2061      2429      2461      2255      2298      2551      2556      2460      2458      2440      2441 
dram[3]:      2198      2189      2496      2367      2562      2562      2240      2232      2265      2264      2099      2659      2507      2516      2424      2414 
dram[4]:      2444      2450      2720      2721      2141      2147      2553      2554      2483      2461      2654      2620      3040      3041      2715      2619 
dram[5]:      2827      3050      2540      2689      2233      2436      2548      2499      2477      2685      2694      2470      2530      2518      2607      2735 
dram[6]:      2553      2546      2610      2630      2303      2145      2374      2384      2657      2664      2607      2610      2623      2565      2900      2833 
dram[7]:      2898      2905      2402      2429      2348      2348      2477      2521      2537      2538      2511      2808      2807      2850      2542      2549 
average row accesses per activate:
dram[0]:  4.136842  4.232759  4.214133  4.268981  3.936000  4.000000  3.664804  3.777351  3.728489  3.801170  3.959100  3.991753  3.438721  3.558824  4.041754  4.273731 
dram[1]:  3.841487  4.006123  3.889328  4.032787  3.959759  4.049383  3.734345  3.889328  3.846154  4.020618  4.050209  4.181426  4.041754  4.163441  3.895372  3.975359 
dram[2]:  3.949698  4.055785  4.442438  4.534562  3.874016  3.959759  3.983806  4.049383  4.157783  4.248366  4.075789  4.127932  3.578558  3.687619  4.264317  4.331096 
dram[3]:  4.030801  4.167728  3.904762  4.032787  3.777351  3.843750  3.762906  3.904762  4.131356  4.220779  3.879760  3.951020  3.744681  3.833663  3.911111  4.058700 
dram[4]:  4.057851  4.091667  4.363636  4.493151  3.657993  3.777351  4.719424  4.742169  3.793774  3.861386  4.181426  4.350562  3.879760  4.093023  4.119149  4.245614 
dram[5]:  4.433409  4.433409  4.534562  4.545034  4.353982  4.462585  4.325275  4.178344  4.220779  4.482759  4.283186  4.410023  4.016598  4.264317  4.181426  4.254945 
dram[6]:  4.196581  4.374165  4.259740  4.363636  3.813953  3.983806  4.196162  4.259740  4.519722  4.605201  4.016598  4.236324  3.744681  3.887550  4.058700  4.199566 
dram[7]:  4.241900  4.453515  4.160676  4.422472  4.306346  4.422472  4.442438  4.315790  4.377528  4.447489  4.254945  4.502326  4.450575  4.512821  4.555294  4.631579 
average row locality = 250003/60845 = 4.108850
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:      5896      5892      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[1]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[2]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[3]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[4]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[5]:      5888      5888      5888      5888      5888      5888      5888      5888      5852      5852      5824      5824      5824      5824      5824      5824 
dram[6]:      5888      5888      5888      5888      5888      5888      5888      5888      5848      5848      5824      5824      5824      5824      5824      5824 
dram[7]:      5888      5888      5888      5888      5888      5888      5888      5888      5848      5848      5824      5824      5824      5824      5824      5824 
total dram reads = 750012
bank skew: 5896/5824 = 1.01
chip skew: 93764/93744 = 1.00
number of total write accesses:
dram[0]:      1964      1964      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[1]:      1964      1964      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[2]:      1964      1964      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[3]:      1964      1964      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[4]:      1968      1968      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[5]:      1968      1968      1984      1984      1984      1984      1984      1984      1948      1948      1920      1920      1920      1920      1920      1920 
dram[6]:      1968      1968      1984      1984      1984      1984      1984      1984      1944      1944      1920      1920      1920      1920      1920      1920 
dram[7]:      1968      1968      1984      1984      1984      1984      1984      1984      1944      1944      1920      1920      1920      1920      1920      1920 
total dram writes = 250000
bank skew: 1984/1920 = 1.03
chip skew: 31256/31248 = 1.00
average mf latency per bank:
dram[0]:        151       157       157       163       140       149       133       141       141       149       152       159       134       142       151       160
dram[1]:        137       147       143       151       142       151       131       138       136       143       144       151       140       147       141       148
dram[2]:        158       167       172       179       154       162       157       163       161       166       170       176       152       158       163       171
dram[3]:        151       158       143       149       144       151       140       148       141       148       145       154       144       151       139       148
dram[4]:        207       217       218       228       192       202       212       219       198       207       216       227       198       209       204       211
dram[5]:        227       245       229       247       224       241       227       241       217       238       230       250       218       239       223       240
dram[6]:        171       180       178       188       168       177       174       181       176       185       177       188       164       173       172       181
dram[7]:        200       207       188       197       200       204       196       202       190       195       198       207       195       202       195       202
maximum mf latency per bank:
dram[0]:       3252      3263      3389      3430      2916      2922      2635      2653      3285      3139      3582      3603      2774      3603      3183      3204
dram[1]:       3056      3111      3218      3243      3138      3253      2402      2428      3066      3086      3105      3167      2735      2751      2830      2874
dram[2]:       3057      3294      3494      3332      3016      3031      3010      3029      2976      2985      3284      3291      2735      2874      3381      3553
dram[3]:       2862      2919      3597      3103      3627      3752      2583      2618      3409      3444      2849      2938      3413      3431      2786      2844
dram[4]:       3364      3494      3688      3734      2856      3067      3314      3507      3166      3206      3303      3438      3119      3180      3637      3298
dram[5]:       4080      4327      3701      3945      3561      4017      3472      3607      3296      3522      3436      3564      3574      3582      3483      3880
dram[6]:       3259      3435      3258      3399      3110      3122      2706      2738      3437      3448      3307      3342      3302      3420      2779      2909
dram[7]:       3389      3498      3405      3249      3302      3319      3379      3640      2931      3035      3438      3744      3604      3633      3078      3280
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272841 n_nop=134716 n_act=7966 n_pre=7950 n_ref_event=0 n_req=31253 n_rd=62516 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9164
n_activity=270136 dram_eff=0.9255
bk0: 5896a 100849i bk1: 5892a 94787i bk2: 5888a 91481i bk3: 5888a 85302i bk4: 5888a 95856i bk5: 5888a 88707i bk6: 5888a 97001i bk7: 5888a 90178i bk8: 5852a 95936i bk9: 5852a 90885i bk10: 5824a 96604i bk11: 5824a 89460i bk12: 5824a 97226i bk13: 5824a 91310i bk14: 5824a 96766i bk15: 5824a 90855i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.745112
Row_Buffer_Locality_read = 0.758841
Row_Buffer_Locality_write = 0.703917
Bank_Level_Parallism = 10.753747
Bank_Level_Parallism_Col = 10.282748
Bank_Level_Parallism_Ready = 5.263101
write_to_read_ratio_blp_rw_average = 0.485277
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.916373 
total_CMD = 272841 
util_bw = 250024 
Wasted_Col = 20002 
Wasted_Row = 50 
Idle = 2765 

BW Util Bottlenecks: 
RCDc_limit = 3888 
RCDWRc_limit = 1191 
WTRc_limit = 86363 
RTWc_limit = 87481 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 86363 
RTWc_limit_alone = 87481 

Commands details: 
total_CMD = 272841 
n_nop = 134716 
Read = 62516 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7966 
n_pre = 7950 
n_ref = 0 
n_req = 31253 
total_req = 125012 

Dual Bus Interface Util: 
issued_total_row = 15916 
issued_total_col = 125012 
Row_Bus_Util =  0.058334 
CoL_Bus_Util = 0.458186 
Either_Row_CoL_Bus_Util = 0.506247 
Issued_on_Two_Bus_Simul_Util = 0.010273 
issued_two_Eff = 0.020293 
queue_avg = 55.970505 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=55.9705
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272841 n_nop=134828 n_act=7872 n_pre=7856 n_ref_event=0 n_req=31250 n_rd=62504 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9163
n_activity=270302 dram_eff=0.9249
bk0: 5888a 96478i bk1: 5888a 87744i bk2: 5888a 95869i bk3: 5888a 88651i bk4: 5888a 99312i bk5: 5888a 92757i bk6: 5888a 94456i bk7: 5888a 88393i bk8: 5852a 100959i bk9: 5852a 94033i bk10: 5824a 97897i bk11: 5824a 91059i bk12: 5824a 100948i bk13: 5824a 93896i bk14: 5824a 100085i bk15: 5824a 92154i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.748096
Row_Buffer_Locality_read = 0.762437
Row_Buffer_Locality_write = 0.705069
Bank_Level_Parallism = 10.666569
Bank_Level_Parallism_Col = 10.204483
Bank_Level_Parallism_Ready = 5.299803
write_to_read_ratio_blp_rw_average = 0.477563
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.916285 
total_CMD = 272841 
util_bw = 250000 
Wasted_Col = 20198 
Wasted_Row = 74 
Idle = 2569 

BW Util Bottlenecks: 
RCDc_limit = 3764 
RCDWRc_limit = 1219 
WTRc_limit = 86640 
RTWc_limit = 87618 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 86640 
RTWc_limit_alone = 87618 

Commands details: 
total_CMD = 272841 
n_nop = 134828 
Read = 62504 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7872 
n_pre = 7856 
n_ref = 0 
n_req = 31250 
total_req = 125000 

Dual Bus Interface Util: 
issued_total_row = 15728 
issued_total_col = 125000 
Row_Bus_Util =  0.057645 
CoL_Bus_Util = 0.458142 
Either_Row_CoL_Bus_Util = 0.505837 
Issued_on_Two_Bus_Simul_Util = 0.009951 
issued_two_Eff = 0.019672 
queue_avg = 53.896076 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=53.8961
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272841 n_nop=135346 n_act=7682 n_pre=7666 n_ref_event=0 n_req=31250 n_rd=62504 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9163
n_activity=270139 dram_eff=0.9254
bk0: 5888a 101922i bk1: 5888a 94773i bk2: 5888a 98825i bk3: 5888a 90913i bk4: 5888a 96857i bk5: 5888a 89647i bk6: 5888a 97562i bk7: 5888a 91595i bk8: 5852a 98208i bk9: 5852a 92761i bk10: 5824a 98628i bk11: 5824a 94580i bk12: 5824a 103826i bk13: 5824a 96144i bk14: 5824a 99099i bk15: 5824a 92327i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.754176
Row_Buffer_Locality_read = 0.776261
Row_Buffer_Locality_write = 0.687916
Bank_Level_Parallism = 10.587750
Bank_Level_Parallism_Col = 10.130163
Bank_Level_Parallism_Ready = 5.192726
write_to_read_ratio_blp_rw_average = 0.485970
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.916285 
total_CMD = 272841 
util_bw = 250000 
Wasted_Col = 20045 
Wasted_Row = 28 
Idle = 2768 

BW Util Bottlenecks: 
RCDc_limit = 3395 
RCDWRc_limit = 1453 
WTRc_limit = 87513 
RTWc_limit = 85597 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 87513 
RTWc_limit_alone = 85597 

Commands details: 
total_CMD = 272841 
n_nop = 135346 
Read = 62504 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7682 
n_pre = 7666 
n_ref = 0 
n_req = 31250 
total_req = 125000 

Dual Bus Interface Util: 
issued_total_row = 15348 
issued_total_col = 125000 
Row_Bus_Util =  0.056253 
CoL_Bus_Util = 0.458142 
Either_Row_CoL_Bus_Util = 0.503938 
Issued_on_Two_Bus_Simul_Util = 0.010457 
issued_two_Eff = 0.020750 
queue_avg = 57.796906 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=57.7969
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents
MSHR: tag=0xc16dc300, atomic=0 1 entries : 0x7ff0693ea7a0 :  mf: uid=727382, sid11:w31, part=3, addr=0xc16dc300, load , size=128, unknown  status = IN_PARTITION_DRAM (159438), 

Cache L2_bank_007:
MSHR contents
MSHR: tag=0xc16dc380, atomic=0 1 entries : 0x7ff06a56b100 :  mf: uid=727381, sid11:w31, part=3, addr=0xc16dc380, load , size=128, unknown  status = IN_PARTITION_DRAM (159438), 

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272841 n_nop=134857 n_act=7927 n_pre=7911 n_ref_event=0 n_req=31250 n_rd=62504 n_rd_L2_A=31242 n_write=31248 n_wr_bk=0 bw_util=0.9162
n_activity=270163 dram_eff=0.9253
bk0: 5888a 95622i bk1: 5888a 89828i bk2: 5888a 96445i bk3: 5888a 88872i bk4: 5888a 95418i bk5: 5888a 86895i bk6: 5886a 95795i bk7: 5884a 87546i bk8: 5852a 99506i bk9: 5852a 91793i bk10: 5824a 94733i bk11: 5824a 88499i bk12: 5824a 99865i bk13: 5824a 93898i bk14: 5824a 98993i bk15: 5824a 92086i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.746336
Row_Buffer_Locality_read = 0.773359
Row_Buffer_Locality_write = 0.665259
Bank_Level_Parallism = 10.742936
Bank_Level_Parallism_Col = 10.274385
Bank_Level_Parallism_Ready = 5.417267
write_to_read_ratio_blp_rw_average = 0.471882
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.916241 
total_CMD = 272841 
util_bw = 249988 
Wasted_Col = 19981 
Wasted_Row = 98 
Idle = 2774 

BW Util Bottlenecks: 
RCDc_limit = 3529 
RCDWRc_limit = 1261 
WTRc_limit = 83963 
RTWc_limit = 84759 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 83963 
RTWc_limit_alone = 84759 

Commands details: 
total_CMD = 272841 
n_nop = 134857 
Read = 62504 
Write = 31248 
L2_Alloc = 31242 
L2_WB = 0 
n_act = 7927 
n_pre = 7911 
n_ref = 0 
n_req = 31250 
total_req = 124994 

Dual Bus Interface Util: 
issued_total_row = 15838 
issued_total_col = 124994 
Row_Bus_Util =  0.058048 
CoL_Bus_Util = 0.458120 
Either_Row_CoL_Bus_Util = 0.505730 
Issued_on_Two_Bus_Simul_Util = 0.010438 
issued_two_Eff = 0.020640 
queue_avg = 51.691700 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=51.6917
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272841 n_nop=135603 n_act=7569 n_pre=7553 n_ref_event=0 n_req=31252 n_rd=62496 n_rd_L2_A=31256 n_write=31256 n_wr_bk=0 bw_util=0.9163
n_activity=269751 dram_eff=0.9268
bk0: 5888a 97432i bk1: 5888a 89870i bk2: 5888a 98905i bk3: 5888a 91675i bk4: 5888a 96207i bk5: 5888a 89055i bk6: 5888a 95643i bk7: 5888a 89151i bk8: 5852a 99407i bk9: 5852a 92354i bk10: 5824a 100004i bk11: 5824a 93422i bk12: 5824a 98781i bk13: 5824a 93700i bk14: 5824a 100402i bk15: 5824a 97424i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.757807
Row_Buffer_Locality_read = 0.776303
Row_Buffer_Locality_write = 0.702329
Bank_Level_Parallism = 10.651067
Bank_Level_Parallism_Col = 10.204483
Bank_Level_Parallism_Ready = 5.203817
write_to_read_ratio_blp_rw_average = 0.485861
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.916343 
total_CMD = 272841 
util_bw = 250016 
Wasted_Col = 19668 
Wasted_Row = 17 
Idle = 3140 

BW Util Bottlenecks: 
RCDc_limit = 3668 
RCDWRc_limit = 1433 
WTRc_limit = 89152 
RTWc_limit = 86245 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 89152 
RTWc_limit_alone = 86245 

Commands details: 
total_CMD = 272841 
n_nop = 135603 
Read = 62496 
Write = 31256 
L2_Alloc = 31256 
L2_WB = 0 
n_act = 7569 
n_pre = 7553 
n_ref = 0 
n_req = 31252 
total_req = 125008 

Dual Bus Interface Util: 
issued_total_row = 15122 
issued_total_col = 125008 
Row_Bus_Util =  0.055424 
CoL_Bus_Util = 0.458172 
Either_Row_CoL_Bus_Util = 0.502996 
Issued_on_Two_Bus_Simul_Util = 0.010600 
issued_two_Eff = 0.021073 
queue_avg = 61.550777 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=61.5508
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272841 n_nop=136068 n_act=7214 n_pre=7198 n_ref_event=0 n_req=31252 n_rd=62496 n_rd_L2_A=31256 n_write=31256 n_wr_bk=0 bw_util=0.9163
n_activity=269775 dram_eff=0.9268
bk0: 5888a 98744i bk1: 5888a 94018i bk2: 5888a 98351i bk3: 5888a 92013i bk4: 5888a 95063i bk5: 5888a 93622i bk6: 5888a 94746i bk7: 5888a 91008i bk8: 5852a 100123i bk9: 5852a 96275i bk10: 5824a 100582i bk11: 5824a 97255i bk12: 5824a 101254i bk13: 5824a 95548i bk14: 5824a 99479i bk15: 5824a 96588i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.769167
Row_Buffer_Locality_read = 0.786885
Row_Buffer_Locality_write = 0.716023
Bank_Level_Parallism = 10.567184
Bank_Level_Parallism_Col = 10.160069
Bank_Level_Parallism_Ready = 5.127737
write_to_read_ratio_blp_rw_average = 0.491117
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.916343 
total_CMD = 272841 
util_bw = 250016 
Wasted_Col = 19695 
Wasted_Row = 22 
Idle = 3108 

BW Util Bottlenecks: 
RCDc_limit = 3803 
RCDWRc_limit = 1366 
WTRc_limit = 90587 
RTWc_limit = 87111 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 90587 
RTWc_limit_alone = 87111 

Commands details: 
total_CMD = 272841 
n_nop = 136068 
Read = 62496 
Write = 31256 
L2_Alloc = 31256 
L2_WB = 0 
n_act = 7214 
n_pre = 7198 
n_ref = 0 
n_req = 31252 
total_req = 125008 

Dual Bus Interface Util: 
issued_total_row = 14412 
issued_total_col = 125008 
Row_Bus_Util =  0.052822 
CoL_Bus_Util = 0.458172 
Either_Row_CoL_Bus_Util = 0.501292 
Issued_on_Two_Bus_Simul_Util = 0.009702 
issued_two_Eff = 0.019353 
queue_avg = 62.762386 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=62.7624
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272841 n_nop=135733 n_act=7517 n_pre=7501 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9162
n_activity=269873 dram_eff=0.9263
bk0: 5888a 100835i bk1: 5888a 92867i bk2: 5888a 99785i bk3: 5888a 92110i bk4: 5888a 100406i bk5: 5888a 93334i bk6: 5888a 98024i bk7: 5888a 93557i bk8: 5848a 98308i bk9: 5848a 93687i bk10: 5824a 99895i bk11: 5824a 93552i bk12: 5824a 103700i bk13: 5824a 97056i bk14: 5824a 103440i bk15: 5824a 95652i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.759441
Row_Buffer_Locality_read = 0.772103
Row_Buffer_Locality_write = 0.721454
Bank_Level_Parallism = 10.528266
Bank_Level_Parallism_Col = 10.078229
Bank_Level_Parallism_Ready = 5.223738
write_to_read_ratio_blp_rw_average = 0.480646
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.916226 
total_CMD = 272841 
util_bw = 249984 
Wasted_Col = 19869 
Wasted_Row = 0 
Idle = 2988 

BW Util Bottlenecks: 
RCDc_limit = 3585 
RCDWRc_limit = 1339 
WTRc_limit = 88721 
RTWc_limit = 86163 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 88721 
RTWc_limit_alone = 86163 

Commands details: 
total_CMD = 272841 
n_nop = 135733 
Read = 62496 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7517 
n_pre = 7501 
n_ref = 0 
n_req = 31248 
total_req = 124992 

Dual Bus Interface Util: 
issued_total_row = 15018 
issued_total_col = 124992 
Row_Bus_Util =  0.055043 
CoL_Bus_Util = 0.458113 
Either_Row_CoL_Bus_Util = 0.502520 
Issued_on_Two_Bus_Simul_Util = 0.010636 
issued_two_Eff = 0.021166 
queue_avg = 61.933632 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=61.9336
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents

Cache L2_bank_015:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=272841 n_nop=136330 n_act=7098 n_pre=7082 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9162
n_activity=270518 dram_eff=0.9241
bk0: 5888a 103379i bk1: 5888a 97021i bk2: 5888a 104681i bk3: 5888a 99898i bk4: 5888a 103004i bk5: 5888a 97293i bk6: 5888a 103711i bk7: 5888a 97450i bk8: 5848a 103680i bk9: 5848a 100781i bk10: 5824a 105408i bk11: 5824a 100292i bk12: 5824a 106406i bk13: 5824a 99180i bk14: 5824a 107590i bk15: 5824a 100253i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.772849
Row_Buffer_Locality_read = 0.785629
Row_Buffer_Locality_write = 0.734511
Bank_Level_Parallism = 10.227720
Bank_Level_Parallism_Col = 9.810197
Bank_Level_Parallism_Ready = 5.076949
write_to_read_ratio_blp_rw_average = 0.482276
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.916226 
total_CMD = 272841 
util_bw = 249984 
Wasted_Col = 20521 
Wasted_Row = 3 
Idle = 2333 

BW Util Bottlenecks: 
RCDc_limit = 3743 
RCDWRc_limit = 1119 
WTRc_limit = 90320 
RTWc_limit = 86473 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 90320 
RTWc_limit_alone = 86473 

Commands details: 
total_CMD = 272841 
n_nop = 136330 
Read = 62496 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 7098 
n_pre = 7082 
n_ref = 0 
n_req = 31248 
total_req = 124992 

Dual Bus Interface Util: 
issued_total_row = 14180 
issued_total_col = 124992 
Row_Bus_Util =  0.051972 
CoL_Bus_Util = 0.458113 
Either_Row_CoL_Bus_Util = 0.500332 
Issued_on_Two_Bus_Simul_Util = 0.009753 
issued_two_Eff = 0.019493 
queue_avg = 62.929104 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=62.9291

========= L2 cache stats =========
L2_cache_bank[0]: Access = 11759, Miss = 11721, Miss_rate = 0.997, Pending_hits = 38, Reservation_fails = 53
L2_cache_bank[1]: Access = 11739, Miss = 11720, Miss_rate = 0.998, Pending_hits = 19, Reservation_fails = 52
L2_cache_bank[2]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 34
L2_cache_bank[3]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 36
L2_cache_bank[4]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 67
L2_cache_bank[5]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 68
L2_cache_bank[6]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 57
L2_cache_bank[7]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 44
L2_cache_bank[8]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 124
L2_cache_bank[9]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 118
L2_cache_bank[10]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 91
L2_cache_bank[11]: Access = 11719, Miss = 11719, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 108
L2_cache_bank[12]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 98
L2_cache_bank[13]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 106
L2_cache_bank[14]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 148
L2_cache_bank[15]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 154
L2_total_cache_accesses = 187560
L2_total_cache_misses = 187503
L2_total_cache_miss_rate = 0.9997
L2_total_cache_pending_hits = 57
L2_total_cache_reservation_fails = 1358
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 125000
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 19
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 1
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 19
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 62500
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 1358
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 38
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 2
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 38
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 125000
	L2_cache_stats_breakdown[CONST_ACC_R][TOTAL_ACCESS] = 20
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 62500
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 40
L2_total_cache_reservation_fail_breakdown:
	L2_cache_stats_fail_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 1358
L2_cache_data_port_util = 0.000
L2_cache_fill_port_util = 0.294

icnt_total_pkts_mem_to_simt=687760
icnt_total_pkts_simt_to_mem=437560
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 145.921
	minimum = 6
	maximum = 2307
Network latency average = 86.7295
	minimum = 6
	maximum = 1709
Slowest packet = 3679
Flit latency average = 47.4936
	minimum = 6
	maximum = 1709
Slowest flit = 4880
Fragmentation average = 1.02884
	minimum = 0
	maximum = 1313
Injected packet rate average = 0.0255293
	minimum = 0 (at node 36)
	maximum = 0.0400137 (at node 20)
Accepted packet rate average = 0.0255293
	minimum = 0 (at node 36)
	maximum = 0.0400137 (at node 20)
Injected flit rate average = 0.0765852
	minimum = 0 (at node 36)
	maximum = 0.146767 (at node 20)
Accepted flit rate average= 0.0765852
	minimum = 0 (at node 36)
	maximum = 0.121171 (at node 12)
Injected packet length average = 2.99989
Accepted packet length average = 2.99989
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 145.921 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2307 (1 samples)
Network latency average = 86.7295 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1709 (1 samples)
Flit latency average = 47.4936 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1709 (1 samples)
Fragmentation average = 1.02884 (1 samples)
	minimum = 0 (1 samples)
	maximum = 1313 (1 samples)
Injected packet rate average = 0.0255293 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0400137 (1 samples)
Accepted packet rate average = 0.0255293 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0400137 (1 samples)
Injected flit rate average = 0.0765852 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.146767 (1 samples)
Accepted flit rate average = 0.0765852 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.121171 (1 samples)
Injected packet size average = 2.99989 (1 samples)
Accepted packet size average = 2.99989 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 2 min, 34 sec (154 sec)
gpgpu_simulation_rate = 136395 (inst/sec)
gpgpu_simulation_rate = 1035 (cycle/sec)
gpgpu_silicon_slowdown = 1552657x
Final sum = 1000000.000000; sum/n = 1.000000 (should be ~1)
GPGPU-Sim: *** exit detected ***
