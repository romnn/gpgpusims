GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded
Accel-Sim [build accelsim-commit-e02c99dbadefc0b9dc95317100be2a446eec142c_modified_0.0]

        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   86 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int           4,4,4,4,21 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp           4,4,4,4,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp      64,64,64,64,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                   21 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            2,2,2,2,2 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,1,1,1,2 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp      64,64,64,64,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           2 # Interconnection network mode
-inter_config_file                   mesh # Interconnection network config file
-icnt_in_buffer_limit                  512 # in_buffer_limit
-icnt_out_buffer_limit                  512 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   86 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              1536:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:4:128:256,L:R:m:N:L,T:512:8,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:8,L:R:f:N:L,S:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:64:128:16,L:R:f:N:L,S:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     S:4:128:256,L:T:m:L:L,A:384:48,16:0,32 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                   25 # L1D write ratio
-gpgpu_l1_banks                         4 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                      39 # L1 Hit Latency
-gpgpu_smem_latency                    29 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    0 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                65536 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      84 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                   32 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                  102400 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option      0,8,16,32,64,100 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                  128 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    1 # adaptive_cache_config
-gpgpu_shmem_sizeDefault               102400 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                    8 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    1 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    0 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    2 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    8 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    8 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    8 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   86 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    4 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    1 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,4,4,4,4,4,4,4,4,4,8,4,4 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    1 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     4 # Number of DP units (default=0)
-gpgpu_num_int_units                    4 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    4 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    4 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      lrr # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    1 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    4 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    2 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues          64:64:64:64 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     S:64:128:32,L:B:m:L:P,A:192:4,32:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                           12 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  192 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    2 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                   16 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=4:RRD=12:RCD=24:RAS=55:RP=24:RC=78:CL=24:WL=8:CDLR=10:WR=24:nbkgrp=4:CCDL=6:RTPL=4 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  187 # ROP queue latency (default 85)
-dram_latency                         254 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    1 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        40 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    2 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    8 # Major compute capability version number
-gpgpu_compute_capability_minor                    6 # Minor compute capability version number
-gpgpu_flush_l1_cache                    1 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1410:1410:1410:4000.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                  128 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                 5000 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
-trace               /benchrun/accelsim-sass/cuda10-matrixmul/sm86_a6000/input-wa128-ha128-wb128-hb128/results/traces/kernelslist.g # traces kernel filetraces kernel file directory
-trace_opcode_latency_initiation_int                  4,1 # Opcode latencies and initiation for integers in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_sp                  4,1 # Opcode latencies and initiation for sp in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_dp                  4,1 # Opcode latencies and initiation for dp in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_sfu                  4,1 # Opcode latencies and initiation for sfu in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_tensor                  4,1 # Opcode latencies and initiation for tensor in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_spec_op_1                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_2                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_3                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_4                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_5                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_6                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_7                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_8                  4,4 # specialized unit config <latency,initiation>
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     4 # column to column delay
RRD                                    12 # minimal delay between activation of rows in different banks
RCD                                    24 # row to column delay
RAS                                    55 # time needed to activate row
RP                                     24 # time needed to precharge (deactivate) row
RC                                     78 # row cycle time
CDLR                                   10 # switching from write to read (changes tWTR)
WR                                     24 # last data-in to row precharge
CL                                     24 # CAS latency
WL                                      8 # Write latency
nbkgrp                                  4 # number of bank groups
CCDL                                    6 # column to column delay between accesses to different bank groups
RTPL                                    4 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 24
addr_dec_mask[CHIP]  = 0000000000000000 	high:64 low:0
addr_dec_mask[BK]    = 0000000000007080 	high:15 low:7
addr_dec_mask[ROW]   = 000000000fff8000 	high:28 low:15
addr_dec_mask[COL]   = 0000000000000f7f 	high:12 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1410000000.000000:1410000000.000000:1410000000.000000:4000000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000070921985816:0.00000000070921985816:0.00000000070921985816:0.00000000025000000000
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: performance model initialization complete.
Processing kernel /benchrun/accelsim-sass/cuda10-matrixmul/sm86_a6000/input-wa128-ha128-wb128-hb128/results/traces/kernel-1.traceg
-kernel name = _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii
-kernel id = 1
-grid dim = (4,4,1)
-block dim = (32,32,1)
-shmem = 8192
-nregs = 30
-binary version = 61
-cuda stream id = 94300396006160
-shmem base_addr = 0x00007f73d2000000
-local mem base_addr = 0x00007f73d0000000
-nvbit version = 1.5.5
-accelsim tracer version = 3
Header info loaded for kernel command : /benchrun/accelsim-sass/cuda10-matrixmul/sm86_a6000/input-wa128-ha128-wb128-hb128/results/traces/kernel-1.traceg
launching kernel name: _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii uid: 1
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: CTA/core = 1, limited by: threads
GPGPU-Sim: Reconfigure L1 cache to 120KB
thread block = 0,0,0
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 1,0,0
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 2,0,0
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 3,0,0
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 0,1,0
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 1,1,0
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 2,1,0
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 3,1,0
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 0,2,0
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 1,2,0
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 2,2,0
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 3,2,0
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 0,3,0
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 1,3,0
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 2,3,0
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 3,3,0
Destroy streams for kernel 1: size 0
kernel_name = _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii 
kernel_launch_uid = 1 
gpu_sim_cycle = 15113
gpu_sim_insn = 6750208
gpu_ipc =     446.6491
gpu_tot_sim_cycle = 15113
gpu_tot_sim_insn = 6750208
gpu_tot_ipc =     446.6491
gpu_tot_issued_cta = 16
gpu_occupancy = 66.2133% 
gpu_tot_occupancy = 66.2133% 
max_total_param_size = 0
gpu_stall_dramfull = 0
gpu_stall_icnt2sh    = 0
partiton_level_parallism =       1.2196
partiton_level_parallism_total  =       1.2196
partiton_level_parallism_util =       9.7782
partiton_level_parallism_util_total  =       9.7782
L2_BW  =      55.0289 GB/Sec
L2_BW_total  =      55.0289 GB/Sec
gpu_total_sim_rate=355274

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 0
	L1I_total_cache_misses = 0
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 0
L1D_cache:
	L1D_cache_core[0]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1542
	L1D_cache_core[1]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1537
	L1D_cache_core[2]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1552
	L1D_cache_core[3]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1552
	L1D_cache_core[4]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1531
	L1D_cache_core[5]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1545
	L1D_cache_core[6]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1544
	L1D_cache_core[7]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1537
	L1D_cache_core[8]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1533
	L1D_cache_core[9]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1537
	L1D_cache_core[10]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1532
	L1D_cache_core[11]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1540
	L1D_cache_core[12]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1552
	L1D_cache_core[13]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1537
	L1D_cache_core[14]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1537
	L1D_cache_core[15]: Access = 1152, Miss = 1152, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 1554
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[20]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[21]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[22]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[23]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[24]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[25]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[26]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[27]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[28]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[29]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[30]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[31]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[32]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[33]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[34]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[35]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[36]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[37]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[38]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[39]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[40]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[41]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[42]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[43]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[44]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[45]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[46]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[47]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[48]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[49]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[50]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[51]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[52]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[53]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[54]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[55]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[56]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[57]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[58]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[59]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[60]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[61]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[62]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[63]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[64]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[65]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[66]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[67]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[68]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[69]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[70]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[71]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[72]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[73]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[74]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[75]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[76]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[77]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[78]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[79]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[80]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[81]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[82]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[83]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 18432
	L1D_total_cache_misses = 18432
	L1D_total_cache_miss_rate = 1.0000
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 24662
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.102
L1C_cache:
	L1C_total_cache_accesses = 0
	L1C_total_cache_misses = 0
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 0
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 4096
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 22101
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 12288
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 512
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 2561
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 1536
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 16384
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 2048

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[GLOBAL_ACC_R][MISS_QUEUE_FULL] = 22101
	Total_core_cache_fail_stats_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 2561
ctas_completed 16, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 
distro:
414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 414, 
gpgpu_n_tot_thrd_icount = 6782976
gpgpu_n_tot_w_icount = 211968
gpgpu_n_stall_shd_mem = 7145
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 16384
gpgpu_n_mem_write_global = 2048
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 0
gpgpu_n_load_insn  = 131072
gpgpu_n_store_insn = 16384
gpgpu_n_shmem_insn = 2752512
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 0
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][resource_stall] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 7145
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 0
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:233716	W0_Idle:27706	W0_Scoreboard:171794	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:210944
single_issue_nums: WS0:52992	WS1:52992	WS2:52992	WS3:52992	
dual_issue_nums: WS0:0	WS1:0	WS2:0	WS3:0	
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 131072 {8:16384,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 81920 {40:2048,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 655360 {40:16384,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 16384 {8:2048,}
maxmflatency = 867 
max_icnt2mem_latency = 330 
maxmrqlatency = 57 
max_icnt2sh_latency = 143 
averagemflatency = 568 
avg_icnt2mem_latency = 151 
avg_mrq_latency = 1 
avg_icnt2sh_latency = 33 
mrq_lat_table:3270 	195 	216 	286 	105 	24 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	305 	4451 	13676 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	0 	0 	0 	1986 	5637 	9825 	984 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	3038 	2792 	2529 	2809 	3911 	3121 	232 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	0 	1 	7 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[8]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[9]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[10]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[11]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
maximum service time to same row:
dram[0]:         0         0         0         0         0         0         0         0         0         0      5898      8190      5903      5973      8215      8265 
dram[1]:         0         0         0         0         0         0         0         0         0         0      5917      8200      5909      5980      8217      8258 
dram[2]:         0         0         0         0         0         0         0         0         0         0      5896      8203      5899      5972      8226      8268 
dram[3]:         0         0         0         0         0         0         0         0         0         0      5914      8189      5916      5979      8213      8231 
dram[4]:         0         0         0         0         0         0         0         0         0         0      5909      8182      5929      5978      8261      8285 
dram[5]:         0         0         0         0         0         0         0         0         0         0      5909      8213      5902      5986      8247      8254 
dram[6]:         0         0         0         0         0         0         0         0         0         0      5924      8186      5928      5965      8212      8272 
dram[7]:         0         0         0         0         0         0         0         0         0         0      5910      8202      5933      5980      8245      8236 
dram[8]:         0         0         0         0         0         0         0         0         0         0      5902      8203      5895      5974      8278      8282 
dram[9]:         0         0         0         0         0         0         0         0         0         0      5896      8210      5935      5988      8235      8260 
dram[10]:         0         0         0         0         0         0         0         0         0         0      5896      8185      5906      5973      8268      8272 
dram[11]:         0         0         0         0         0         0         0         0         0         0      5915      8181      5898      5986      8240      8259 
average row accesses per activate:
dram[0]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 64.000000 64.000000 96.000000 96.000000 96.000000 96.000000 
dram[1]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 64.000000 64.000000 96.000000 96.000000 96.000000 96.000000 
dram[2]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 64.000000 64.000000 96.000000 96.000000 96.000000 96.000000 
dram[3]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 64.000000 64.000000 96.000000 96.000000 96.000000 96.000000 
dram[4]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 36.000000 36.000000 48.000000 48.000000 48.000000 48.000000 
dram[5]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 36.000000 36.000000 48.000000 48.000000 48.000000 48.000000 
dram[6]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 36.000000 36.000000 48.000000 48.000000 48.000000 48.000000 
dram[7]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 36.000000 36.000000 48.000000 48.000000 48.000000 48.000000 
dram[8]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 28.000000 28.000000 48.000000 48.000000 48.000000 48.000000 
dram[9]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 28.000000 28.000000 48.000000 48.000000 48.000000 48.000000 
dram[10]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 28.000000 28.000000 48.000000 48.000000 48.000000 48.000000 
dram[11]:      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan      -nan 28.000000 28.000000 48.000000 48.000000 48.000000 48.000000 
average row locality = 4096/72 = 56.888889
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[8]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[9]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[10]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[11]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:         0         0         0         0         0         0         0         0         0         0        64        64        96        96        96        96 
dram[1]:         0         0         0         0         0         0         0         0         0         0        64        64        96        96        96        96 
dram[2]:         0         0         0         0         0         0         0         0         0         0        64        64        96        96        96        96 
dram[3]:         0         0         0         0         0         0         0         0         0         0        64        64        96        96        96        96 
dram[4]:         0         0         0         0         0         0         0         0         0         0        36        36        48        48        48        48 
dram[5]:         0         0         0         0         0         0         0         0         0         0        36        36        48        48        48        48 
dram[6]:         0         0         0         0         0         0         0         0         0         0        36        36        48        48        48        48 
dram[7]:         0         0         0         0         0         0         0         0         0         0        36        36        48        48        48        48 
dram[8]:         0         0         0         0         0         0         0         0         0         0        28        28        48        48        48        48 
dram[9]:         0         0         0         0         0         0         0         0         0         0        28        28        48        48        48        48 
dram[10]:         0         0         0         0         0         0         0         0         0         0        28        28        48        48        48        48 
dram[11]:         0         0         0         0         0         0         0         0         0         0        28        28        48        48        48        48 
total dram reads = 4096
min_bank_accesses = 0!
chip skew: 512/248 = 2.06
number of total write accesses:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[8]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[9]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[10]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[11]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total dram writes = 0
min_bank_accesses = 0!
min_chip_accesses = 0!
average mf latency per bank:
dram[0]:     none      none      none      none      none      none      none      none      none      none        2407      2310      2460      2410      2496      2559
dram[1]:     none      none      none      none      none      none      none      none      none      none        2470      2424      2422      2514      2654      2575
dram[2]:     none      none      none      none      none      none      none      none      none      none        2427      2433      2455      2433      2564      2546
dram[3]:     none      none      none      none      none      none      none      none      none      none        2450      2348      2428      2429      2590      2570
dram[4]:     none      none      none      none      none      none      none      none      none      none        2135      2120      2302      2311      2358      2325
dram[5]:     none      none      none      none      none      none      none      none      none      none        2221      2139      2226      2303      2294      2345
dram[6]:     none      none      none      none      none      none      none      none      none      none        2221      2133      2352      2328      2284      2308
dram[7]:     none      none      none      none      none      none      none      none      none      none        2271      2166      2232      2271      2321      2351
dram[8]:     none      none      none      none      none      none      none      none      none      none        2178      2120      2223      2296      2330      2344
dram[9]:     none      none      none      none      none      none      none      none      none      none        2144      2168      2350      2313      2270      2294
dram[10]:     none      none      none      none      none      none      none      none      none      none        2164      2083      2178      2220      2326      2268
dram[11]:     none      none      none      none      none      none      none      none      none      none        2165      2051      2277      2175      2242      2293
maximum mf latency per bank:
dram[0]:        413       408       418       407         0         0         0         0         0         0       789       800       810       796       798       796
dram[1]:        404       405       413       417         0         0         0         0         0         0       802       833       800       816       847       858
dram[2]:        386       381       395       368         0         0         0         0         0         0       797       831       811       816       825       802
dram[3]:        390       397       400       373         0         0         0         0         0         0       806       792       822       795       848       867
dram[4]:        361       349       349       349         0         0         0         0         0         0       676       703       724       699       770       771
dram[5]:        353       345       351       345         0         0         0         0         0         0       697       680       693       707       764       754
dram[6]:        354       340       350       341         0         0         0         0         0         0       697       692       716       698       718       771
dram[7]:        342       336       335       338         0         0         0         0         0         0       722       676       730       724       730       713
dram[8]:        342       336       339       340         0         0         0         0         0         0       687       674       705       723       752       749
dram[9]:        350       347       342       339         0         0         0         0         0         0       691       696       703       697       733       756
dram[10]:        341       346       356       340         0         0         0         0         0         0       692       673       709       693       761       721
dram[11]:        339       343       337       340         0         0         0         0         0         0       692       657       701       714       686       747
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42353 n_act=6 n_pre=0 n_ref_event=0 n_req=512 n_rd=512 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.04777
n_activity=3709 dram_eff=0.5522
bk0: 0a 42867i bk1: 0a 42868i bk2: 0a 42868i bk3: 0a 42869i bk4: 0a 42871i bk5: 0a 42872i bk6: 0a 42872i bk7: 0a 42872i bk8: 0a 42872i bk9: 0a 42873i bk10: 64a 42617i bk11: 64a 42541i bk12: 96a 42427i bk13: 96a 42476i bk14: 96a 42621i bk15: 96a 42550i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.988281
Row_Buffer_Locality_read = 0.988281
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.573224
Bank_Level_Parallism_Col = 1.570799
Bank_Level_Parallism_Ready = 1.146484
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.514160 

BW Util details:
bwutil = 0.047771 
total_CMD = 42871 
util_bw = 2048 
Wasted_Col = 210 
Wasted_Row = 0 
Idle = 40613 

BW Util Bottlenecks: 
RCDc_limit = 59 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 186 
rwq = 0 
CCDLc_limit_alone = 186 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42353 
Read = 512 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 512 
total_req = 512 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 512 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.011943 
Either_Row_CoL_Bus_Util = 0.012083 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.075832 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=9 avg=0.0758322
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42353 n_act=6 n_pre=0 n_ref_event=0 n_req=512 n_rd=512 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.04777
n_activity=3655 dram_eff=0.5603
bk0: 0a 42868i bk1: 0a 42869i bk2: 0a 42870i bk3: 0a 42870i bk4: 0a 42870i bk5: 0a 42870i bk6: 0a 42872i bk7: 0a 42872i bk8: 0a 42873i bk9: 0a 42874i bk10: 64a 42527i bk11: 64a 42515i bk12: 96a 42482i bk13: 96a 42489i bk14: 96a 42457i bk15: 96a 42595i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.988281
Row_Buffer_Locality_read = 0.988281
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.559579
Bank_Level_Parallism_Col = 1.559719
Bank_Level_Parallism_Ready = 1.169922
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.438525 

BW Util details:
bwutil = 0.047771 
total_CMD = 42871 
util_bw = 2048 
Wasted_Col = 289 
Wasted_Row = 0 
Idle = 40534 

BW Util Bottlenecks: 
RCDc_limit = 96 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 216 
rwq = 0 
CCDLc_limit_alone = 216 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42353 
Read = 512 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 512 
total_req = 512 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 512 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.011943 
Either_Row_CoL_Bus_Util = 0.012083 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.127312 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=21 avg=0.127312
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42353 n_act=6 n_pre=0 n_ref_event=0 n_req=512 n_rd=512 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.04777
n_activity=3627 dram_eff=0.5647
bk0: 0a 42867i bk1: 0a 42869i bk2: 0a 42869i bk3: 0a 42870i bk4: 0a 42870i bk5: 0a 42872i bk6: 0a 42872i bk7: 0a 42872i bk8: 0a 42872i bk9: 0a 42873i bk10: 64a 42578i bk11: 64a 42525i bk12: 96a 42416i bk13: 96a 42526i bk14: 96a 42579i bk15: 96a 42493i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.988281
Row_Buffer_Locality_read = 0.988281
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.533412
Bank_Level_Parallism_Col = 1.529343
Bank_Level_Parallism_Ready = 1.150391
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.453052 

BW Util details:
bwutil = 0.047771 
total_CMD = 42871 
util_bw = 2048 
Wasted_Col = 247 
Wasted_Row = 0 
Idle = 40576 

BW Util Bottlenecks: 
RCDc_limit = 62 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 219 
rwq = 0 
CCDLc_limit_alone = 219 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42353 
Read = 512 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 512 
total_req = 512 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 512 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.011943 
Either_Row_CoL_Bus_Util = 0.012083 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.091530 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=12 avg=0.0915304
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42353 n_act=6 n_pre=0 n_ref_event=0 n_req=512 n_rd=512 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.04777
n_activity=3619 dram_eff=0.5659
bk0: 0a 42867i bk1: 0a 42868i bk2: 0a 42868i bk3: 0a 42868i bk4: 0a 42869i bk5: 0a 42872i bk6: 0a 42872i bk7: 0a 42873i bk8: 0a 42873i bk9: 0a 42874i bk10: 64a 42623i bk11: 64a 42519i bk12: 96a 42480i bk13: 96a 42528i bk14: 96a 42447i bk15: 96a 42419i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.988281
Row_Buffer_Locality_read = 0.988281
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.684211
Bank_Level_Parallism_Col = 1.679901
Bank_Level_Parallism_Ready = 1.238281
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.564516 

BW Util details:
bwutil = 0.047771 
total_CMD = 42871 
util_bw = 2048 
Wasted_Col = 240 
Wasted_Row = 0 
Idle = 40583 

BW Util Bottlenecks: 
RCDc_limit = 95 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 164 
rwq = 0 
CCDLc_limit_alone = 164 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42353 
Read = 512 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 512 
total_req = 512 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 512 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.011943 
Either_Row_CoL_Bus_Util = 0.012083 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.118915 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=21 avg=0.118915
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42601 n_act=6 n_pre=0 n_ref_event=0 n_req=264 n_rd=264 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.02463
n_activity=2953 dram_eff=0.3576
bk0: 0a 42867i bk1: 0a 42868i bk2: 0a 42870i bk3: 0a 42870i bk4: 0a 42870i bk5: 0a 42872i bk6: 0a 42872i bk7: 0a 42872i bk8: 0a 42873i bk9: 0a 42873i bk10: 36a 42736i bk11: 36a 42750i bk12: 48a 42776i bk13: 48a 42719i bk14: 48a 42814i bk15: 48a 42791i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.977273
Row_Buffer_Locality_read = 0.977273
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.112485
Bank_Level_Parallism_Col = 1.110559
Bank_Level_Parallism_Ready = 1.015152
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.110559 

BW Util details:
bwutil = 0.024632 
total_CMD = 42871 
util_bw = 1056 
Wasted_Col = 240 
Wasted_Row = 0 
Idle = 41575 

BW Util Bottlenecks: 
RCDc_limit = 104 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 154 
rwq = 0 
CCDLc_limit_alone = 154 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42601 
Read = 264 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 264 
total_req = 264 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 264 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.006158 
Either_Row_CoL_Bus_Util = 0.006298 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.014789 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=4 avg=0.0147886
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42601 n_act=6 n_pre=0 n_ref_event=0 n_req=264 n_rd=264 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.02463
n_activity=2951 dram_eff=0.3578
bk0: 0a 42868i bk1: 0a 42870i bk2: 0a 42870i bk3: 0a 42870i bk4: 0a 42871i bk5: 0a 42871i bk6: 0a 42871i bk7: 0a 42871i bk8: 0a 42873i bk9: 0a 42874i bk10: 36a 42735i bk11: 36a 42744i bk12: 48a 42739i bk13: 48a 42761i bk14: 48a 42808i bk15: 48a 42798i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.977273
Row_Buffer_Locality_read = 0.977273
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.209396
Bank_Level_Parallism_Col = 1.207827
Bank_Level_Parallism_Ready = 1.026515
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.175439 

BW Util details:
bwutil = 0.024632 
total_CMD = 42871 
util_bw = 1056 
Wasted_Col = 183 
Wasted_Row = 0 
Idle = 41632 

BW Util Bottlenecks: 
RCDc_limit = 96 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 106 
rwq = 0 
CCDLc_limit_alone = 106 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42601 
Read = 264 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 264 
total_req = 264 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 264 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.006158 
Either_Row_CoL_Bus_Util = 0.006298 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.010870 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=4 avg=0.0108698
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42601 n_act=6 n_pre=0 n_ref_event=0 n_req=264 n_rd=264 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.02463
n_activity=2897 dram_eff=0.3645
bk0: 0a 42870i bk1: 0a 42871i bk2: 0a 42871i bk3: 0a 42871i bk4: 0a 42871i bk5: 0a 42872i bk6: 0a 42872i bk7: 0a 42872i bk8: 0a 42872i bk9: 0a 42872i bk10: 36a 42740i bk11: 36a 42707i bk12: 48a 42752i bk13: 48a 42782i bk14: 48a 42818i bk15: 48a 42822i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.977273
Row_Buffer_Locality_read = 0.977273
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.159030
Bank_Level_Parallism_Col = 1.158752
Bank_Level_Parallism_Ready = 1.018939
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.158752 

BW Util details:
bwutil = 0.024632 
total_CMD = 42871 
util_bw = 1056 
Wasted_Col = 214 
Wasted_Row = 0 
Idle = 41601 

BW Util Bottlenecks: 
RCDc_limit = 124 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 106 
rwq = 0 
CCDLc_limit_alone = 106 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42601 
Read = 264 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 264 
total_req = 264 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 264 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.006158 
Either_Row_CoL_Bus_Util = 0.006298 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.016795 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=5 avg=0.0167946
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents

Cache L2_bank_015:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42601 n_act=6 n_pre=0 n_ref_event=0 n_req=264 n_rd=264 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.02463
n_activity=2957 dram_eff=0.3571
bk0: 0a 42867i bk1: 0a 42869i bk2: 0a 42869i bk3: 0a 42869i bk4: 0a 42871i bk5: 0a 42872i bk6: 0a 42872i bk7: 0a 42872i bk8: 0a 42873i bk9: 0a 42873i bk10: 36a 42736i bk11: 36a 42743i bk12: 48a 42702i bk13: 48a 42734i bk14: 48a 42803i bk15: 48a 42818i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.977273
Row_Buffer_Locality_read = 0.977273
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.130797
Bank_Level_Parallism_Col = 1.131737
Bank_Level_Parallism_Ready = 1.015152
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.122156 

BW Util details:
bwutil = 0.024632 
total_CMD = 42871 
util_bw = 1056 
Wasted_Col = 251 
Wasted_Row = 0 
Idle = 41564 

BW Util Bottlenecks: 
RCDc_limit = 123 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 134 
rwq = 0 
CCDLc_limit_alone = 134 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42601 
Read = 264 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 264 
total_req = 264 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 264 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.006158 
Either_Row_CoL_Bus_Util = 0.006298 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.015558 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=5 avg=0.0155583
Memory Partition 8: 
Cache L2_bank_016:
MSHR contents

Cache L2_bank_017:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[8]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42617 n_act=6 n_pre=0 n_ref_event=0 n_req=248 n_rd=248 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.02314
n_activity=2798 dram_eff=0.3545
bk0: 0a 42866i bk1: 0a 42869i bk2: 0a 42869i bk3: 0a 42871i bk4: 0a 42871i bk5: 0a 42872i bk6: 0a 42872i bk7: 0a 42872i bk8: 0a 42873i bk9: 0a 42874i bk10: 28a 42791i bk11: 28a 42700i bk12: 48a 42745i bk13: 48a 42736i bk14: 48a 42802i bk15: 48a 42729i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.975806
Row_Buffer_Locality_read = 0.975806
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.318306
Bank_Level_Parallism_Col = 1.317308
Bank_Level_Parallism_Ready = 1.084677
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.215659 

BW Util details:
bwutil = 0.023139 
total_CMD = 42871 
util_bw = 992 
Wasted_Col = 190 
Wasted_Row = 0 
Idle = 41689 

BW Util Bottlenecks: 
RCDc_limit = 90 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 128 
rwq = 0 
CCDLc_limit_alone = 128 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42617 
Read = 248 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 248 
total_req = 248 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 248 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.005785 
Either_Row_CoL_Bus_Util = 0.005925 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.017098 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=6 avg=0.0170978
Memory Partition 9: 
Cache L2_bank_018:
MSHR contents

Cache L2_bank_019:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[9]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42617 n_act=6 n_pre=0 n_ref_event=0 n_req=248 n_rd=248 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.02314
n_activity=2681 dram_eff=0.37
bk0: 0a 42866i bk1: 0a 42868i bk2: 0a 42869i bk3: 0a 42870i bk4: 0a 42870i bk5: 0a 42872i bk6: 0a 42873i bk7: 0a 42873i bk8: 0a 42873i bk9: 0a 42873i bk10: 28a 42783i bk11: 28a 42766i bk12: 48a 42779i bk13: 48a 42779i bk14: 48a 42759i bk15: 48a 42722i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.975806
Row_Buffer_Locality_read = 0.975806
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.145266
Bank_Level_Parallism_Col = 1.146405
Bank_Level_Parallism_Ready = 1.064516
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.117647 

BW Util details:
bwutil = 0.023139 
total_CMD = 42871 
util_bw = 992 
Wasted_Col = 247 
Wasted_Row = 0 
Idle = 41632 

BW Util Bottlenecks: 
RCDc_limit = 119 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 136 
rwq = 0 
CCDLc_limit_alone = 136 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42617 
Read = 248 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 248 
total_req = 248 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 248 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.005785 
Either_Row_CoL_Bus_Util = 0.005925 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.006951 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=3 avg=0.00695109
Memory Partition 10: 
Cache L2_bank_020:
MSHR contents

Cache L2_bank_021:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[10]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42617 n_act=6 n_pre=0 n_ref_event=0 n_req=248 n_rd=248 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.02314
n_activity=2861 dram_eff=0.3467
bk0: 0a 42868i bk1: 0a 42871i bk2: 0a 42871i bk3: 0a 42871i bk4: 0a 42871i bk5: 0a 42872i bk6: 0a 42872i bk7: 0a 42872i bk8: 0a 42873i bk9: 0a 42873i bk10: 28a 42777i bk11: 28a 42770i bk12: 48a 42762i bk13: 48a 42752i bk14: 48a 42823i bk15: 48a 42816i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.975806
Row_Buffer_Locality_read = 0.975806
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.110145
Bank_Level_Parallism_Col = 1.106414
Bank_Level_Parallism_Ready = 1.012097
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.106414 

BW Util details:
bwutil = 0.023139 
total_CMD = 42871 
util_bw = 992 
Wasted_Col = 194 
Wasted_Row = 0 
Idle = 41685 

BW Util Bottlenecks: 
RCDc_limit = 124 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 88 
rwq = 0 
CCDLc_limit_alone = 88 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42617 
Read = 248 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 248 
total_req = 248 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 248 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.005785 
Either_Row_CoL_Bus_Util = 0.005925 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.009377 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=3 avg=0.00937697
Memory Partition 11: 
Cache L2_bank_022:
MSHR contents

Cache L2_bank_023:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[11]: 16 bks, busW=2 BL=16 CL=24, tRRD=12 tCCD=4, tRCD=24 tRAS=55 tRP=24 tRC=78
n_cmd=42871 n_nop=42617 n_act=6 n_pre=0 n_ref_event=0 n_req=248 n_rd=248 n_rd_L2_A=0 n_write=0 n_wr_bk=0 bw_util=0.02314
n_activity=2760 dram_eff=0.3594
bk0: 0a 42865i bk1: 0a 42869i bk2: 0a 42870i bk3: 0a 42870i bk4: 0a 42872i bk5: 0a 42872i bk6: 0a 42872i bk7: 0a 42873i bk8: 0a 42873i bk9: 0a 42874i bk10: 28a 42771i bk11: 28a 42762i bk12: 48a 42774i bk13: 48a 42742i bk14: 48a 42782i bk15: 48a 42785i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.975806
Row_Buffer_Locality_read = 0.975806
Row_Buffer_Locality_write = -nan
Bank_Level_Parallism = 1.115033
Bank_Level_Parallism_Col = 1.114474
Bank_Level_Parallism_Ready = 1.016064
write_to_read_ratio_blp_rw_average = 0.000000
GrpLevelPara = 1.114474 

BW Util details:
bwutil = 0.023139 
total_CMD = 42871 
util_bw = 992 
Wasted_Col = 236 
Wasted_Row = 0 
Idle = 41643 

BW Util Bottlenecks: 
RCDc_limit = 115 
RCDWRc_limit = 0 
WTRc_limit = 0 
RTWc_limit = 0 
CCDLc_limit = 129 
rwq = 0 
CCDLc_limit_alone = 129 
WTRc_limit_alone = 0 
RTWc_limit_alone = 0 

Commands details: 
total_CMD = 42871 
n_nop = 42617 
Read = 248 
Write = 0 
L2_Alloc = 0 
L2_WB = 0 
n_act = 6 
n_pre = 0 
n_ref = 0 
n_req = 248 
total_req = 248 

Dual Bus Interface Util: 
issued_total_row = 6 
issued_total_col = 248 
Row_Bus_Util =  0.000140 
CoL_Bus_Util = 0.005785 
Either_Row_CoL_Bus_Util = 0.005925 
Issued_on_Two_Bus_Simul_Util = 0.000000 
issued_two_Eff = 0.000000 
queue_avg = 0.011360 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=3 avg=0.0113597

========= L2 cache stats =========
L2_cache_bank[0]: Access = 1152, Miss = 384, Miss_rate = 0.333, Pending_hits = 756, Reservation_fails = 0
L2_cache_bank[1]: Access = 1152, Miss = 384, Miss_rate = 0.333, Pending_hits = 744, Reservation_fails = 0
L2_cache_bank[2]: Access = 1152, Miss = 384, Miss_rate = 0.333, Pending_hits = 747, Reservation_fails = 0
L2_cache_bank[3]: Access = 1152, Miss = 384, Miss_rate = 0.333, Pending_hits = 746, Reservation_fails = 0
L2_cache_bank[4]: Access = 1152, Miss = 384, Miss_rate = 0.333, Pending_hits = 761, Reservation_fails = 0
L2_cache_bank[5]: Access = 1152, Miss = 384, Miss_rate = 0.333, Pending_hits = 749, Reservation_fails = 0
L2_cache_bank[6]: Access = 1152, Miss = 384, Miss_rate = 0.333, Pending_hits = 748, Reservation_fails = 0
L2_cache_bank[7]: Access = 1152, Miss = 384, Miss_rate = 0.333, Pending_hits = 753, Reservation_fails = 0
L2_cache_bank[8]: Access = 592, Miss = 196, Miss_rate = 0.331, Pending_hits = 388, Reservation_fails = 0
L2_cache_bank[9]: Access = 592, Miss = 196, Miss_rate = 0.331, Pending_hits = 387, Reservation_fails = 0
L2_cache_bank[10]: Access = 592, Miss = 196, Miss_rate = 0.331, Pending_hits = 390, Reservation_fails = 0
L2_cache_bank[11]: Access = 592, Miss = 196, Miss_rate = 0.331, Pending_hits = 380, Reservation_fails = 0
L2_cache_bank[12]: Access = 592, Miss = 196, Miss_rate = 0.331, Pending_hits = 390, Reservation_fails = 0
L2_cache_bank[13]: Access = 592, Miss = 196, Miss_rate = 0.331, Pending_hits = 387, Reservation_fails = 0
L2_cache_bank[14]: Access = 592, Miss = 196, Miss_rate = 0.331, Pending_hits = 389, Reservation_fails = 0
L2_cache_bank[15]: Access = 592, Miss = 196, Miss_rate = 0.331, Pending_hits = 385, Reservation_fails = 0
L2_cache_bank[16]: Access = 560, Miss = 188, Miss_rate = 0.336, Pending_hits = 365, Reservation_fails = 0
L2_cache_bank[17]: Access = 560, Miss = 188, Miss_rate = 0.336, Pending_hits = 361, Reservation_fails = 0
L2_cache_bank[18]: Access = 560, Miss = 188, Miss_rate = 0.336, Pending_hits = 364, Reservation_fails = 0
L2_cache_bank[19]: Access = 560, Miss = 188, Miss_rate = 0.336, Pending_hits = 369, Reservation_fails = 0
L2_cache_bank[20]: Access = 560, Miss = 188, Miss_rate = 0.336, Pending_hits = 368, Reservation_fails = 0
L2_cache_bank[21]: Access = 560, Miss = 188, Miss_rate = 0.336, Pending_hits = 361, Reservation_fails = 0
L2_cache_bank[22]: Access = 560, Miss = 188, Miss_rate = 0.336, Pending_hits = 356, Reservation_fails = 0
L2_cache_bank[23]: Access = 560, Miss = 188, Miss_rate = 0.336, Pending_hits = 359, Reservation_fails = 0
L2_total_cache_accesses = 18432
L2_total_cache_misses = 6144
L2_total_cache_miss_rate = 0.3333
L2_total_cache_pending_hits = 12003
L2_total_cache_reservation_fails = 0
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 285
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 12003
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 1024
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 3072
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 12003
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 512
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 1536
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 16384
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 2048
L2_total_cache_reservation_fail_breakdown:
L2_cache_data_port_util = 0.001
L2_cache_fill_port_util = 0.011

icnt_total_pkts_mem_to_simt=18432
icnt_total_pkts_simt_to_mem=18432
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Req_Network_injected_packets_num = 18432
Req_Network_cycles = 15113
Req_Network_injected_packets_per_cycle =       1.2196 
Req_Network_conflicts_per_cycle =       0.6927
Req_Network_conflicts_per_cycle_util =       5.5538
Req_Bank_Level_Parallism =       9.7782
Req_Network_in_buffer_full_per_cycle =       0.0000
Req_Network_in_buffer_avg_util =       0.7213
Req_Network_out_buffer_full_per_cycle =       0.0000
Req_Network_out_buffer_avg_util =       0.0508

Reply_Network_injected_packets_num = 18432
Reply_Network_cycles = 15113
Reply_Network_injected_packets_per_cycle =        1.2196
Reply_Network_conflicts_per_cycle =        0.9174
Reply_Network_conflicts_per_cycle_util =       7.3907
Reply_Bank_Level_Parallism =       9.8252
Reply_Network_in_buffer_full_per_cycle =       0.0000
Reply_Network_in_buffer_avg_util =       1.5318
Reply_Network_out_buffer_full_per_cycle =       0.0000
Reply_Network_out_buffer_avg_util =       0.0145
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 0 min, 19 sec (19 sec)
gpgpu_simulation_rate = 355274 (inst/sec)
gpgpu_simulation_rate = 795 (cycle/sec)
gpgpu_silicon_slowdown = 1773584x
GPGPU-Sim: *** simulation thread exiting ***
GPGPU-Sim: *** exit detected ***
