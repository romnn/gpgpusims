GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded
Accel-Sim [build accelsim-commit-e02c99dbadefc0b9dc95317100be2a446eec142c_modified_0.0]

        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:1607.0:1607.0:2500.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
-trace               /benchrun/accelsim-sass/sm6_gtx1080/cuda10-matrixmul/input-wa512-ha512-wb512-hb512/results/traces/kernelslist.g # traces kernel filetraces kernel file directory
-trace_opcode_latency_initiation_int                  4,1 # Opcode latencies and initiation for integers in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_sp                  4,1 # Opcode latencies and initiation for sp in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_dp                  4,1 # Opcode latencies and initiation for dp in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_sfu                  4,1 # Opcode latencies and initiation for sfu in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_tensor                  4,1 # Opcode latencies and initiation for tensor in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_spec_op_1                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_2                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_3                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_4                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_5                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_6                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_7                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_8                  4,4 # specialized unit config <latency,initiation>
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:1607000000.000000:1607000000.000000:2500000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000062227753578:0.00000000062227753578:0.00000000040000000000
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: performance model initialization complete.
Processing kernel /benchrun/accelsim-sass/sm6_gtx1080/cuda10-matrixmul/input-wa512-ha512-wb512-hb512/results/traces/kernel-1.traceg
-kernel name = _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii
-kernel id = 1
-grid dim = (16,16,1)
-block dim = (32,32,1)
-shmem = 8192
-nregs = 30
-binary version = 61
-cuda stream id = 94046710367968
-shmem base_addr = 0x00007fde0c000000
-local mem base_addr = 0x00007fde0a000000
-nvbit version = 1.5.5
-accelsim tracer version = 3
Header info loaded for kernel command : /benchrun/accelsim-sass/sm6_gtx1080/cuda10-matrixmul/input-wa512-ha512-wb512-hb512/results/traces/kernel-1.traceg
launching kernel name: _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii uid: 1
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads regs
thread block = 0,0,0
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 1,0,0
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 2,0,0
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 3,0,0
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 4,0,0
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 5,0,0
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 6,0,0
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 7,0,0
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 8,0,0
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 9,0,0
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 10,0,0
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 11,0,0
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 12,0,0
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 13,0,0
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 14,0,0
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 15,0,0
GPGPU-Sim uArch: Shader 16 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 0,1,0
GPGPU-Sim uArch: Shader 17 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 1,1,0
GPGPU-Sim uArch: Shader 18 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 2,1,0
GPGPU-Sim uArch: Shader 19 bind to kernel 1 '_Z13MatrixMulCUDAILi32EEvPfS0_S0_ii'
thread block = 3,1,0
thread block = 4,1,0
thread block = 5,1,0
thread block = 6,1,0
thread block = 7,1,0
thread block = 8,1,0
thread block = 9,1,0
thread block = 10,1,0
thread block = 11,1,0
thread block = 12,1,0
thread block = 13,1,0
thread block = 14,1,0
thread block = 15,1,0
thread block = 0,2,0
thread block = 1,2,0
thread block = 2,2,0
thread block = 3,2,0
thread block = 4,2,0
thread block = 5,2,0
thread block = 6,2,0
thread block = 7,2,0
thread block = 8,2,0
thread block = 9,2,0
thread block = 10,2,0
thread block = 11,2,0
thread block = 12,2,0
thread block = 13,2,0
thread block = 14,2,0
thread block = 15,2,0
thread block = 0,3,0
thread block = 1,3,0
thread block = 2,3,0
thread block = 3,3,0
thread block = 4,3,0
thread block = 5,3,0
thread block = 6,3,0
thread block = 7,3,0
thread block = 8,3,0
thread block = 9,3,0
thread block = 10,3,0
thread block = 11,3,0
thread block = 12,3,0
thread block = 13,3,0
thread block = 14,3,0
thread block = 15,3,0
thread block = 0,4,0
thread block = 1,4,0
thread block = 2,4,0
thread block = 3,4,0
thread block = 4,4,0
thread block = 5,4,0
thread block = 6,4,0
thread block = 7,4,0
thread block = 8,4,0
thread block = 9,4,0
thread block = 10,4,0
thread block = 11,4,0
thread block = 12,4,0
thread block = 13,4,0
thread block = 14,4,0
thread block = 15,4,0
thread block = 0,5,0
thread block = 1,5,0
thread block = 2,5,0
thread block = 3,5,0
thread block = 4,5,0
thread block = 5,5,0
thread block = 6,5,0
thread block = 7,5,0
thread block = 8,5,0
thread block = 9,5,0
thread block = 10,5,0
thread block = 11,5,0
thread block = 12,5,0
thread block = 13,5,0
thread block = 14,5,0
thread block = 15,5,0
thread block = 0,6,0
thread block = 1,6,0
thread block = 2,6,0
thread block = 3,6,0
thread block = 4,6,0
thread block = 5,6,0
thread block = 6,6,0
thread block = 7,6,0
thread block = 8,6,0
thread block = 9,6,0
thread block = 10,6,0
thread block = 11,6,0
thread block = 12,6,0
thread block = 13,6,0
thread block = 14,6,0
thread block = 15,6,0
thread block = 0,7,0
thread block = 1,7,0
thread block = 2,7,0
thread block = 3,7,0
thread block = 4,7,0
thread block = 5,7,0
thread block = 6,7,0
thread block = 7,7,0
thread block = 8,7,0
thread block = 9,7,0
thread block = 10,7,0
thread block = 11,7,0
thread block = 12,7,0
thread block = 13,7,0
thread block = 14,7,0
thread block = 15,7,0
thread block = 0,8,0
thread block = 1,8,0
thread block = 2,8,0
thread block = 3,8,0
thread block = 4,8,0
thread block = 5,8,0
thread block = 6,8,0
thread block = 7,8,0
thread block = 8,8,0
thread block = 9,8,0
thread block = 10,8,0
thread block = 11,8,0
thread block = 12,8,0
thread block = 13,8,0
thread block = 14,8,0
thread block = 15,8,0
thread block = 0,9,0
thread block = 1,9,0
thread block = 2,9,0
thread block = 3,9,0
thread block = 4,9,0
thread block = 5,9,0
thread block = 6,9,0
thread block = 7,9,0
thread block = 8,9,0
thread block = 9,9,0
thread block = 10,9,0
thread block = 11,9,0
thread block = 12,9,0
thread block = 13,9,0
thread block = 14,9,0
thread block = 15,9,0
thread block = 0,10,0
thread block = 1,10,0
thread block = 2,10,0
thread block = 3,10,0
thread block = 4,10,0
thread block = 5,10,0
thread block = 6,10,0
thread block = 7,10,0
thread block = 8,10,0
thread block = 9,10,0
thread block = 10,10,0
thread block = 11,10,0
thread block = 12,10,0
thread block = 13,10,0
thread block = 14,10,0
thread block = 15,10,0
thread block = 0,11,0
thread block = 1,11,0
thread block = 2,11,0
thread block = 3,11,0
thread block = 4,11,0
thread block = 5,11,0
thread block = 6,11,0
thread block = 7,11,0
thread block = 8,11,0
thread block = 9,11,0
thread block = 10,11,0
thread block = 11,11,0
thread block = 12,11,0
thread block = 13,11,0
thread block = 14,11,0
thread block = 15,11,0
thread block = 0,12,0
thread block = 1,12,0
thread block = 2,12,0
thread block = 3,12,0
thread block = 4,12,0
thread block = 5,12,0
thread block = 6,12,0
thread block = 7,12,0
thread block = 8,12,0
thread block = 9,12,0
thread block = 10,12,0
thread block = 11,12,0
thread block = 12,12,0
thread block = 13,12,0
thread block = 14,12,0
thread block = 15,12,0
thread block = 0,13,0
thread block = 1,13,0
thread block = 2,13,0
thread block = 3,13,0
thread block = 4,13,0
thread block = 5,13,0
thread block = 6,13,0
thread block = 7,13,0
thread block = 8,13,0
thread block = 9,13,0
thread block = 10,13,0
thread block = 11,13,0
thread block = 12,13,0
thread block = 13,13,0
thread block = 14,13,0
thread block = 15,13,0
thread block = 0,14,0
thread block = 1,14,0
thread block = 2,14,0
thread block = 3,14,0
thread block = 4,14,0
thread block = 5,14,0
thread block = 6,14,0
thread block = 7,14,0
thread block = 8,14,0
thread block = 9,14,0
thread block = 10,14,0
thread block = 11,14,0
thread block = 12,14,0
thread block = 13,14,0
thread block = 14,14,0
thread block = 15,14,0
thread block = 0,15,0
thread block = 1,15,0
thread block = 2,15,0
thread block = 3,15,0
thread block = 4,15,0
thread block = 5,15,0
thread block = 6,15,0
thread block = 7,15,0
thread block = 8,15,0
thread block = 9,15,0
thread block = 10,15,0
thread block = 11,15,0
thread block = 12,15,0
thread block = 13,15,0
thread block = 14,15,0
thread block = 15,15,0
Destroy streams for kernel 1: size 0
kernel_name = _Z13MatrixMulCUDAILi32EEvPfS0_S0_ii 
kernel_launch_uid = 1 
gpu_sim_cycle = 411494
gpu_sim_insn = 397410304
gpu_ipc =     965.7742
gpu_tot_sim_cycle = 411494
gpu_tot_sim_insn = 397410304
gpu_tot_ipc =     965.7742
gpu_tot_issued_cta = 256
gpu_occupancy = 96.1551% 
gpu_tot_occupancy = 96.1551% 
max_total_param_size = 0
gpu_stall_dramfull = 709602
gpu_stall_icnt2sh    = 1678950
partiton_level_parallism =       0.6575
partiton_level_parallism_total  =       0.6575
partiton_level_parallism_util =       1.4027
partiton_level_parallism_util_total  =       1.4027
L2_BW  =      33.8136 GB/Sec
L2_BW_total  =      33.8136 GB/Sec
gpu_total_sim_rate=1234193

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 6217728
	L1I_total_cache_misses = 9670
	L1I_total_cache_miss_rate = 0.0016
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 21466
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 0
	L1C_total_cache_misses = 0
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 0
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 6208058
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 9670
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 21466
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 9430
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 6217728

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[INST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 21466
ctas_completed 256, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
distro:
11220, 11240, 11272, 11234, 11465, 11480, 11743, 11750, 11735, 11747, 11392, 11424, 11499, 11481, 11606, 11610, 11619, 11638, 11473, 11462, 11465, 11457, 11520, 11510, 11553, 11570, 11501, 11484, 11513, 11530, 11567, 11575, 9638, 9665, 9666, 9656, 9857, 9843, 10074, 10094, 10059, 10055, 9795, 9801, 9848, 9840, 9943, 9954, 9962, 9999, 9867, 9876, 9881, 9875, 9938, 9917, 9947, 9954, 9913, 9907, 9935, 9900, 9929, 9962, 
gpgpu_n_tot_thrd_icount = 397934592
gpgpu_n_tot_w_icount = 12435456
gpgpu_n_stall_shd_mem = 485370
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 262144
gpgpu_n_mem_write_global = 8192
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 0
gpgpu_n_load_insn  = 8388608
gpgpu_n_store_insn = 262144
gpgpu_n_shmem_insn = 176160768
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 0
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][resource_stall] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 0
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:3539891	W0_Idle:146569	W0_Scoreboard:983390	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:12419072
single_issue_nums: WS0:5164536	WS1:5160948	
dual_issue_nums: WS0:526596	WS1:528390	
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 2097152 {8:262144,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 1114112 {136:8192,}
traffic_breakdown_coretomem[INST_ACC_R] = 1920 {8:240,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 35651584 {136:262144,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 65536 {8:8192,}
traffic_breakdown_memtocore[INST_ACC_R] = 32640 {136:240,}
maxmflatency = 3217 
max_icnt2mem_latency = 2860 
maxmrqlatency = 779 
max_icnt2sh_latency = 127 
averagemflatency = 326 
avg_icnt2mem_latency = 73 
avg_mrq_latency = 106 
avg_icnt2sh_latency = 29 
mrq_lat_table:5926 	952 	1662 	2731 	5052 	2637 	3317 	4961 	5162 	380 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	128810 	108478 	28674 	3556 	818 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	0 	159665 	38309 	22545 	11174 	17361 	13939 	4681 	2273 	629 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	0 	28682 	128252 	109294 	4108 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	205 	553 	30 	24 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[5]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[6]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[7]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     59376     51467     59164     51381     57897     55117     57848     56581     57668     56286     57667     56384     58982     52554     58827     52675 
dram[1]:     48638     56276     47836     57244     61869     68049     62238     68053     62570     71572     62779     71637     60344     67471     60521     67609 
dram[2]:     60936     64260     60967     64316     61480     63380     61460     63458     62872     65891     62954     65995     61728     64555     61705     64628 
dram[3]:     65068     66918     65185     66982     65118     68115     65158     68212     69828     68334     69923     68448     65151     67629     65234     67714 
dram[4]:     67955     69758     68048     69830     69602     74867     69679     74878     66857     67422     66934     67512     67972     67973     67982     68034 
dram[5]:     72881     73555     72947     73618     72369     74021     72457     74037     71063     72815     71122     72808     70440     72232     70455     72310 
dram[6]:     74026     77003     74052     77039     78854     80527     78939     80582     73625     74835     73720     74937     68165     68947     68264     69026 
dram[7]:     77415     80465     77415     80544     79285     80870     79353     80967     76271     78353     76349     78455     70776     73490     70794     73600 
average row accesses per activate:
dram[0]: 17.133333 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 18.285715 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[1]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[2]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 18.285715 21.333334 19.692308 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[3]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[4]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[5]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[6]: 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[7]: 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
average row locality = 32780/1555 = 21.080385
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[1]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[2]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[3]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[4]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[5]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[6]:       768       768       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[7]:       768       768       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
total dram reads = 98352
bank skew: 772/768 = 1.01
chip skew: 12296/12288 = 1.00
number of total write accesses:
dram[0]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[1]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[2]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[3]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[4]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[5]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[6]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[7]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
total dram writes = 32768
bank skew: 256/256 = 1.00
chip skew: 4096/4096 = 1.00
average mf latency per bank:
dram[0]:        897       819      1378      1181       866       938      1067      1081       743       719       933       838       658       545       836       711
dram[1]:        790       725       960       886       652       633       829       770       678       603       852       723       570       524       742       699
dram[2]:        664       670       820       863       642       582       801       712       557       536       730       673       576       479       714       636
dram[3]:        598       586       741       723       553       564       670       698       542       576       677       723       523       496       647       664
dram[4]:        577       565       730       724       607       561       730       693       542       520       693       655       507       489       660       607
dram[5]:        564       572       739       726       540       570       702       718       542       529       714       682       564       522       701       687
dram[6]:        614       549       798       701       551       539       685       667       550       505       675       665       485       533       612       675
dram[7]:        581       555       740       686       549       510       673       666       517       539       642       687       538       535       709       692
maximum mf latency per bank:
dram[0]:       2951      2857      3052      3010      2865      3048      3217      3034      2729      2567      2451      2605      1289      1268      1312      1288
dram[1]:       2362      2439      1628      1972      2637      2021      2375      2031      2139      1333      2235      1290      1622      1810      1527      1996
dram[2]:       2295      2034      1385      1661      2643      2723      1495      1552      1041      1132      1369       879      1042       691      1161       782
dram[3]:       2346      2410      1910      1874      2622      2697      1456      1502      1276      1215      1312      1299      1093      1042      1037       934
dram[4]:       2389      2465      1906      1878      2621      2697      1456      1502       837       844      1312       882       697       918       728       987
dram[5]:       2358      2389      2390      1846      1952      1963      1231      1946      1275      1326      1276      1352      1334      1296      1253      1304
dram[6]:       2389      2395      2349      2391      1827      1886      1324      1478      1266      1245      1268      1280      1310      1305      1223      1235
dram[7]:       2390      2460      1928      1913      1909      2013      2033      1649      1298      1288      1302      1256       894       781      1306       950
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=640158 n_nop=623391 n_act=198 n_pre=182 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.05121
n_activity=51400 dram_eff=0.6378
bk0: 772a 635606i bk1: 772a 635285i bk2: 768a 635382i bk3: 768a 635219i bk4: 768a 635898i bk5: 768a 635515i bk6: 768a 635411i bk7: 768a 635679i bk8: 768a 636071i bk9: 768a 635861i bk10: 768a 635553i bk11: 768a 635982i bk12: 768a 635040i bk13: 768a 634923i bk14: 768a 634858i bk15: 768a 634864i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.951684
Row_Buffer_Locality_read = 0.956409
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.788310
Bank_Level_Parallism_Col = 1.792009
Bank_Level_Parallism_Ready = 1.382265
write_to_read_ratio_blp_rw_average = 0.312305
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051212 
total_CMD = 640158 
util_bw = 32784 
Wasted_Col = 10933 
Wasted_Row = 1310 
Idle = 595131 

BW Util Bottlenecks: 
RCDc_limit = 1196 
RCDWRc_limit = 278 
WTRc_limit = 9382 
RTWc_limit = 9684 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9382 
RTWc_limit_alone = 9684 

Commands details: 
total_CMD = 640158 
n_nop = 623391 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 198 
n_pre = 182 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 380 
issued_total_col = 16392 
Row_Bus_Util =  0.000594 
CoL_Bus_Util = 0.025606 
Either_Row_CoL_Bus_Util = 0.026192 
Issued_on_Two_Bus_Simul_Util = 0.000008 
issued_two_Eff = 0.000298 
queue_avg = 1.090801 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.0908
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=640158 n_nop=623399 n_act=194 n_pre=178 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.05121
n_activity=50991 dram_eff=0.6429
bk0: 772a 635388i bk1: 772a 635417i bk2: 768a 635005i bk3: 768a 635252i bk4: 768a 636102i bk5: 768a 636028i bk6: 768a 635642i bk7: 768a 635708i bk8: 768a 635677i bk9: 768a 635824i bk10: 768a 635472i bk11: 768a 635665i bk12: 768a 635622i bk13: 768a 635603i bk14: 768a 635694i bk15: 768a 635536i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952660
Row_Buffer_Locality_read = 0.957710
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.702835
Bank_Level_Parallism_Col = 1.706720
Bank_Level_Parallism_Ready = 1.374543
write_to_read_ratio_blp_rw_average = 0.311607
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051212 
total_CMD = 640158 
util_bw = 32784 
Wasted_Col = 11526 
Wasted_Row = 1363 
Idle = 594485 

BW Util Bottlenecks: 
RCDc_limit = 1108 
RCDWRc_limit = 299 
WTRc_limit = 9294 
RTWc_limit = 9530 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9294 
RTWc_limit_alone = 9530 

Commands details: 
total_CMD = 640158 
n_nop = 623399 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 194 
n_pre = 178 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 372 
issued_total_col = 16392 
Row_Bus_Util =  0.000581 
CoL_Bus_Util = 0.025606 
Either_Row_CoL_Bus_Util = 0.026179 
Issued_on_Two_Bus_Simul_Util = 0.000008 
issued_two_Eff = 0.000298 
queue_avg = 1.038387 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.03839
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=640158 n_nop=623390 n_act=197 n_pre=181 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.05121
n_activity=50081 dram_eff=0.6546
bk0: 772a 636141i bk1: 772a 635770i bk2: 768a 635746i bk3: 768a 635464i bk4: 768a 635653i bk5: 768a 635428i bk6: 768a 635198i bk7: 768a 635111i bk8: 768a 635694i bk9: 768a 635960i bk10: 768a 635437i bk11: 768a 635703i bk12: 768a 636054i bk13: 768a 636077i bk14: 768a 635733i bk15: 768a 635916i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.951928
Row_Buffer_Locality_read = 0.956734
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.644445
Bank_Level_Parallism_Col = 1.643827
Bank_Level_Parallism_Ready = 1.352772
write_to_read_ratio_blp_rw_average = 0.318229
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051212 
total_CMD = 640158 
util_bw = 32784 
Wasted_Col = 12102 
Wasted_Row = 1334 
Idle = 593938 

BW Util Bottlenecks: 
RCDc_limit = 1048 
RCDWRc_limit = 310 
WTRc_limit = 9317 
RTWc_limit = 9789 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9317 
RTWc_limit_alone = 9789 

Commands details: 
total_CMD = 640158 
n_nop = 623390 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 197 
n_pre = 181 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 378 
issued_total_col = 16392 
Row_Bus_Util =  0.000590 
CoL_Bus_Util = 0.025606 
Either_Row_CoL_Bus_Util = 0.026194 
Issued_on_Two_Bus_Simul_Util = 0.000003 
issued_two_Eff = 0.000119 
queue_avg = 1.029718 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.02972
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=640158 n_nop=623400 n_act=194 n_pre=178 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.05121
n_activity=49295 dram_eff=0.6651
bk0: 772a 635156i bk1: 772a 635100i bk2: 768a 634530i bk3: 768a 634797i bk4: 768a 635988i bk5: 768a 635610i bk6: 768a 635318i bk7: 768a 635357i bk8: 768a 636146i bk9: 768a 635944i bk10: 768a 635835i bk11: 768a 635819i bk12: 768a 635505i bk13: 768a 635606i bk14: 768a 635191i bk15: 768a 635157i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952660
Row_Buffer_Locality_read = 0.957710
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.749443
Bank_Level_Parallism_Col = 1.748920
Bank_Level_Parallism_Ready = 1.388533
write_to_read_ratio_blp_rw_average = 0.328565
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051212 
total_CMD = 640158 
util_bw = 32784 
Wasted_Col = 11711 
Wasted_Row = 1231 
Idle = 594432 

BW Util Bottlenecks: 
RCDc_limit = 1005 
RCDWRc_limit = 303 
WTRc_limit = 9456 
RTWc_limit = 9685 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9456 
RTWc_limit_alone = 9685 

Commands details: 
total_CMD = 640158 
n_nop = 623400 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 194 
n_pre = 178 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 372 
issued_total_col = 16392 
Row_Bus_Util =  0.000581 
CoL_Bus_Util = 0.025606 
Either_Row_CoL_Bus_Util = 0.026178 
Issued_on_Two_Bus_Simul_Util = 0.000009 
issued_two_Eff = 0.000358 
queue_avg = 1.095470 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.09547
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=640158 n_nop=623398 n_act=194 n_pre=178 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.05121
n_activity=49849 dram_eff=0.6577
bk0: 772a 635541i bk1: 772a 635175i bk2: 768a 634830i bk3: 768a 634990i bk4: 768a 636028i bk5: 768a 635989i bk6: 768a 635591i bk7: 768a 635683i bk8: 768a 635809i bk9: 768a 636123i bk10: 768a 635732i bk11: 768a 635899i bk12: 768a 636033i bk13: 768a 635997i bk14: 768a 636003i bk15: 768a 635917i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952660
Row_Buffer_Locality_read = 0.957710
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.637848
Bank_Level_Parallism_Col = 1.644205
Bank_Level_Parallism_Ready = 1.339250
write_to_read_ratio_blp_rw_average = 0.315752
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051212 
total_CMD = 640158 
util_bw = 32784 
Wasted_Col = 11944 
Wasted_Row = 1482 
Idle = 593948 

BW Util Bottlenecks: 
RCDc_limit = 1107 
RCDWRc_limit = 318 
WTRc_limit = 9286 
RTWc_limit = 9748 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9286 
RTWc_limit_alone = 9748 

Commands details: 
total_CMD = 640158 
n_nop = 623398 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 194 
n_pre = 178 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 372 
issued_total_col = 16392 
Row_Bus_Util =  0.000581 
CoL_Bus_Util = 0.025606 
Either_Row_CoL_Bus_Util = 0.026181 
Issued_on_Two_Bus_Simul_Util = 0.000006 
issued_two_Eff = 0.000239 
queue_avg = 1.047762 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.04776
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=640158 n_nop=623400 n_act=194 n_pre=178 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.05121
n_activity=49463 dram_eff=0.6628
bk0: 772a 635910i bk1: 772a 635803i bk2: 768a 635546i bk3: 768a 635336i bk4: 768a 635286i bk5: 768a 635277i bk6: 768a 634978i bk7: 768a 634826i bk8: 768a 635977i bk9: 768a 635831i bk10: 768a 635738i bk11: 768a 635671i bk12: 768a 636015i bk13: 768a 635996i bk14: 768a 635765i bk15: 768a 635824i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952660
Row_Buffer_Locality_read = 0.957710
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.691649
Bank_Level_Parallism_Col = 1.698421
Bank_Level_Parallism_Ready = 1.371706
write_to_read_ratio_blp_rw_average = 0.308964
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051212 
total_CMD = 640158 
util_bw = 32784 
Wasted_Col = 11473 
Wasted_Row = 1443 
Idle = 594458 

BW Util Bottlenecks: 
RCDc_limit = 1110 
RCDWRc_limit = 314 
WTRc_limit = 9320 
RTWc_limit = 9665 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9320 
RTWc_limit_alone = 9665 

Commands details: 
total_CMD = 640158 
n_nop = 623400 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 194 
n_pre = 178 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 372 
issued_total_col = 16392 
Row_Bus_Util =  0.000581 
CoL_Bus_Util = 0.025606 
Either_Row_CoL_Bus_Util = 0.026178 
Issued_on_Two_Bus_Simul_Util = 0.000009 
issued_two_Eff = 0.000358 
queue_avg = 1.065824 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.06582
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=640158 n_nop=623414 n_act=192 n_pre=176 n_ref_event=0 n_req=4096 n_rd=8192 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.05119
n_activity=50564 dram_eff=0.6481
bk0: 768a 636054i bk1: 768a 636018i bk2: 768a 635604i bk3: 768a 635800i bk4: 768a 635721i bk5: 768a 636140i bk6: 768a 635339i bk7: 768a 635677i bk8: 768a 636018i bk9: 768a 636077i bk10: 768a 635781i bk11: 768a 635981i bk12: 768a 636106i bk13: 768a 636088i bk14: 768a 635943i bk15: 768a 636025i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.953125
Row_Buffer_Locality_read = 0.958333
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.561003
Bank_Level_Parallism_Col = 1.561127
Bank_Level_Parallism_Ready = 1.293630
write_to_read_ratio_blp_rw_average = 0.317501
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051187 
total_CMD = 640158 
util_bw = 32768 
Wasted_Col = 12419 
Wasted_Row = 1380 
Idle = 593591 

BW Util Bottlenecks: 
RCDc_limit = 1073 
RCDWRc_limit = 307 
WTRc_limit = 9309 
RTWc_limit = 9569 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9309 
RTWc_limit_alone = 9569 

Commands details: 
total_CMD = 640158 
n_nop = 623414 
Read = 8192 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 192 
n_pre = 176 
n_ref = 0 
n_req = 4096 
total_req = 16384 

Dual Bus Interface Util: 
issued_total_row = 368 
issued_total_col = 16384 
Row_Bus_Util =  0.000575 
CoL_Bus_Util = 0.025594 
Either_Row_CoL_Bus_Util = 0.026156 
Issued_on_Two_Bus_Simul_Util = 0.000012 
issued_two_Eff = 0.000478 
queue_avg = 0.929778 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=44 avg=0.929778
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents

Cache L2_bank_015:
MSHR contents
MSHR: tag=0xdd9fef80, atomic=0 1 entries : 0x56313ba6d0a0 :  mf: uid=6517722, sid16:w29, part=7, addr=0x7fdddd9fef80, load , size=128, unknown  status = IN_PARTITION_DRAM (411492), 

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=640158 n_nop=623419 n_act=192 n_pre=176 n_ref_event=0 n_req=4096 n_rd=8192 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.05119
n_activity=49092 dram_eff=0.6675
bk0: 768a 635616i bk1: 768a 635333i bk2: 768a 635303i bk3: 768a 634937i bk4: 768a 635249i bk5: 768a 635481i bk6: 768a 634908i bk7: 768a 635146i bk8: 768a 635610i bk9: 768a 634939i bk10: 768a 635032i bk11: 768a 634892i bk12: 768a 635552i bk13: 768a 636003i bk14: 768a 635297i bk15: 768a 635830i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.953125
Row_Buffer_Locality_read = 0.958333
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.801819
Bank_Level_Parallism_Col = 1.802940
Bank_Level_Parallism_Ready = 1.405590
write_to_read_ratio_blp_rw_average = 0.333861
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051187 
total_CMD = 640158 
util_bw = 32768 
Wasted_Col = 11496 
Wasted_Row = 1230 
Idle = 594664 

BW Util Bottlenecks: 
RCDc_limit = 1023 
RCDWRc_limit = 297 
WTRc_limit = 9464 
RTWc_limit = 9699 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9464 
RTWc_limit_alone = 9699 

Commands details: 
total_CMD = 640158 
n_nop = 623419 
Read = 8192 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 192 
n_pre = 176 
n_ref = 0 
n_req = 4096 
total_req = 16384 

Dual Bus Interface Util: 
issued_total_row = 368 
issued_total_col = 16384 
Row_Bus_Util =  0.000575 
CoL_Bus_Util = 0.025594 
Either_Row_CoL_Bus_Util = 0.026148 
Issued_on_Two_Bus_Simul_Util = 0.000020 
issued_two_Eff = 0.000777 
queue_avg = 1.131057 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.13106

========= L2 cache stats =========
L2_cache_bank[0]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 243, Reservation_fails = 18
L2_cache_bank[1]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 164, Reservation_fails = 2
L2_cache_bank[2]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 70, Reservation_fails = 9
L2_cache_bank[3]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 61, Reservation_fails = 14
L2_cache_bank[4]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 39, Reservation_fails = 7
L2_cache_bank[5]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 56, Reservation_fails = 22
L2_cache_bank[6]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 68, Reservation_fails = 10
L2_cache_bank[7]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 57, Reservation_fails = 5
L2_cache_bank[8]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 87, Reservation_fails = 14
L2_cache_bank[9]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 44, Reservation_fails = 0
L2_cache_bank[10]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 41, Reservation_fails = 0
L2_cache_bank[11]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 41, Reservation_fails = 1
L2_cache_bank[12]: Access = 16896, Miss = 1536, Miss_rate = 0.091, Pending_hits = 33, Reservation_fails = 22
L2_cache_bank[13]: Access = 16896, Miss = 1536, Miss_rate = 0.091, Pending_hits = 18, Reservation_fails = 4
L2_cache_bank[14]: Access = 16896, Miss = 1536, Miss_rate = 0.091, Pending_hits = 66, Reservation_fails = 6
L2_cache_bank[15]: Access = 16896, Miss = 1536, Miss_rate = 0.091, Pending_hits = 50, Reservation_fails = 16
L2_total_cache_accesses = 270576
L2_total_cache_misses = 24588
L2_total_cache_miss_rate = 0.0909
L2_total_cache_pending_hits = 1138
L2_total_cache_reservation_fails = 150
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 244741
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 1019
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 16384
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 1019
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 8192
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 150
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 109
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 119
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 12
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 119
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 262144
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 8192
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 240
L2_total_cache_reservation_fail_breakdown:
	L2_cache_stats_fail_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 150
L2_cache_data_port_util = 0.149
L2_cache_fill_port_util = 0.015

icnt_total_pkts_mem_to_simt=1320112
icnt_total_pkts_simt_to_mem=303344
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 39.7313
	minimum = 6
	maximum = 2827
Network latency average = 26.8686
	minimum = 6
	maximum = 1378
Slowest packet = 533
Flit latency average = 18.1894
	minimum = 6
	maximum = 1378
Slowest flit = 933
Fragmentation average = 0.010655
	minimum = 0
	maximum = 365
Injected packet rate average = 0.0263018
	minimum = 0 (at node 36)
	maximum = 0.0411087 (at node 20)
Accepted packet rate average = 0.0263018
	minimum = 0 (at node 36)
	maximum = 0.0411087 (at node 20)
Injected flit rate average = 0.0789055
	minimum = 0 (at node 36)
	maximum = 0.200567 (at node 20)
Accepted flit rate average= 0.0789055
	minimum = 0 (at node 36)
	maximum = 0.162909 (at node 0)
Injected packet length average = 3
Accepted packet length average = 3
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 39.7313 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2827 (1 samples)
Network latency average = 26.8686 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1378 (1 samples)
Flit latency average = 18.1894 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1378 (1 samples)
Fragmentation average = 0.010655 (1 samples)
	minimum = 0 (1 samples)
	maximum = 365 (1 samples)
Injected packet rate average = 0.0263018 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0411087 (1 samples)
Accepted packet rate average = 0.0263018 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0411087 (1 samples)
Injected flit rate average = 0.0789055 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.200567 (1 samples)
Accepted flit rate average = 0.0789055 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.162909 (1 samples)
Injected packet size average = 3 (1 samples)
Accepted packet size average = 3 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 5 min, 22 sec (322 sec)
gpgpu_simulation_rate = 1234193 (inst/sec)
gpgpu_simulation_rate = 1277 (cycle/sec)
gpgpu_silicon_slowdown = 1258418x
GPGPU-Sim: *** simulation thread exiting ***
GPGPU-Sim: *** exit detected ***
