GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded
Accel-Sim [build accelsim-commit-e02c99dbadefc0b9dc95317100be2a446eec142c_modified_0.0]

        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:1607.0:1607.0:2500.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
-trace               /benchrun/accelsim-sass/sm6_gtx1080/cuda4-matrixmul/input-512/results/traces/kernelslist.g # traces kernel filetraces kernel file directory
-trace_opcode_latency_initiation_int                  4,1 # Opcode latencies and initiation for integers in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_sp                  4,1 # Opcode latencies and initiation for sp in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_dp                  4,1 # Opcode latencies and initiation for dp in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_sfu                  4,1 # Opcode latencies and initiation for sfu in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_tensor                  4,1 # Opcode latencies and initiation for tensor in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_spec_op_1                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_2                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_3                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_4                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_5                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_6                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_7                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_8                  4,4 # specialized unit config <latency,initiation>
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:1607000000.000000:1607000000.000000:2500000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000062227753578:0.00000000062227753578:0.00000000040000000000
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: performance model initialization complete.
launching memcpy command : MemcpyHtoD,0x00007fe0e5500000,1048576
launching memcpy command : MemcpyHtoD,0x00007fe0e5600000,1048576
Processing kernel /benchrun/accelsim-sass/sm6_gtx1080/cuda4-matrixmul/input-512/results/traces/kernel-1.traceg
-kernel name = _Z8mult_gpuPfS_S_ii
-kernel id = 1
-grid dim = (16,16,1)
-block dim = (32,32,1)
-shmem = 8192
-nregs = 30
-binary version = 61
-cuda stream id = 0
-shmem base_addr = 0x00007fe112000000
-local mem base_addr = 0x00007fe110000000
-nvbit version = 1.5.5
-accelsim tracer version = 3
Header info loaded for kernel command : /benchrun/accelsim-sass/sm6_gtx1080/cuda4-matrixmul/input-512/results/traces/kernel-1.traceg
launching kernel name: _Z8mult_gpuPfS_S_ii uid: 1
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads regs
thread block = 0,0,0
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 1,0,0
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 2,0,0
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 3,0,0
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 4,0,0
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 5,0,0
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 6,0,0
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 7,0,0
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 8,0,0
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 9,0,0
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 10,0,0
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 11,0,0
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 12,0,0
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 13,0,0
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 14,0,0
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 15,0,0
GPGPU-Sim uArch: Shader 16 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 0,1,0
GPGPU-Sim uArch: Shader 17 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 1,1,0
GPGPU-Sim uArch: Shader 18 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 2,1,0
GPGPU-Sim uArch: Shader 19 bind to kernel 1 '_Z8mult_gpuPfS_S_ii'
thread block = 3,1,0
thread block = 4,1,0
thread block = 5,1,0
thread block = 6,1,0
thread block = 7,1,0
thread block = 8,1,0
thread block = 9,1,0
thread block = 10,1,0
thread block = 11,1,0
thread block = 12,1,0
thread block = 13,1,0
thread block = 14,1,0
thread block = 15,1,0
thread block = 0,2,0
thread block = 1,2,0
thread block = 2,2,0
thread block = 3,2,0
thread block = 4,2,0
thread block = 5,2,0
thread block = 6,2,0
thread block = 7,2,0
thread block = 8,2,0
thread block = 9,2,0
thread block = 10,2,0
thread block = 11,2,0
thread block = 12,2,0
thread block = 13,2,0
thread block = 14,2,0
thread block = 15,2,0
thread block = 0,3,0
thread block = 1,3,0
thread block = 2,3,0
thread block = 3,3,0
thread block = 4,3,0
thread block = 5,3,0
thread block = 6,3,0
thread block = 7,3,0
thread block = 8,3,0
thread block = 9,3,0
thread block = 10,3,0
thread block = 11,3,0
thread block = 12,3,0
thread block = 13,3,0
thread block = 14,3,0
thread block = 15,3,0
thread block = 0,4,0
thread block = 1,4,0
thread block = 2,4,0
thread block = 3,4,0
thread block = 4,4,0
thread block = 5,4,0
thread block = 6,4,0
thread block = 7,4,0
thread block = 8,4,0
thread block = 9,4,0
thread block = 10,4,0
thread block = 11,4,0
thread block = 12,4,0
thread block = 13,4,0
thread block = 14,4,0
thread block = 15,4,0
thread block = 0,5,0
thread block = 1,5,0
thread block = 2,5,0
thread block = 3,5,0
thread block = 4,5,0
thread block = 5,5,0
thread block = 6,5,0
thread block = 7,5,0
thread block = 8,5,0
thread block = 9,5,0
thread block = 10,5,0
thread block = 11,5,0
thread block = 12,5,0
thread block = 13,5,0
thread block = 14,5,0
thread block = 15,5,0
thread block = 0,6,0
thread block = 1,6,0
thread block = 2,6,0
thread block = 3,6,0
thread block = 4,6,0
thread block = 5,6,0
thread block = 6,6,0
thread block = 7,6,0
thread block = 8,6,0
thread block = 9,6,0
thread block = 10,6,0
thread block = 11,6,0
thread block = 12,6,0
thread block = 13,6,0
thread block = 14,6,0
thread block = 15,6,0
thread block = 0,7,0
thread block = 1,7,0
thread block = 2,7,0
thread block = 3,7,0
thread block = 4,7,0
thread block = 5,7,0
thread block = 6,7,0
thread block = 7,7,0
thread block = 8,7,0
thread block = 9,7,0
thread block = 10,7,0
thread block = 11,7,0
thread block = 12,7,0
thread block = 13,7,0
thread block = 14,7,0
thread block = 15,7,0
thread block = 0,8,0
thread block = 1,8,0
thread block = 2,8,0
thread block = 3,8,0
thread block = 4,8,0
thread block = 5,8,0
thread block = 6,8,0
thread block = 7,8,0
thread block = 8,8,0
thread block = 9,8,0
thread block = 10,8,0
thread block = 11,8,0
thread block = 12,8,0
thread block = 13,8,0
thread block = 14,8,0
thread block = 15,8,0
thread block = 0,9,0
thread block = 1,9,0
thread block = 2,9,0
thread block = 3,9,0
thread block = 4,9,0
thread block = 5,9,0
thread block = 6,9,0
thread block = 7,9,0
thread block = 8,9,0
thread block = 9,9,0
thread block = 10,9,0
thread block = 11,9,0
thread block = 12,9,0
thread block = 13,9,0
thread block = 14,9,0
thread block = 15,9,0
thread block = 0,10,0
thread block = 1,10,0
thread block = 2,10,0
thread block = 3,10,0
thread block = 4,10,0
thread block = 5,10,0
thread block = 6,10,0
thread block = 7,10,0
thread block = 8,10,0
thread block = 9,10,0
thread block = 10,10,0
thread block = 11,10,0
thread block = 12,10,0
thread block = 13,10,0
thread block = 14,10,0
thread block = 15,10,0
thread block = 0,11,0
thread block = 1,11,0
thread block = 2,11,0
thread block = 3,11,0
thread block = 4,11,0
thread block = 5,11,0
thread block = 6,11,0
thread block = 7,11,0
thread block = 8,11,0
thread block = 9,11,0
thread block = 10,11,0
thread block = 11,11,0
thread block = 12,11,0
thread block = 13,11,0
thread block = 14,11,0
thread block = 15,11,0
thread block = 0,12,0
thread block = 1,12,0
thread block = 2,12,0
thread block = 3,12,0
thread block = 4,12,0
thread block = 5,12,0
thread block = 6,12,0
thread block = 7,12,0
thread block = 8,12,0
thread block = 9,12,0
thread block = 10,12,0
thread block = 11,12,0
thread block = 12,12,0
thread block = 13,12,0
thread block = 14,12,0
thread block = 15,12,0
thread block = 0,13,0
thread block = 1,13,0
thread block = 2,13,0
thread block = 3,13,0
thread block = 4,13,0
thread block = 5,13,0
thread block = 6,13,0
thread block = 7,13,0
thread block = 8,13,0
thread block = 9,13,0
thread block = 10,13,0
thread block = 11,13,0
thread block = 12,13,0
thread block = 13,13,0
thread block = 14,13,0
thread block = 15,13,0
thread block = 0,14,0
thread block = 1,14,0
thread block = 2,14,0
thread block = 3,14,0
thread block = 4,14,0
thread block = 5,14,0
thread block = 6,14,0
thread block = 7,14,0
thread block = 8,14,0
thread block = 9,14,0
thread block = 10,14,0
thread block = 11,14,0
thread block = 12,14,0
thread block = 13,14,0
thread block = 14,14,0
thread block = 15,14,0
thread block = 0,15,0
thread block = 1,15,0
thread block = 2,15,0
thread block = 3,15,0
thread block = 4,15,0
thread block = 5,15,0
thread block = 6,15,0
thread block = 7,15,0
thread block = 8,15,0
thread block = 9,15,0
thread block = 10,15,0
thread block = 11,15,0
thread block = 12,15,0
thread block = 13,15,0
thread block = 14,15,0
thread block = 15,15,0
Destroy streams for kernel 1: size 0
kernel_name = _Z8mult_gpuPfS_S_ii 
kernel_launch_uid = 1 
gpu_sim_cycle = 412399
gpu_sim_insn = 397410304
gpu_ipc =     963.6548
gpu_tot_sim_cycle = 412399
gpu_tot_sim_insn = 397410304
gpu_tot_ipc =     963.6548
gpu_tot_issued_cta = 256
gpu_occupancy = 96.1181% 
gpu_tot_occupancy = 96.1181% 
max_total_param_size = 0
gpu_stall_dramfull = 763018
gpu_stall_icnt2sh    = 1622551
partiton_level_parallism =       0.6561
partiton_level_parallism_total  =       0.6561
partiton_level_parallism_util =       1.4127
partiton_level_parallism_util_total  =       1.4127
L2_BW  =      33.7394 GB/Sec
L2_BW_total  =      33.7394 GB/Sec
gpu_total_sim_rate=1257627

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 6217728
	L1I_total_cache_misses = 9672
	L1I_total_cache_miss_rate = 0.0016
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 21470
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 0
	L1C_total_cache_misses = 0
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 0
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 6208056
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 9672
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 21470
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 9432
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 6217728

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[INST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 21470
ctas_completed 256, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
distro:
9642, 9648, 9660, 9657, 9839, 9846, 10073, 10077, 10051, 10093, 9771, 9813, 9879, 9860, 9975, 9952, 9969, 9982, 9860, 9863, 9880, 9855, 9944, 9931, 9960, 9938, 9917, 9907, 9896, 9925, 9997, 9969, 9669, 9705, 9721, 9720, 9871, 9865, 10056, 10073, 10071, 10014, 9761, 9770, 9836, 9813, 9905, 9932, 9934, 9942, 9874, 9883, 9878, 9870, 9942, 9937, 9946, 9960, 9884, 9896, 9913, 9931, 9957, 9917, 
gpgpu_n_tot_thrd_icount = 397934592
gpgpu_n_tot_w_icount = 12435456
gpgpu_n_stall_shd_mem = 520479
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 262144
gpgpu_n_mem_write_global = 8192
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 0
gpgpu_n_load_insn  = 8388608
gpgpu_n_store_insn = 262144
gpgpu_n_shmem_insn = 176160768
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 0
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][resource_stall] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 0
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:3577542	W0_Idle:145278	W0_Scoreboard:1035465	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:12419072
single_issue_nums: WS0:5170528	WS1:5166954	
dual_issue_nums: WS0:523600	WS1:525387	
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 2097152 {8:262144,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 1114112 {136:8192,}
traffic_breakdown_coretomem[INST_ACC_R] = 1920 {8:240,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 35651584 {136:262144,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 65536 {8:8192,}
traffic_breakdown_memtocore[INST_ACC_R] = 32640 {136:240,}
maxmflatency = 3217 
max_icnt2mem_latency = 2860 
maxmrqlatency = 783 
max_icnt2sh_latency = 147 
averagemflatency = 342 
avg_icnt2mem_latency = 83 
avg_mrq_latency = 108 
avg_icnt2sh_latency = 28 
mrq_lat_table:5658 	902 	1626 	2600 	5147 	2879 	3263 	5053 	5260 	392 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	118781 	110000 	37754 	3003 	798 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	0 	144231 	37759 	27707 	13717 	20615 	18915 	5067 	1947 	618 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	0 	29699 	138345 	98066 	4221 	5 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	144 	624 	23 	23 	2 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[1]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[2]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[3]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[4]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[5]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[6]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
dram[7]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32        32 
maximum service time to same row:
dram[0]:     59420     54591     59369     54312     59844     58709     59821     60071     58453     58325     58436     59197     59405     55455     59247     55562 
dram[1]:     48034     55315     48270     55408     69372     69660     69585     69711     65842     72709     65939     72830     61465     68158     61665     68374 
dram[2]:     60556     65257     60521     65327     61478     62840     61807     62909     61798     66855     62119     66821     59994     62860     60350     62984 
dram[3]:     64775     67759     64807     68126     65610     67300     65695     67282     73303     69670     73390     69623     64843     67960     64904     68024 
dram[4]:     68457     72671     68549     72760     71195     73368     71300     73472     68786     69336     68909     69438     68916     70873     69007     70920 
dram[5]:     73226     76180     73634     76098     76380     79024     76497     79069     72191     74610     72418     74698     73036     76658     73087     76740 
dram[6]:     75506     77367     75595     77393     79363     84644     79474     84750     76055     75873     76127     75957     71708     71197     71813     71244 
dram[7]:     79418     82726     79473     82817     82321     83670     82405     83764     80408     81133     80496     81014     72642     77366     72749     77471 
average row accesses per activate:
dram[0]: 17.133333 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[1]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[2]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[3]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[4]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[5]: 19.769230 19.769230 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[6]: 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
dram[7]: 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 21.333334 
average row locality = 32780/1550 = 21.148388
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[1]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[2]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[3]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[4]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[5]:       772       772       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[6]:       768       768       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
dram[7]:       768       768       768       768       768       768       768       768       768       768       768       768       768       768       768       768 
total dram reads = 98352
bank skew: 772/768 = 1.01
chip skew: 12296/12288 = 1.00
number of total write accesses:
dram[0]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[1]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[2]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[3]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[4]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[5]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[6]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
dram[7]:       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256       256 
total dram writes = 32768
bank skew: 256/256 = 1.00
chip skew: 4096/4096 = 1.00
average mf latency per bank:
dram[0]:        939       918      1425      1216       865       944      1062      1094       756       755       925       897       637       620       799       716
dram[1]:        796       644       906       831       731       651       848       776       668       609       793       760       559       599       695       790
dram[2]:        741       625       874       769       706       629       868       741       687       569       863       703       605       540       775       685
dram[3]:        605       626       731       746       604       706       712       850       561       569       678       712       520       574       673       743
dram[4]:        663       557       832       705       633       627       802       765       549       551       710       663       583       533       742       666
dram[5]:        619       618       777       736       606       603       727       732       586       559       719       692       581       559       743       731
dram[6]:        620       647       784       801       571       605       691       764       569       589       720       736       565       556       711       734
dram[7]:        610       585       784       708       566       588       699       721       562       545       683       686       575       505       729       646
maximum mf latency per bank:
dram[0]:       2951      2838      3052      2991      2865      2999      3217      2952      2729      2533      2451      2324      1110      1008      1260       976
dram[1]:       2362      2439      1539      1972      2672      2030      1688      1776      1289      1284      1312      1232      1313      1185      1422      1728
dram[2]:       2295      2034      1674      1661      2645      2618      1394      1349      1148       964      1400       978      1005       993      1113       904
dram[3]:       2346      2410      1910      1874      2132      2628      1404      2032      1300      1029      1440      1514       981       944       940      1087
dram[4]:       2389      2465      1906      1878      2600      2664      2614      1441       868      1180       896       789       828       736       916       737
dram[5]:       2358      2389      2390      1846      1941      1952      1171      2026      1223      1154      1235      1260       937      1003      1211      1280
dram[6]:       2389      2395      2349      2391      1937      1532      1670      1962      1232      1056      1301      1228       808      1096      1192       898
dram[7]:       2390      2460      1928      1913      1913      1978      1942      1948      1123      1162      1214       872       815      1049      1101      1068
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents

Cache L2_bank_001:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=641566 n_nop=624806 n_act=196 n_pre=180 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.0511
n_activity=51566 dram_eff=0.6358
bk0: 772a 636641i bk1: 772a 636688i bk2: 768a 636431i bk3: 768a 636741i bk4: 768a 637289i bk5: 768a 636899i bk6: 768a 636874i bk7: 768a 636292i bk8: 768a 637554i bk9: 768a 637541i bk10: 768a 637330i bk11: 768a 637429i bk12: 768a 637092i bk13: 768a 636960i bk14: 768a 636525i bk15: 768a 636784i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952172
Row_Buffer_Locality_read = 0.957059
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.738919
Bank_Level_Parallism_Col = 1.744081
Bank_Level_Parallism_Ready = 1.383081
write_to_read_ratio_blp_rw_average = 0.310610
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051100 
total_CMD = 641566 
util_bw = 32784 
Wasted_Col = 11293 
Wasted_Row = 1376 
Idle = 596113 

BW Util Bottlenecks: 
RCDc_limit = 1168 
RCDWRc_limit = 329 
WTRc_limit = 9288 
RTWc_limit = 9718 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9288 
RTWc_limit_alone = 9718 

Commands details: 
total_CMD = 641566 
n_nop = 624806 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 196 
n_pre = 180 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 376 
issued_total_col = 16392 
Row_Bus_Util =  0.000586 
CoL_Bus_Util = 0.025550 
Either_Row_CoL_Bus_Util = 0.026124 
Issued_on_Two_Bus_Simul_Util = 0.000012 
issued_two_Eff = 0.000477 
queue_avg = 1.082210 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.08221
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=641566 n_nop=624805 n_act=194 n_pre=178 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.0511
n_activity=50483 dram_eff=0.6494
bk0: 772a 637076i bk1: 772a 637119i bk2: 768a 636741i bk3: 768a 636772i bk4: 768a 637380i bk5: 768a 637403i bk6: 768a 636843i bk7: 768a 637134i bk8: 768a 636785i bk9: 768a 637323i bk10: 768a 636594i bk11: 768a 636983i bk12: 768a 636796i bk13: 768a 636372i bk14: 768a 636463i bk15: 768a 636444i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952660
Row_Buffer_Locality_read = 0.957710
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.758853
Bank_Level_Parallism_Col = 1.764466
Bank_Level_Parallism_Ready = 1.385737
write_to_read_ratio_blp_rw_average = 0.313677
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051100 
total_CMD = 641566 
util_bw = 32784 
Wasted_Col = 11179 
Wasted_Row = 1361 
Idle = 596242 

BW Util Bottlenecks: 
RCDc_limit = 1179 
RCDWRc_limit = 299 
WTRc_limit = 9379 
RTWc_limit = 9655 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9379 
RTWc_limit_alone = 9655 

Commands details: 
total_CMD = 641566 
n_nop = 624805 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 194 
n_pre = 178 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 372 
issued_total_col = 16392 
Row_Bus_Util =  0.000580 
CoL_Bus_Util = 0.025550 
Either_Row_CoL_Bus_Util = 0.026125 
Issued_on_Two_Bus_Simul_Util = 0.000005 
issued_two_Eff = 0.000179 
queue_avg = 1.096514 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.09651
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents

Cache L2_bank_005:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=641566 n_nop=624816 n_act=194 n_pre=178 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.0511
n_activity=49800 dram_eff=0.6583
bk0: 772a 637402i bk1: 772a 637389i bk2: 768a 636804i bk3: 768a 637101i bk4: 768a 637291i bk5: 768a 637078i bk6: 768a 636624i bk7: 768a 636892i bk8: 768a 637556i bk9: 768a 636965i bk10: 768a 637361i bk11: 768a 636544i bk12: 768a 636480i bk13: 768a 636960i bk14: 768a 636544i bk15: 768a 636921i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952660
Row_Buffer_Locality_read = 0.957710
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.694901
Bank_Level_Parallism_Col = 1.696376
Bank_Level_Parallism_Ready = 1.379590
write_to_read_ratio_blp_rw_average = 0.315728
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051100 
total_CMD = 641566 
util_bw = 32784 
Wasted_Col = 11777 
Wasted_Row = 1313 
Idle = 595692 

BW Util Bottlenecks: 
RCDc_limit = 1025 
RCDWRc_limit = 319 
WTRc_limit = 9407 
RTWc_limit = 9541 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9407 
RTWc_limit_alone = 9541 

Commands details: 
total_CMD = 641566 
n_nop = 624816 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 194 
n_pre = 178 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 372 
issued_total_col = 16392 
Row_Bus_Util =  0.000580 
CoL_Bus_Util = 0.025550 
Either_Row_CoL_Bus_Util = 0.026108 
Issued_on_Two_Bus_Simul_Util = 0.000022 
issued_two_Eff = 0.000836 
queue_avg = 1.014493 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.01449
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=641566 n_nop=624808 n_act=194 n_pre=178 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.0511
n_activity=47578 dram_eff=0.6891
bk0: 772a 636348i bk1: 772a 636735i bk2: 768a 635754i bk3: 768a 636206i bk4: 768a 635839i bk5: 768a 635793i bk6: 768a 635594i bk7: 768a 635586i bk8: 768a 636468i bk9: 768a 637443i bk10: 768a 636172i bk11: 768a 637090i bk12: 768a 636573i bk13: 768a 636841i bk14: 768a 636650i bk15: 768a 636624i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952660
Row_Buffer_Locality_read = 0.957710
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.954692
Bank_Level_Parallism_Col = 1.955683
Bank_Level_Parallism_Ready = 1.593218
write_to_read_ratio_blp_rw_average = 0.319587
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051100 
total_CMD = 641566 
util_bw = 32784 
Wasted_Col = 10995 
Wasted_Row = 1125 
Idle = 596662 

BW Util Bottlenecks: 
RCDc_limit = 903 
RCDWRc_limit = 278 
WTRc_limit = 9385 
RTWc_limit = 9757 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9385 
RTWc_limit_alone = 9757 

Commands details: 
total_CMD = 641566 
n_nop = 624808 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 194 
n_pre = 178 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 372 
issued_total_col = 16392 
Row_Bus_Util =  0.000580 
CoL_Bus_Util = 0.025550 
Either_Row_CoL_Bus_Util = 0.026120 
Issued_on_Two_Bus_Simul_Util = 0.000009 
issued_two_Eff = 0.000358 
queue_avg = 1.204662 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.20466
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=641566 n_nop=624812 n_act=194 n_pre=178 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.0511
n_activity=49040 dram_eff=0.6685
bk0: 772a 637420i bk1: 772a 637161i bk2: 768a 636946i bk3: 768a 636839i bk4: 768a 636905i bk5: 768a 636860i bk6: 768a 636338i bk7: 768a 636315i bk8: 768a 637438i bk9: 768a 636874i bk10: 768a 637162i bk11: 768a 636862i bk12: 768a 637465i bk13: 768a 637352i bk14: 768a 637131i bk15: 768a 636910i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952660
Row_Buffer_Locality_read = 0.957710
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.693471
Bank_Level_Parallism_Col = 1.698672
Bank_Level_Parallism_Ready = 1.383532
write_to_read_ratio_blp_rw_average = 0.312897
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051100 
total_CMD = 641566 
util_bw = 32784 
Wasted_Col = 11592 
Wasted_Row = 1413 
Idle = 595777 

BW Util Bottlenecks: 
RCDc_limit = 1107 
RCDWRc_limit = 297 
WTRc_limit = 9260 
RTWc_limit = 9699 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9260 
RTWc_limit_alone = 9699 

Commands details: 
total_CMD = 641566 
n_nop = 624812 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 194 
n_pre = 178 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 372 
issued_total_col = 16392 
Row_Bus_Util =  0.000580 
CoL_Bus_Util = 0.025550 
Either_Row_CoL_Bus_Util = 0.026114 
Issued_on_Two_Bus_Simul_Util = 0.000016 
issued_two_Eff = 0.000597 
queue_avg = 1.114889 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.11489
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=641566 n_nop=624808 n_act=194 n_pre=178 n_ref_event=0 n_req=4098 n_rd=8200 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.0511
n_activity=48937 dram_eff=0.6699
bk0: 772a 636920i bk1: 772a 636865i bk2: 768a 636699i bk3: 768a 636480i bk4: 768a 636684i bk5: 768a 636775i bk6: 768a 636317i bk7: 768a 636181i bk8: 768a 637085i bk9: 768a 636988i bk10: 768a 636741i bk11: 768a 636903i bk12: 768a 637516i bk13: 768a 637507i bk14: 768a 637409i bk15: 768a 637362i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.952660
Row_Buffer_Locality_read = 0.957710
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.758206
Bank_Level_Parallism_Col = 1.765375
Bank_Level_Parallism_Ready = 1.396841
write_to_read_ratio_blp_rw_average = 0.305936
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051100 
total_CMD = 641566 
util_bw = 32784 
Wasted_Col = 10884 
Wasted_Row = 1400 
Idle = 596498 

BW Util Bottlenecks: 
RCDc_limit = 1111 
RCDWRc_limit = 257 
WTRc_limit = 9263 
RTWc_limit = 9662 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9263 
RTWc_limit_alone = 9662 

Commands details: 
total_CMD = 641566 
n_nop = 624808 
Read = 8200 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 194 
n_pre = 178 
n_ref = 0 
n_req = 4098 
total_req = 16392 

Dual Bus Interface Util: 
issued_total_row = 372 
issued_total_col = 16392 
Row_Bus_Util =  0.000580 
CoL_Bus_Util = 0.025550 
Either_Row_CoL_Bus_Util = 0.026120 
Issued_on_Two_Bus_Simul_Util = 0.000009 
issued_two_Eff = 0.000358 
queue_avg = 1.105797 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=1.1058
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=641566 n_nop=624822 n_act=192 n_pre=176 n_ref_event=0 n_req=4096 n_rd=8192 n_rd_L2_A=4096 n_write=4096 n_wr_bk=0 bw_util=0.05108
n_activity=50103 dram_eff=0.654
bk0: 768a 637169i bk1: 768a 636994i bk2: 768a 636640i bk3: 768a 636469i bk4: 768a 637432i bk5: 768a 637159i bk6: 768a 637186i bk7: 768a 636840i bk8: 768a 637590i bk9: 768a 637361i bk10: 768a 637301i bk11: 768a 637045i bk12: 768a 637519i bk13: 768a 637537i bk14: 768a 637301i bk15: 768a 637145i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.953125
Row_Buffer_Locality_read = 0.958333
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.613526
Bank_Level_Parallism_Col = 1.613959
Bank_Level_Parallism_Ready = 1.355971
write_to_read_ratio_blp_rw_average = 0.313202
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051075 
total_CMD = 641566 
util_bw = 32768 
Wasted_Col = 12289 
Wasted_Row = 1347 
Idle = 595162 

BW Util Bottlenecks: 
RCDc_limit = 1031 
RCDWRc_limit = 307 
WTRc_limit = 9276 
RTWc_limit = 9593 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9276 
RTWc_limit_alone = 9593 

Commands details: 
total_CMD = 641566 
n_nop = 624822 
Read = 8192 
Write = 4096 
L2_Alloc = 4096 
L2_WB = 0 
n_act = 192 
n_pre = 176 
n_ref = 0 
n_req = 4096 
total_req = 16384 

Dual Bus Interface Util: 
issued_total_row = 368 
issued_total_col = 16384 
Row_Bus_Util =  0.000574 
CoL_Bus_Util = 0.025538 
Either_Row_CoL_Bus_Util = 0.026099 
Issued_on_Two_Bus_Simul_Util = 0.000012 
issued_two_Eff = 0.000478 
queue_avg = 0.992144 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.992144
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents
MSHR: tag=0xe57fe700, atomic=0 1 entries : 0x55f416359d90 :  mf: uid=6517726, sid17:w28, part=7, addr=0x7fe0e57fe700, load , size=128, unknown  status = IN_PARTITION_DRAM (412398), 
MSHR: tag=0xe57f7f00, atomic=0 1 entries : 0x55f41a5a3160 :  mf: uid=6517712, sid17:w15, part=7, addr=0x7fe0e57f7f00, load , size=128, unknown  status = IN_PARTITION_DRAM (412397), 

Cache L2_bank_015:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=641566 n_nop=624824 n_act=192 n_pre=176 n_ref_event=0 n_req=4096 n_rd=8192 n_rd_L2_A=4093 n_write=4096 n_wr_bk=0 bw_util=0.05107
n_activity=50224 dram_eff=0.6523
bk0: 768a 637571i bk1: 768a 637307i bk2: 768a 637259i bk3: 768a 636900i bk4: 768a 637173i bk5: 768a 637139i bk6: 768a 636681i bk7: 768a 636574i bk8: 768a 637318i bk9: 768a 637621i bk10: 768a 637250i bk11: 768a 637086i bk12: 768a 636995i bk13: 768a 637275i bk14: 765a 636752i bk15: 768a 637128i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.953125
Row_Buffer_Locality_read = 0.958333
Row_Buffer_Locality_write = 0.937500
Bank_Level_Parallism = 1.610760
Bank_Level_Parallism_Col = 1.611305
Bank_Level_Parallism_Ready = 1.330566
write_to_read_ratio_blp_rw_average = 0.326457
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.051066 
total_CMD = 641566 
util_bw = 32762 
Wasted_Col = 12725 
Wasted_Row = 1362 
Idle = 594717 

BW Util Bottlenecks: 
RCDc_limit = 1062 
RCDWRc_limit = 308 
WTRc_limit = 9446 
RTWc_limit = 9652 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 9446 
RTWc_limit_alone = 9652 

Commands details: 
total_CMD = 641566 
n_nop = 624824 
Read = 8192 
Write = 4096 
L2_Alloc = 4093 
L2_WB = 0 
n_act = 192 
n_pre = 176 
n_ref = 0 
n_req = 4096 
total_req = 16381 

Dual Bus Interface Util: 
issued_total_row = 368 
issued_total_col = 16381 
Row_Bus_Util =  0.000574 
CoL_Bus_Util = 0.025533 
Either_Row_CoL_Bus_Util = 0.026096 
Issued_on_Two_Bus_Simul_Util = 0.000011 
issued_two_Eff = 0.000418 
queue_avg = 0.964582 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=0.964582

========= L2 cache stats =========
L2_cache_bank[0]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 189, Reservation_fails = 28
L2_cache_bank[1]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 128, Reservation_fails = 9
L2_cache_bank[2]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 72, Reservation_fails = 0
L2_cache_bank[3]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 26, Reservation_fails = 10
L2_cache_bank[4]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 58, Reservation_fails = 31
L2_cache_bank[5]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 189, Reservation_fails = 25
L2_cache_bank[6]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 136, Reservation_fails = 6
L2_cache_bank[7]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 178, Reservation_fails = 10
L2_cache_bank[8]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 127, Reservation_fails = 8
L2_cache_bank[9]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 145, Reservation_fails = 2
L2_cache_bank[10]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 128, Reservation_fails = 2
L2_cache_bank[11]: Access = 16916, Miss = 1537, Miss_rate = 0.091, Pending_hits = 156, Reservation_fails = 16
L2_cache_bank[12]: Access = 16896, Miss = 1536, Miss_rate = 0.091, Pending_hits = 140, Reservation_fails = 14
L2_cache_bank[13]: Access = 16896, Miss = 1536, Miss_rate = 0.091, Pending_hits = 153, Reservation_fails = 16
L2_cache_bank[14]: Access = 16896, Miss = 1536, Miss_rate = 0.091, Pending_hits = 81, Reservation_fails = 30
L2_cache_bank[15]: Access = 16896, Miss = 1536, Miss_rate = 0.091, Pending_hits = 102, Reservation_fails = 5
L2_total_cache_accesses = 270576
L2_total_cache_misses = 24588
L2_total_cache_miss_rate = 0.0909
L2_total_cache_pending_hits = 2008
L2_total_cache_reservation_fails = 212
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 243871
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 1889
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 16384
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 1889
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 8192
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 212
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 109
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 119
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 12
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 119
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 262144
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 8192
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 240
L2_total_cache_reservation_fail_breakdown:
	L2_cache_stats_fail_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 212
L2_cache_data_port_util = 0.148
L2_cache_fill_port_util = 0.015

icnt_total_pkts_mem_to_simt=1320112
icnt_total_pkts_simt_to_mem=303344
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 41.9734
	minimum = 6
	maximum = 2827
Network latency average = 28.3817
	minimum = 6
	maximum = 1378
Slowest packet = 533
Flit latency average = 18.4321
	minimum = 6
	maximum = 1378
Slowest flit = 933
Fragmentation average = 0.0118821
	minimum = 0
	maximum = 373
Injected packet rate average = 0.0262441
	minimum = 0 (at node 36)
	maximum = 0.0410185 (at node 20)
Accepted packet rate average = 0.0262441
	minimum = 0 (at node 36)
	maximum = 0.0410185 (at node 20)
Injected flit rate average = 0.0787323
	minimum = 0 (at node 36)
	maximum = 0.200127 (at node 20)
Accepted flit rate average= 0.0787323
	minimum = 0 (at node 36)
	maximum = 0.162551 (at node 1)
Injected packet length average = 3
Accepted packet length average = 3
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 41.9734 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2827 (1 samples)
Network latency average = 28.3817 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1378 (1 samples)
Flit latency average = 18.4321 (1 samples)
	minimum = 6 (1 samples)
	maximum = 1378 (1 samples)
Fragmentation average = 0.0118821 (1 samples)
	minimum = 0 (1 samples)
	maximum = 373 (1 samples)
Injected packet rate average = 0.0262441 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0410185 (1 samples)
Accepted packet rate average = 0.0262441 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0410185 (1 samples)
Injected flit rate average = 0.0787323 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.200127 (1 samples)
Accepted flit rate average = 0.0787323 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.162551 (1 samples)
Injected packet size average = 3 (1 samples)
Accepted packet size average = 3 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 5 min, 16 sec (316 sec)
gpgpu_simulation_rate = 1257627 (inst/sec)
gpgpu_simulation_rate = 1305 (cycle/sec)
gpgpu_silicon_slowdown = 1231417x
GPGPU-Sim: *** simulation thread exiting ***
GPGPU-Sim: *** exit detected ***
