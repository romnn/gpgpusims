GPGPU-Sim version 4.2.0 (build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a-modified_590.0) configured with AccelWattch.

----------------------------------------------------------------------------
INFO - If you only care about PTX execution, ignore this message. GPGPU-Sim supports PTX execution in modern CUDA.
If you want to run PTXPLUS (sm_1x SASS) with a modern card configuration - set the envronment variable
$PTXAS_CUDA_INSTALL_PATH to point a CUDA version compabible with your card configurations (i.e. 8+ for PASCAL, 9+ for VOLTA etc..)
For example: "export $PTXAS_CUDA_INSTALL_PATH=/usr/local/cuda-9.1"

The following text describes why:
If you are using PTXPLUS, only sm_1x is supported and it requires that the app and simulator binaries are compiled in CUDA 4.2 or less.
The simulator requires it since CUDA headers desribe struct sizes in the exec which change from gen to gen.
The apps require 4.2 because new versions of CUDA tools have dropped parsing support for generating sm_1x
When running using modern config (i.e. volta) and PTXPLUS with CUDA 4.2, the $PTXAS_CUDA_INSTALL_PATH env variable is required to get proper register usage
(and hence occupancy) using a version of CUDA that knows the register usage on the real card.

----------------------------------------------------------------------------
setup_environment succeeded
Accel-Sim [build accelsim-commit-e02c99dbadefc0b9dc95317100be2a446eec142c_modified_0.0]

        *** GPGPU-Sim Simulator Version 4.2.0  [build gpgpu-sim_git-commit-13c67115070dc2f0876254a790d0238073ca364a_modified_0.0] ***


GPGPU-Sim: Configuration options:

-save_embedded_ptx                      0 # saves ptx files embedded in binary as <n>.ptx
-keep                                   0 # keep intermediate files created by GPGPU-Sim when interfacing with external programs
-gpgpu_ptx_save_converted_ptxplus                    0 # Saved converted ptxplus to a file
-gpgpu_occupancy_sm_number                   60 # The SM number to pass to ptxas when getting register usage for computing GPU occupancy. This parameter is required in the config.
-ptx_opcode_latency_int         4,13,4,5,145 # Opcode latencies for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,19,25,145,32
-ptx_opcode_latency_fp          4,13,4,5,39 # Opcode latencies for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,30
-ptx_opcode_latency_dp         8,19,8,8,330 # Opcode latencies for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,335
-ptx_opcode_latency_sfu                    8 # Opcode latencies for SFU instructionsDefault 8
-ptx_opcode_latency_tesnor                   64 # Opcode latencies for Tensor instructionsDefault 64
-ptx_opcode_initiation_int            1,2,2,2,8 # Opcode initiation intervals for integers <ADD,MAX,MUL,MAD,DIV,SHFL>Default 1,1,4,4,32,4
-ptx_opcode_initiation_fp            1,2,1,1,4 # Opcode initiation intervals for single precision floating points <ADD,MAX,MUL,MAD,DIV>Default 1,1,1,1,5
-ptx_opcode_initiation_dp          1,2,1,1,130 # Opcode initiation intervals for double precision floating points <ADD,MAX,MUL,MAD,DIV>Default 8,8,8,8,130
-ptx_opcode_initiation_sfu                    8 # Opcode initiation intervals for sfu instructionsDefault 8
-ptx_opcode_initiation_tensor                   64 # Opcode initiation intervals for tensor instructionsDefault 64
-cdp_latency         7200,8000,100,12000,1600 # CDP API latency <cudaStreamCreateWithFlags, cudaGetParameterBufferV2_init_perWarp, cudaGetParameterBufferV2_perKernel, cudaLaunchDeviceV2_init_perWarp, cudaLaunchDevicV2_perKernel>Default 7200,8000,100,12000,1600
-network_mode                           1 # Interconnection network mode
-inter_config_file   config_fermi_islip.icnt # Interconnection network config file
-icnt_in_buffer_limit                   64 # in_buffer_limit
-icnt_out_buffer_limit                   64 # out_buffer_limit
-icnt_subnets                           2 # subnets
-icnt_arbiter_algo                      1 # arbiter_algo
-icnt_verbose                           0 # inct_verbose
-icnt_grant_cycles                      1 # grant_cycles
-gpgpu_ptx_use_cuobjdump                    1 # Use cuobjdump to extract ptx and sass from binaries
-gpgpu_experimental_lib_support                    0 # Try to extract code from cuda libraries [Broken because of unknown cudaGetExportTable]
-checkpoint_option                      0 #  checkpointing flag (0 = no checkpoint)
-checkpoint_kernel                      1 #  checkpointing during execution of which kernel (1- 1st kernel)
-checkpoint_CTA                         0 #  checkpointing after # of CTA (< less than total CTA)
-resume_option                          0 #  resume flag (0 = no resume)
-resume_kernel                          0 #  Resume from which kernel (1= 1st kernel)
-resume_CTA                             0 #  resume from which CTA 
-checkpoint_CTA_t                       0 #  resume from which CTA 
-checkpoint_insn_Y                      0 #  resume from which CTA 
-gpgpu_ptx_convert_to_ptxplus                    0 # Convert SASS (native ISA) to ptxplus and run ptxplus
-gpgpu_ptx_force_max_capability                   60 # Force maximum compute capability
-gpgpu_ptx_inst_debug_to_file                    0 # Dump executed instructions' debug information to file
-gpgpu_ptx_inst_debug_file       inst_debug.txt # Executed instructions' debug output file
-gpgpu_ptx_inst_debug_thread_uid                    1 # Thread UID for executed instructions' debug output
-gpgpu_simd_model                       1 # 1 = post-dominator
-gpgpu_shader_core_pipeline              2048:32 # shader core pipeline config, i.e., {<nthread>:<warpsize>}
-gpgpu_tex_cache:l1  N:16:128:24,L:R:m:N:L,F:128:4,128:2 # per-shader L1 texture cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>:<rf>}
-gpgpu_const_cache:l1 N:128:64:2,L:R:f:N:L,A:2:64,4 # per-shader L1 constant memory cache  (READ-ONLY) config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:il1     N:8:128:4,L:R:f:N:L,A:2:48,4 # shader L1 instruction cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>} 
-gpgpu_cache:dl1     N:64:128:6,L:L:m:N:H,A:128:8,8 # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_l1_cache_write_ratio                    0 # L1D write ratio
-gpgpu_l1_banks                         1 # The number of L1 cache banks
-gpgpu_l1_banks_byte_interleaving                   32 # l1 banks byte interleaving granularity
-gpgpu_l1_banks_hashing_function                    0 # l1 banks hashing function
-gpgpu_l1_latency                       1 # L1 Hit Latency
-gpgpu_smem_latency                     3 # smem Latency
-gpgpu_cache:dl1PrefL1                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_cache:dl1PrefShared                 none # per-shader L1 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq> | none}
-gpgpu_gmem_skip_L1D                    1 # global memory access skip L1D cache (implements -Xptxas -dlcm=cg, default=no skip)
-gpgpu_perfect_mem                      0 # enable perfect memory mode (no cache miss)
-n_regfile_gating_group                    4 # group of lanes that should be read/written together)
-gpgpu_clock_gated_reg_file                    0 # enable clock gated reg file for power calculations
-gpgpu_clock_gated_lanes                    0 # enable clock gated lanes for power calculations
-gpgpu_shader_registers                65536 # Number of registers per shader core. Limits number of concurrent CTAs. (default 8192)
-gpgpu_registers_per_block                 8192 # Maximum number of registers per CTA. (default 8192)
-gpgpu_ignore_resources_limitation                    0 # gpgpu_ignore_resources_limitation (default 0)
-gpgpu_shader_cta                      32 # Maximum number of concurrent CTAs in shader (default 32)
-gpgpu_num_cta_barriers                   16 # Maximum number of named barriers per CTA (default 16)
-gpgpu_n_clusters                      20 # number of processing clusters
-gpgpu_n_cores_per_cluster                    1 # number of simd cores per cluster
-gpgpu_n_cluster_ejection_buffer_size                    8 # number of packets in ejection buffer
-gpgpu_n_ldst_response_buffer_size                    2 # number of response packets in ld/st unit ejection buffer
-gpgpu_shmem_per_block                49152 # Size of shared memory per thread block or CTA (default 48kB)
-gpgpu_shmem_size                   98304 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_option                     0 # Option list of shared memory sizes
-gpgpu_unified_l1d_size                    0 # Size of unified data cache(L1D + shared memory) in KB
-gpgpu_adaptive_cache_config                    0 # adaptive_cache_config
-gpgpu_shmem_sizeDefault                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefL1                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_size_PrefShared                16384 # Size of shared memory per shader core (default 16kB)
-gpgpu_shmem_num_banks                   32 # Number of banks in the shared memory in each shader core (default 16)
-gpgpu_shmem_limited_broadcast                    0 # Limit shared memory to do one broadcast per cycle (default on)
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_mem_unit_ports                    1 # The number of memory transactions allowed per core cycle
-gpgpu_shmem_warp_parts                    1 # Number of portions a warp is divided into for shared memory bank conflict check 
-gpgpu_warpdistro_shader                   -1 # Specify which shader core to collect the warp size distribution from
-gpgpu_warp_issue_shader                    0 # Specify which shader core to collect the warp issue distribution from
-gpgpu_local_mem_map                    1 # Mapping from local memory space address to simulated GPU physical address space (default = enabled)
-gpgpu_num_reg_banks                   32 # Number of register banks (default = 8)
-gpgpu_reg_bank_use_warp_id                    0 # Use warp ID in mapping registers to banks (default = off)
-gpgpu_sub_core_model                    0 # Sub Core Volta/Pascal model (default = off)
-gpgpu_enable_specialized_operand_collector                    1 # enable_specialized_operand_collector
-gpgpu_operand_collector_num_units_sp                   20 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_dp                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_sfu                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_int                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_units_tensor_core                    4 # number of collector units (default = 4)
-gpgpu_operand_collector_num_units_mem                    8 # number of collector units (default = 2)
-gpgpu_operand_collector_num_units_gen                    0 # number of collector units (default = 0)
-gpgpu_operand_collector_num_in_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_in_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_in_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sp                    4 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_dp                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_sfu                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_int                    0 # number of collector unit in ports (default = 0)
-gpgpu_operand_collector_num_out_ports_tensor_core                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_mem                    1 # number of collector unit in ports (default = 1)
-gpgpu_operand_collector_num_out_ports_gen                    0 # number of collector unit in ports (default = 0)
-gpgpu_coalesce_arch                   13 # Coalescing arch (GT200 = 13, Fermi = 20)
-gpgpu_num_sched_per_core                    2 # Number of warp schedulers per core
-gpgpu_max_insn_issue_per_warp                    2 # Max number of instructions that can be issued per warp in one cycle by scheduler (either 1 or 2)
-gpgpu_dual_issue_diff_exec_units                    1 # should dual issue use two different execution unit resources (Default = 1)
-gpgpu_simt_core_sim_order                    1 # Select the simulation order of cores in a cluster (0=Fix, 1=Round-Robin)
-gpgpu_pipeline_widths 4,0,0,1,1,4,0,0,1,1,6 # Pipeline widths ID_OC_SP,ID_OC_DP,ID_OC_INT,ID_OC_SFU,ID_OC_MEM,OC_EX_SP,OC_EX_DP,OC_EX_INT,OC_EX_SFU,OC_EX_MEM,EX_WB,ID_OC_TENSOR_CORE,OC_EX_TENSOR_CORE
-gpgpu_tensor_core_avail                    0 # Tensor Core Available (default=0)
-gpgpu_num_sp_units                     4 # Number of SP units (default=1)
-gpgpu_num_dp_units                     0 # Number of DP units (default=0)
-gpgpu_num_int_units                    0 # Number of INT units (default=0)
-gpgpu_num_sfu_units                    1 # Number of SF units (default=1)
-gpgpu_num_tensor_core_units                    0 # Number of tensor_core units (default=1)
-gpgpu_num_mem_units                    1 # Number if ldst units (default=1) WARNING: not hooked up to anything
-gpgpu_scheduler                      gto # Scheduler configuration: < lrr | gto | two_level_active > If two_level_active:<num_active_warps>:<inner_prioritization>:<outer_prioritization>For complete list of prioritization values see shader.h enum scheduler_prioritization_typeDefault: gto
-gpgpu_concurrent_kernel_sm                    0 # Support concurrent kernels on a SM (default = disabled)
-gpgpu_perfect_inst_const_cache                    0 # perfect inst and const cache mode, so all inst and const hits in the cache(default = disabled)
-gpgpu_inst_fetch_throughput                    1 # the number of fetched intruction per warp each cycle
-gpgpu_reg_file_port_throughput                    1 # the number ports of the register file
-specialized_unit_1         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_2         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_3         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_4         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_5         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_6         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_7         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-specialized_unit_8         0,4,4,4,4,BRA # specialized unit config {<enabled>,<num_units>:<latency>:<initiation>,<ID_OC_SPEC>:<OC_EX_SPEC>,<NAME>}
-gpgpu_perf_sim_memcpy                    1 # Fill the L2 cache on memcpy
-gpgpu_simple_dram_model                    0 # simple_dram_model with fixed latency and BW
-gpgpu_dram_scheduler                    1 # 0 = fifo, 1 = FR-FCFS (defaul)
-gpgpu_dram_partition_queues              8:8:8:8 # i2$:$2d:d2$:$2i
-l2_ideal                               0 # Use a ideal L2 cache that always hit
-gpgpu_cache:dl2     N:64:128:16,L:B:m:W:L,A:1024:1024,4:0,32 # unified banked L2 data cache config  {<nsets>:<bsize>:<assoc>,<rep>:<wr>:<alloc>:<wr_alloc>,<mshr>:<N>:<merge>,<mq>}
-gpgpu_cache:dl2_texture_only                    0 # L2 cache used for texture only
-gpgpu_n_mem                            8 # number of memory modules (e.g. memory controllers) in gpu
-gpgpu_n_sub_partition_per_mchannel                    2 # number of memory subpartition in each memory module
-gpgpu_n_mem_per_ctrlr                    1 # number of memory chips per memory controller
-gpgpu_memlatency_stat                   14 # track and display latency statistics 0x2 enables MC, 0x4 enables queue logs
-gpgpu_frfcfs_dram_sched_queue_size                   64 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_return_queue_size                  116 # 0 = unlimited (default); # entries per chip
-gpgpu_dram_buswidth                    4 # default = 4 bytes (8 bytes per cycle at DDR)
-gpgpu_dram_burst_length                    8 # Burst length of each DRAM request (default = 4 data bus cycle)
-dram_data_command_freq_ratio                    4 # Frequency ratio between DRAM data bus and command bus (default = 2 times, i.e. DDR)
-gpgpu_dram_timing_opt nbk=16:CCD=2:RRD=6:RCD=12:RAS=28:RP=12:RC=40: CL=12:WL=4:CDLR=5:WR=12:nbkgrp=1:CCDL=0:RTPL=0 # DRAM timing parameters = {nbk:tCCD:tRRD:tRCD:tRAS:tRP:tRC:CL:WL:tCDLR:tWR:nbkgrp:tCCDL:tRTPL}
-gpgpu_l2_rop_latency                  120 # ROP queue latency (default 85)
-dram_latency                         100 # DRAM latency (default 30)
-dram_dual_bus_interface                    0 # dual_bus_interface (default = 0) 
-dram_bnk_indexing_policy                    0 # dram_bnk_indexing_policy (0 = normal indexing, 1 = Xoring with the higher bits) (Default = 0)
-dram_bnkgrp_indexing_policy                    0 # dram_bnkgrp_indexing_policy (0 = take higher bits, 1 = take lower bits) (Default = 0)
-dram_seperate_write_queue_enable                    0 # Seperate_Write_Queue_Enable
-dram_write_queue_size             32:28:16 # Write_Queue_Size
-dram_elimnate_rw_turnaround                    0 # elimnate_rw_turnaround i.e set tWTR and tRTW = 0
-icnt_flit_size                        32 # icnt_flit_size
-gpgpu_mem_addr_mapping dramid@8;00000000.00000000.00000000.00000000.0000RRRR.RRRRRRRR.RBBBCCCC.BCCSSSSS # mapping memory address to dram model {dramid@<start bit>;<memory address map>}
-gpgpu_mem_addr_test                    0 # run sweep test to check address mapping for aliased address
-gpgpu_mem_address_mask                    1 # 0 = old addressing mask, 1 = new addressing mask, 2 = new add. mask + flipped bank sel and chip sel bits
-gpgpu_memory_partition_indexing                    0 # 0 = no indexing, 1 = bitwise xoring, 2 = IPoly, 3 = custom indexing
-accelwattch_xml_file accelwattch_sass_sim.xml # AccelWattch XML file
-power_simulation_enabled                    0 # Turn on power simulator (1=On, 0=Off)
-power_per_cycle_dump                    0 # Dump detailed power output each cycle
-hw_perf_file_name            hw_perf.csv # Hardware Performance Statistics file
-hw_perf_bench_name                       # Kernel Name in Hardware Performance Statistics file
-power_simulation_mode                    0 # Switch performance counter input for power simulation (0=Sim, 1=HW, 2=HW-Sim Hybrid)
-dvfs_enabled                           0 # Turn on DVFS for power model
-aggregate_power_stats                    0 # Accumulate power across all kernels
-accelwattch_hybrid_perfsim_L1_RH                    0 # Get L1 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_RM                    0 # Get L1 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WH                    0 # Get L1 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L1_WM                    0 # Get L1 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RH                    0 # Get L2 Read Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_RM                    0 # Get L2 Read Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WH                    0 # Get L2 Write Hits for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_L2_WM                    0 # Get L2 Write Misses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CC_ACC                    0 # Get Constant Cache Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_SHARED_ACC                    0 # Get Shared Memory Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_RD                    0 # Get DRAM Reads for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_DRAM_WR                    0 # Get DRAM Writes for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NOC                    0 # Get Interconnect Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_PIPE_DUTY                    0 # Get Pipeline Duty Cycle Acesses for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_NUM_SM_IDLE                    0 # Get Number of Idle SMs for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_CYCLES                    0 # Get Executed Cycles for Accelwattch-Hybrid from Accel-Sim
-accelwattch_hybrid_perfsim_VOLTAGE                    0 # Get Chip Voltage for Accelwattch-Hybrid from Accel-Sim
-power_trace_enabled                    0 # produce a file for the power trace (1=On, 0=Off)
-power_trace_zlevel                     6 # Compression level of the power trace output log (0=no comp, 9=highest)
-steady_power_levels_enabled                    0 # produce a file for the steady power levels (1=On, 0=Off)
-steady_state_definition                  8:4 # allowed deviation:number of samples
-gpgpu_max_cycle                        0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_insn                         0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_cta                          0 # terminates gpu simulation early (0 = no limit)
-gpgpu_max_completed_cta                    0 # terminates gpu simulation early (0 = no limit)
-gpgpu_runtime_stat                   500 # display runtime statistics such as dram utilization {<freq>:<flag>}
-liveness_message_freq                    1 # Minimum number of seconds between simulation liveness messages (0 = always print)
-gpgpu_compute_capability_major                    7 # Major compute capability version number
-gpgpu_compute_capability_minor                    0 # Minor compute capability version number
-gpgpu_flush_l1_cache                    0 # Flush L1 cache at the end of each kernel call
-gpgpu_flush_l2_cache                    0 # Flush L2 cache at the end of each kernel call
-gpgpu_deadlock_detect                    1 # Stop the simulation at deadlock (1=on (default), 0=off)
-gpgpu_ptx_instruction_classification                    0 # if enabled will classify ptx instruction types per kernel (Max 255 kernels now)
-gpgpu_ptx_sim_mode                     0 # Select between Performance (default) or Functional simulation (1)
-gpgpu_clock_domains 1607.0:2962.0:1607.0:2750.0 # Clock Domain Frequencies in MhZ {<Core Clock>:<ICNT Clock>:<L2 Clock>:<DRAM Clock>}
-gpgpu_max_concurrent_kernel                   32 # maximum kernels that can run concurrently on GPU, set this value according to max resident grids for your compute capability
-gpgpu_cflog_interval                    0 # Interval between each snapshot in control flow logger
-visualizer_enabled                     0 # Turn on visualizer output (1=On, 0=Off)
-visualizer_outputfile                 NULL # Specifies the output log file for visualizer
-visualizer_zlevel                      6 # Compression level of the visualizer output log (0=no comp, 9=highest)
-gpgpu_stack_size_limit                 1024 # GPU thread stack size
-gpgpu_heap_size_limit              8388608 # GPU malloc heap size 
-gpgpu_runtime_sync_depth_limit                    2 # GPU device runtime synchronize depth
-gpgpu_runtime_pending_launch_count_limit                 2048 # GPU device runtime pending launch count
-trace_enabled                          0 # Turn on traces
-trace_components                    none # comma seperated list of traces to enable. Complete list found in trace_streams.tup. Default none
-trace_sampling_core                    0 # The core which is printed using CORE_DPRINTF. Default 0
-trace_sampling_memory_partition                   -1 # The memory partition which is printed using MEMPART_DPRINTF. Default -1 (i.e. all)
-enable_ptx_file_line_stats                    1 # Turn on PTX source line statistic profiling. (1 = On)
-ptx_line_stats_filename gpgpu_inst_stats.txt # Output file for PTX source line statistics.
-gpgpu_kernel_launch_latency                    0 # Kernel launch latency in cycles. Default: 0
-gpgpu_cdp_enabled                      0 # Turn on CDP
-gpgpu_TB_launch_latency                    0 # thread block launch latency in cycles. Default: 0
-trace               /benchrun/accelsim-sass/vectoradd/sm6_gtx1080/input-1000000/results/traces/kernelslist.g # traces kernel filetraces kernel file directory
-trace_opcode_latency_initiation_int                  4,1 # Opcode latencies and initiation for integers in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_sp                  4,1 # Opcode latencies and initiation for sp in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_dp                  4,1 # Opcode latencies and initiation for dp in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_sfu                  4,1 # Opcode latencies and initiation for sfu in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_tensor                  4,1 # Opcode latencies and initiation for tensor in trace driven mode <latency,initiation>
-trace_opcode_latency_initiation_spec_op_1                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_2                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_3                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_4                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_5                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_6                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_7                  4,4 # specialized unit config <latency,initiation>
-trace_opcode_latency_initiation_spec_op_8                  4,4 # specialized unit config <latency,initiation>
DRAM Timing Options:
nbk                                    16 # number of banks
CCD                                     2 # column to column delay
RRD                                     6 # minimal delay between activation of rows in different banks
RCD                                    12 # row to column delay
RAS                                    28 # time needed to activate row
RP                                     12 # time needed to precharge (deactivate) row
RC                                     40 # row cycle time
CDLR                                    5 # switching from write to read (changes tWTR)
WR                                     12 # last data-in to row precharge
CL                                     12 # CAS latency
WL                                      4 # Write latency
nbkgrp                                  1 # number of bank groups
CCDL                                    0 # column to column delay between accesses to different bank groups
RTPL                                    0 # read to precharge delay between accesses to different bank groups
Total number of memory sub partition = 16
addr_dec_mask[CHIP]  = 0000000000000700 	high:11 low:8
addr_dec_mask[BK]    = 0000000000038080 	high:18 low:7
addr_dec_mask[ROW]   = 000000007ffc0000 	high:31 low:18
addr_dec_mask[COL]   = 000000000000787f 	high:15 low:0
addr_dec_mask[BURST] = 000000000000001f 	high:5 low:0
sub_partition_id_mask = 0000000000000080
GPGPU-Sim uArch: clock freqs: 1607000000.000000:2962000000.000000:1607000000.000000:2750000000.000000
GPGPU-Sim uArch: clock periods: 0.00000000062227753578:0.00000000033760972316:0.00000000062227753578:0.00000000036363636364
*** Initializing Memory Statistics ***
GPGPU-Sim uArch: interconnect node map (shaderID+MemID to icntID)
GPGPU-Sim uArch: Memory nodes ID start from index: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: interconnect node reverse map (icntID to shaderID+MemID)
GPGPU-Sim uArch: Memory nodes start from ID: 20
GPGPU-Sim uArch:    0   1   2   3   4   5   6
GPGPU-Sim uArch:    7   8   9  10  11  12  13
GPGPU-Sim uArch:   14  15  16  17  18  19  20
GPGPU-Sim uArch:   21  22  23  24  25  26  27
GPGPU-Sim uArch:   28  29  30  31  32  33  34
GPGPU-Sim uArch:   35  36  37  38  39  40  41
GPGPU-Sim uArch:   42  43  44  45  46  47  48
GPGPU-Sim uArch:   49
GPGPU-Sim uArch: performance model initialization complete.
launching memcpy command : MemcpyHtoD,0x00007f47dd600000,8000000
launching memcpy command : MemcpyHtoD,0x00007f47e4a00000,8000000
launching memcpy command : MemcpyHtoD,0x00007f47e5200000,8000000
Processing kernel /benchrun/accelsim-sass/vectoradd/sm6_gtx1080/input-1000000/results/traces/kernel-1.traceg
-kernel name = _Z6vecAddPdS_S_i
-kernel id = 1
-grid dim = (977,1,1)
-block dim = (1024,1,1)
-shmem = 0
-nregs = 10
-binary version = 61
-cuda stream id = 0
-shmem base_addr = 0x00007f480b000000
-local mem base_addr = 0x00007f4809000000
-nvbit version = 1.5.5
-accelsim tracer version = 3
Header info loaded for kernel command : /benchrun/accelsim-sass/vectoradd/sm6_gtx1080/input-1000000/results/traces/kernel-1.traceg
launching kernel name: _Z6vecAddPdS_S_i uid: 1
GPGPU-Sim uArch: Shader 0 bind to kernel 1 '_Z6vecAddPdS_S_i'
GPGPU-Sim uArch: CTA/core = 2, limited by: threads
thread block = 0,0,0
GPGPU-Sim uArch: Shader 1 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 1,0,0
GPGPU-Sim uArch: Shader 2 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 2,0,0
GPGPU-Sim uArch: Shader 3 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 3,0,0
GPGPU-Sim uArch: Shader 4 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 4,0,0
GPGPU-Sim uArch: Shader 5 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 5,0,0
GPGPU-Sim uArch: Shader 6 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 6,0,0
GPGPU-Sim uArch: Shader 7 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 7,0,0
GPGPU-Sim uArch: Shader 8 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 8,0,0
GPGPU-Sim uArch: Shader 9 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 9,0,0
GPGPU-Sim uArch: Shader 10 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 10,0,0
GPGPU-Sim uArch: Shader 11 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 11,0,0
GPGPU-Sim uArch: Shader 12 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 12,0,0
GPGPU-Sim uArch: Shader 13 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 13,0,0
GPGPU-Sim uArch: Shader 14 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 14,0,0
GPGPU-Sim uArch: Shader 15 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 15,0,0
GPGPU-Sim uArch: Shader 16 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 16,0,0
GPGPU-Sim uArch: Shader 17 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 17,0,0
GPGPU-Sim uArch: Shader 18 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 18,0,0
GPGPU-Sim uArch: Shader 19 bind to kernel 1 '_Z6vecAddPdS_S_i'
thread block = 19,0,0
thread block = 20,0,0
thread block = 21,0,0
thread block = 22,0,0
thread block = 23,0,0
thread block = 24,0,0
thread block = 25,0,0
thread block = 26,0,0
thread block = 27,0,0
thread block = 28,0,0
thread block = 29,0,0
thread block = 30,0,0
thread block = 31,0,0
thread block = 32,0,0
thread block = 33,0,0
thread block = 34,0,0
thread block = 35,0,0
thread block = 36,0,0
thread block = 37,0,0
thread block = 38,0,0
thread block = 39,0,0
thread block = 40,0,0
thread block = 41,0,0
thread block = 42,0,0
thread block = 43,0,0
thread block = 44,0,0
thread block = 45,0,0
thread block = 46,0,0
thread block = 47,0,0
thread block = 48,0,0
thread block = 49,0,0
thread block = 50,0,0
thread block = 51,0,0
thread block = 52,0,0
thread block = 53,0,0
thread block = 54,0,0
thread block = 55,0,0
thread block = 56,0,0
thread block = 57,0,0
thread block = 58,0,0
thread block = 59,0,0
thread block = 60,0,0
thread block = 61,0,0
thread block = 62,0,0
thread block = 63,0,0
thread block = 64,0,0
thread block = 65,0,0
thread block = 66,0,0
thread block = 67,0,0
thread block = 68,0,0
thread block = 69,0,0
thread block = 70,0,0
thread block = 71,0,0
thread block = 72,0,0
thread block = 73,0,0
thread block = 74,0,0
thread block = 75,0,0
thread block = 76,0,0
thread block = 77,0,0
thread block = 78,0,0
thread block = 79,0,0
thread block = 80,0,0
thread block = 81,0,0
thread block = 82,0,0
thread block = 83,0,0
thread block = 84,0,0
thread block = 85,0,0
thread block = 86,0,0
thread block = 87,0,0
thread block = 88,0,0
thread block = 89,0,0
thread block = 90,0,0
thread block = 91,0,0
thread block = 92,0,0
thread block = 93,0,0
thread block = 94,0,0
thread block = 95,0,0
thread block = 96,0,0
thread block = 97,0,0
thread block = 98,0,0
thread block = 99,0,0
thread block = 100,0,0
thread block = 101,0,0
thread block = 102,0,0
thread block = 103,0,0
thread block = 104,0,0
thread block = 105,0,0
thread block = 106,0,0
thread block = 107,0,0
thread block = 108,0,0
thread block = 109,0,0
thread block = 110,0,0
thread block = 111,0,0
thread block = 112,0,0
thread block = 113,0,0
thread block = 114,0,0
thread block = 115,0,0
thread block = 116,0,0
thread block = 117,0,0
thread block = 118,0,0
thread block = 119,0,0
thread block = 120,0,0
thread block = 121,0,0
thread block = 122,0,0
thread block = 123,0,0
thread block = 124,0,0
thread block = 125,0,0
thread block = 126,0,0
thread block = 127,0,0
thread block = 128,0,0
thread block = 129,0,0
thread block = 130,0,0
thread block = 131,0,0
thread block = 132,0,0
thread block = 133,0,0
thread block = 134,0,0
thread block = 135,0,0
thread block = 136,0,0
thread block = 137,0,0
thread block = 138,0,0
thread block = 139,0,0
thread block = 140,0,0
thread block = 141,0,0
thread block = 142,0,0
thread block = 143,0,0
thread block = 144,0,0
thread block = 145,0,0
thread block = 146,0,0
thread block = 147,0,0
thread block = 148,0,0
thread block = 149,0,0
thread block = 150,0,0
thread block = 151,0,0
thread block = 152,0,0
thread block = 153,0,0
thread block = 154,0,0
thread block = 155,0,0
thread block = 156,0,0
thread block = 157,0,0
thread block = 158,0,0
thread block = 159,0,0
thread block = 160,0,0
thread block = 161,0,0
thread block = 162,0,0
thread block = 163,0,0
thread block = 164,0,0
thread block = 165,0,0
thread block = 166,0,0
thread block = 167,0,0
thread block = 168,0,0
thread block = 169,0,0
thread block = 170,0,0
thread block = 171,0,0
thread block = 172,0,0
thread block = 173,0,0
thread block = 174,0,0
thread block = 175,0,0
thread block = 176,0,0
thread block = 177,0,0
thread block = 178,0,0
thread block = 179,0,0
thread block = 180,0,0
thread block = 181,0,0
thread block = 182,0,0
thread block = 183,0,0
thread block = 184,0,0
thread block = 185,0,0
thread block = 186,0,0
thread block = 187,0,0
thread block = 188,0,0
thread block = 189,0,0
thread block = 190,0,0
thread block = 191,0,0
thread block = 192,0,0
thread block = 193,0,0
thread block = 194,0,0
thread block = 195,0,0
thread block = 196,0,0
thread block = 197,0,0
thread block = 198,0,0
thread block = 199,0,0
thread block = 200,0,0
thread block = 201,0,0
thread block = 202,0,0
thread block = 203,0,0
thread block = 204,0,0
thread block = 205,0,0
thread block = 206,0,0
thread block = 207,0,0
thread block = 208,0,0
thread block = 209,0,0
thread block = 210,0,0
thread block = 211,0,0
thread block = 212,0,0
thread block = 213,0,0
thread block = 214,0,0
thread block = 215,0,0
thread block = 216,0,0
thread block = 217,0,0
thread block = 218,0,0
thread block = 219,0,0
thread block = 220,0,0
thread block = 221,0,0
thread block = 222,0,0
thread block = 223,0,0
thread block = 224,0,0
thread block = 225,0,0
thread block = 226,0,0
thread block = 227,0,0
thread block = 228,0,0
thread block = 229,0,0
thread block = 230,0,0
thread block = 231,0,0
thread block = 232,0,0
thread block = 233,0,0
thread block = 234,0,0
thread block = 235,0,0
thread block = 236,0,0
thread block = 237,0,0
thread block = 238,0,0
thread block = 239,0,0
thread block = 240,0,0
thread block = 241,0,0
thread block = 242,0,0
thread block = 243,0,0
thread block = 244,0,0
thread block = 245,0,0
thread block = 246,0,0
thread block = 247,0,0
thread block = 248,0,0
thread block = 249,0,0
thread block = 250,0,0
thread block = 251,0,0
thread block = 252,0,0
thread block = 253,0,0
thread block = 254,0,0
thread block = 255,0,0
thread block = 256,0,0
thread block = 257,0,0
thread block = 258,0,0
thread block = 259,0,0
thread block = 260,0,0
thread block = 261,0,0
thread block = 262,0,0
thread block = 263,0,0
thread block = 264,0,0
thread block = 265,0,0
thread block = 266,0,0
thread block = 267,0,0
thread block = 268,0,0
thread block = 269,0,0
thread block = 270,0,0
thread block = 271,0,0
thread block = 272,0,0
thread block = 273,0,0
thread block = 274,0,0
thread block = 275,0,0
thread block = 276,0,0
thread block = 277,0,0
thread block = 278,0,0
thread block = 279,0,0
thread block = 280,0,0
thread block = 281,0,0
thread block = 282,0,0
thread block = 283,0,0
thread block = 284,0,0
thread block = 285,0,0
thread block = 286,0,0
thread block = 287,0,0
thread block = 288,0,0
thread block = 289,0,0
thread block = 290,0,0
thread block = 291,0,0
thread block = 292,0,0
thread block = 293,0,0
thread block = 294,0,0
thread block = 295,0,0
thread block = 296,0,0
thread block = 297,0,0
thread block = 298,0,0
thread block = 299,0,0
thread block = 300,0,0
thread block = 301,0,0
thread block = 302,0,0
thread block = 303,0,0
thread block = 304,0,0
thread block = 305,0,0
thread block = 306,0,0
thread block = 307,0,0
thread block = 308,0,0
thread block = 309,0,0
thread block = 310,0,0
thread block = 311,0,0
thread block = 312,0,0
thread block = 313,0,0
thread block = 314,0,0
thread block = 315,0,0
thread block = 316,0,0
thread block = 317,0,0
thread block = 318,0,0
thread block = 319,0,0
thread block = 320,0,0
thread block = 321,0,0
thread block = 322,0,0
thread block = 323,0,0
thread block = 324,0,0
thread block = 325,0,0
thread block = 326,0,0
thread block = 327,0,0
thread block = 328,0,0
thread block = 329,0,0
thread block = 330,0,0
thread block = 331,0,0
thread block = 332,0,0
thread block = 333,0,0
thread block = 334,0,0
thread block = 335,0,0
thread block = 336,0,0
thread block = 337,0,0
thread block = 338,0,0
thread block = 339,0,0
thread block = 340,0,0
thread block = 341,0,0
thread block = 342,0,0
thread block = 343,0,0
thread block = 344,0,0
thread block = 345,0,0
thread block = 346,0,0
thread block = 347,0,0
thread block = 348,0,0
thread block = 349,0,0
thread block = 350,0,0
thread block = 351,0,0
thread block = 352,0,0
thread block = 353,0,0
thread block = 354,0,0
thread block = 355,0,0
thread block = 356,0,0
thread block = 357,0,0
thread block = 358,0,0
thread block = 359,0,0
thread block = 360,0,0
thread block = 361,0,0
thread block = 362,0,0
thread block = 363,0,0
thread block = 364,0,0
thread block = 365,0,0
thread block = 366,0,0
thread block = 367,0,0
thread block = 368,0,0
thread block = 369,0,0
thread block = 370,0,0
thread block = 371,0,0
thread block = 372,0,0
thread block = 373,0,0
thread block = 374,0,0
thread block = 375,0,0
thread block = 376,0,0
thread block = 377,0,0
thread block = 378,0,0
thread block = 379,0,0
thread block = 380,0,0
thread block = 381,0,0
thread block = 382,0,0
thread block = 383,0,0
thread block = 384,0,0
thread block = 385,0,0
thread block = 386,0,0
thread block = 387,0,0
thread block = 388,0,0
thread block = 389,0,0
thread block = 390,0,0
thread block = 391,0,0
thread block = 392,0,0
thread block = 393,0,0
thread block = 394,0,0
thread block = 395,0,0
thread block = 396,0,0
thread block = 397,0,0
thread block = 398,0,0
thread block = 399,0,0
thread block = 400,0,0
thread block = 401,0,0
thread block = 402,0,0
thread block = 403,0,0
thread block = 404,0,0
thread block = 405,0,0
thread block = 406,0,0
thread block = 407,0,0
thread block = 408,0,0
thread block = 409,0,0
thread block = 410,0,0
thread block = 411,0,0
thread block = 412,0,0
thread block = 413,0,0
thread block = 414,0,0
thread block = 415,0,0
thread block = 416,0,0
thread block = 417,0,0
thread block = 418,0,0
thread block = 419,0,0
thread block = 420,0,0
thread block = 421,0,0
thread block = 422,0,0
thread block = 423,0,0
thread block = 424,0,0
thread block = 425,0,0
thread block = 426,0,0
thread block = 427,0,0
thread block = 428,0,0
thread block = 429,0,0
thread block = 430,0,0
thread block = 431,0,0
thread block = 432,0,0
thread block = 433,0,0
thread block = 434,0,0
thread block = 435,0,0
thread block = 436,0,0
thread block = 437,0,0
thread block = 438,0,0
thread block = 439,0,0
thread block = 440,0,0
thread block = 441,0,0
thread block = 442,0,0
thread block = 443,0,0
thread block = 444,0,0
thread block = 445,0,0
thread block = 446,0,0
thread block = 447,0,0
thread block = 448,0,0
thread block = 449,0,0
thread block = 450,0,0
thread block = 451,0,0
thread block = 452,0,0
thread block = 453,0,0
thread block = 454,0,0
thread block = 455,0,0
thread block = 456,0,0
thread block = 457,0,0
thread block = 458,0,0
thread block = 459,0,0
thread block = 460,0,0
thread block = 461,0,0
thread block = 462,0,0
thread block = 463,0,0
thread block = 464,0,0
thread block = 465,0,0
thread block = 466,0,0
thread block = 467,0,0
thread block = 468,0,0
thread block = 469,0,0
thread block = 470,0,0
thread block = 471,0,0
thread block = 472,0,0
thread block = 473,0,0
thread block = 474,0,0
thread block = 475,0,0
thread block = 476,0,0
thread block = 477,0,0
thread block = 478,0,0
thread block = 479,0,0
thread block = 480,0,0
thread block = 481,0,0
thread block = 482,0,0
thread block = 483,0,0
thread block = 484,0,0
thread block = 485,0,0
thread block = 486,0,0
thread block = 487,0,0
thread block = 488,0,0
thread block = 489,0,0
thread block = 490,0,0
thread block = 491,0,0
thread block = 492,0,0
thread block = 493,0,0
thread block = 494,0,0
thread block = 495,0,0
thread block = 496,0,0
thread block = 497,0,0
thread block = 498,0,0
thread block = 499,0,0
thread block = 500,0,0
thread block = 501,0,0
thread block = 502,0,0
thread block = 503,0,0
thread block = 504,0,0
thread block = 505,0,0
thread block = 506,0,0
thread block = 507,0,0
thread block = 508,0,0
thread block = 509,0,0
thread block = 510,0,0
thread block = 511,0,0
thread block = 512,0,0
thread block = 513,0,0
thread block = 514,0,0
thread block = 515,0,0
thread block = 516,0,0
thread block = 517,0,0
thread block = 518,0,0
thread block = 519,0,0
thread block = 520,0,0
thread block = 521,0,0
thread block = 522,0,0
thread block = 523,0,0
thread block = 524,0,0
thread block = 525,0,0
thread block = 526,0,0
thread block = 527,0,0
thread block = 528,0,0
thread block = 529,0,0
thread block = 530,0,0
thread block = 531,0,0
thread block = 532,0,0
thread block = 533,0,0
thread block = 534,0,0
thread block = 535,0,0
thread block = 536,0,0
thread block = 537,0,0
thread block = 538,0,0
thread block = 539,0,0
thread block = 540,0,0
thread block = 541,0,0
thread block = 542,0,0
thread block = 543,0,0
thread block = 544,0,0
thread block = 545,0,0
thread block = 546,0,0
thread block = 547,0,0
thread block = 548,0,0
thread block = 549,0,0
thread block = 550,0,0
thread block = 551,0,0
thread block = 552,0,0
thread block = 553,0,0
thread block = 554,0,0
thread block = 555,0,0
thread block = 556,0,0
thread block = 557,0,0
thread block = 558,0,0
thread block = 559,0,0
thread block = 560,0,0
thread block = 561,0,0
thread block = 562,0,0
thread block = 563,0,0
thread block = 564,0,0
thread block = 565,0,0
thread block = 566,0,0
thread block = 567,0,0
thread block = 568,0,0
thread block = 569,0,0
thread block = 570,0,0
thread block = 571,0,0
thread block = 572,0,0
thread block = 573,0,0
thread block = 574,0,0
thread block = 575,0,0
thread block = 576,0,0
thread block = 577,0,0
thread block = 578,0,0
thread block = 579,0,0
thread block = 580,0,0
thread block = 581,0,0
thread block = 582,0,0
thread block = 583,0,0
thread block = 584,0,0
thread block = 585,0,0
thread block = 586,0,0
thread block = 587,0,0
thread block = 588,0,0
thread block = 589,0,0
thread block = 590,0,0
thread block = 591,0,0
thread block = 592,0,0
thread block = 593,0,0
thread block = 594,0,0
thread block = 595,0,0
thread block = 596,0,0
thread block = 597,0,0
thread block = 598,0,0
thread block = 599,0,0
thread block = 600,0,0
thread block = 601,0,0
thread block = 602,0,0
thread block = 603,0,0
thread block = 604,0,0
thread block = 605,0,0
thread block = 606,0,0
thread block = 607,0,0
thread block = 608,0,0
thread block = 609,0,0
thread block = 610,0,0
thread block = 611,0,0
thread block = 612,0,0
thread block = 613,0,0
thread block = 614,0,0
thread block = 615,0,0
thread block = 616,0,0
thread block = 617,0,0
thread block = 618,0,0
thread block = 619,0,0
thread block = 620,0,0
thread block = 621,0,0
thread block = 622,0,0
thread block = 623,0,0
thread block = 624,0,0
thread block = 625,0,0
thread block = 626,0,0
thread block = 627,0,0
thread block = 628,0,0
thread block = 629,0,0
thread block = 630,0,0
thread block = 631,0,0
thread block = 632,0,0
thread block = 633,0,0
thread block = 634,0,0
thread block = 635,0,0
thread block = 636,0,0
thread block = 637,0,0
thread block = 638,0,0
thread block = 639,0,0
thread block = 640,0,0
thread block = 641,0,0
thread block = 642,0,0
thread block = 643,0,0
thread block = 644,0,0
thread block = 645,0,0
thread block = 646,0,0
thread block = 647,0,0
thread block = 648,0,0
thread block = 649,0,0
thread block = 650,0,0
thread block = 651,0,0
thread block = 652,0,0
thread block = 653,0,0
thread block = 654,0,0
thread block = 655,0,0
thread block = 656,0,0
thread block = 657,0,0
thread block = 658,0,0
thread block = 659,0,0
thread block = 660,0,0
thread block = 661,0,0
thread block = 662,0,0
thread block = 663,0,0
thread block = 664,0,0
thread block = 665,0,0
thread block = 666,0,0
thread block = 667,0,0
thread block = 668,0,0
thread block = 669,0,0
thread block = 670,0,0
thread block = 671,0,0
thread block = 672,0,0
thread block = 673,0,0
thread block = 674,0,0
thread block = 675,0,0
thread block = 676,0,0
thread block = 677,0,0
thread block = 678,0,0
thread block = 679,0,0
thread block = 680,0,0
thread block = 681,0,0
thread block = 682,0,0
thread block = 683,0,0
thread block = 684,0,0
thread block = 685,0,0
thread block = 686,0,0
thread block = 687,0,0
thread block = 688,0,0
thread block = 689,0,0
thread block = 690,0,0
thread block = 691,0,0
thread block = 692,0,0
thread block = 693,0,0
thread block = 694,0,0
thread block = 695,0,0
thread block = 696,0,0
thread block = 697,0,0
thread block = 698,0,0
thread block = 699,0,0
thread block = 700,0,0
thread block = 701,0,0
thread block = 702,0,0
thread block = 703,0,0
thread block = 704,0,0
thread block = 705,0,0
thread block = 706,0,0
thread block = 707,0,0
thread block = 708,0,0
thread block = 709,0,0
thread block = 710,0,0
thread block = 711,0,0
thread block = 712,0,0
thread block = 713,0,0
thread block = 714,0,0
thread block = 715,0,0
thread block = 716,0,0
thread block = 717,0,0
thread block = 718,0,0
thread block = 719,0,0
thread block = 720,0,0
thread block = 721,0,0
thread block = 722,0,0
thread block = 723,0,0
thread block = 724,0,0
thread block = 725,0,0
thread block = 726,0,0
thread block = 727,0,0
thread block = 728,0,0
thread block = 729,0,0
thread block = 730,0,0
thread block = 731,0,0
thread block = 732,0,0
thread block = 733,0,0
thread block = 734,0,0
thread block = 735,0,0
thread block = 736,0,0
thread block = 737,0,0
thread block = 738,0,0
thread block = 739,0,0
thread block = 740,0,0
thread block = 741,0,0
thread block = 742,0,0
thread block = 743,0,0
thread block = 744,0,0
thread block = 745,0,0
thread block = 746,0,0
thread block = 747,0,0
thread block = 748,0,0
thread block = 749,0,0
thread block = 750,0,0
thread block = 751,0,0
thread block = 752,0,0
thread block = 753,0,0
thread block = 754,0,0
thread block = 755,0,0
thread block = 756,0,0
thread block = 757,0,0
thread block = 758,0,0
thread block = 759,0,0
thread block = 760,0,0
thread block = 761,0,0
thread block = 762,0,0
thread block = 763,0,0
thread block = 764,0,0
thread block = 765,0,0
thread block = 766,0,0
thread block = 767,0,0
thread block = 768,0,0
thread block = 769,0,0
thread block = 770,0,0
thread block = 771,0,0
thread block = 772,0,0
thread block = 773,0,0
thread block = 774,0,0
thread block = 775,0,0
thread block = 776,0,0
thread block = 777,0,0
thread block = 778,0,0
thread block = 779,0,0
thread block = 780,0,0
thread block = 781,0,0
thread block = 782,0,0
thread block = 783,0,0
thread block = 784,0,0
thread block = 785,0,0
thread block = 786,0,0
thread block = 787,0,0
thread block = 788,0,0
thread block = 789,0,0
thread block = 790,0,0
thread block = 791,0,0
thread block = 792,0,0
thread block = 793,0,0
thread block = 794,0,0
thread block = 795,0,0
thread block = 796,0,0
thread block = 797,0,0
thread block = 798,0,0
thread block = 799,0,0
thread block = 800,0,0
thread block = 801,0,0
thread block = 802,0,0
thread block = 803,0,0
thread block = 804,0,0
thread block = 805,0,0
thread block = 806,0,0
thread block = 807,0,0
thread block = 808,0,0
thread block = 809,0,0
thread block = 810,0,0
thread block = 811,0,0
thread block = 812,0,0
thread block = 813,0,0
thread block = 814,0,0
thread block = 815,0,0
thread block = 816,0,0
thread block = 817,0,0
thread block = 818,0,0
thread block = 819,0,0
thread block = 820,0,0
thread block = 821,0,0
thread block = 822,0,0
thread block = 823,0,0
thread block = 824,0,0
thread block = 825,0,0
thread block = 826,0,0
thread block = 827,0,0
thread block = 828,0,0
thread block = 829,0,0
thread block = 830,0,0
thread block = 831,0,0
thread block = 832,0,0
thread block = 833,0,0
thread block = 834,0,0
thread block = 835,0,0
thread block = 836,0,0
thread block = 837,0,0
thread block = 838,0,0
thread block = 839,0,0
thread block = 840,0,0
thread block = 841,0,0
thread block = 842,0,0
thread block = 843,0,0
thread block = 844,0,0
thread block = 845,0,0
thread block = 846,0,0
thread block = 847,0,0
thread block = 848,0,0
thread block = 849,0,0
thread block = 850,0,0
thread block = 851,0,0
thread block = 852,0,0
thread block = 853,0,0
thread block = 854,0,0
thread block = 855,0,0
thread block = 856,0,0
thread block = 857,0,0
thread block = 858,0,0
thread block = 859,0,0
thread block = 860,0,0
thread block = 861,0,0
thread block = 862,0,0
thread block = 863,0,0
thread block = 864,0,0
thread block = 865,0,0
thread block = 866,0,0
thread block = 867,0,0
thread block = 868,0,0
thread block = 869,0,0
thread block = 870,0,0
thread block = 871,0,0
thread block = 872,0,0
thread block = 873,0,0
thread block = 874,0,0
thread block = 875,0,0
thread block = 876,0,0
thread block = 877,0,0
thread block = 878,0,0
thread block = 879,0,0
thread block = 880,0,0
thread block = 881,0,0
thread block = 882,0,0
thread block = 883,0,0
thread block = 884,0,0
thread block = 885,0,0
thread block = 886,0,0
thread block = 887,0,0
thread block = 888,0,0
thread block = 889,0,0
thread block = 890,0,0
thread block = 891,0,0
thread block = 892,0,0
thread block = 893,0,0
thread block = 894,0,0
thread block = 895,0,0
thread block = 896,0,0
thread block = 897,0,0
thread block = 898,0,0
thread block = 899,0,0
thread block = 900,0,0
thread block = 901,0,0
thread block = 902,0,0
thread block = 903,0,0
thread block = 904,0,0
thread block = 905,0,0
thread block = 906,0,0
thread block = 907,0,0
thread block = 908,0,0
thread block = 909,0,0
thread block = 910,0,0
thread block = 911,0,0
thread block = 912,0,0
thread block = 913,0,0
thread block = 914,0,0
thread block = 915,0,0
thread block = 916,0,0
thread block = 917,0,0
thread block = 918,0,0
thread block = 919,0,0
thread block = 920,0,0
thread block = 921,0,0
thread block = 922,0,0
thread block = 923,0,0
thread block = 924,0,0
thread block = 925,0,0
thread block = 926,0,0
thread block = 927,0,0
thread block = 928,0,0
thread block = 929,0,0
thread block = 930,0,0
thread block = 931,0,0
thread block = 932,0,0
thread block = 933,0,0
thread block = 934,0,0
thread block = 935,0,0
thread block = 936,0,0
thread block = 937,0,0
thread block = 938,0,0
thread block = 939,0,0
thread block = 940,0,0
thread block = 941,0,0
thread block = 942,0,0
thread block = 943,0,0
thread block = 944,0,0
thread block = 945,0,0
thread block = 946,0,0
thread block = 947,0,0
thread block = 948,0,0
thread block = 949,0,0
thread block = 950,0,0
thread block = 951,0,0
thread block = 952,0,0
thread block = 953,0,0
thread block = 954,0,0
thread block = 955,0,0
thread block = 956,0,0
thread block = 957,0,0
thread block = 958,0,0
thread block = 959,0,0
thread block = 960,0,0
thread block = 961,0,0
thread block = 962,0,0
thread block = 963,0,0
thread block = 964,0,0
thread block = 965,0,0
thread block = 966,0,0
thread block = 967,0,0
thread block = 968,0,0
thread block = 969,0,0
thread block = 970,0,0
thread block = 971,0,0
thread block = 972,0,0
thread block = 973,0,0
thread block = 974,0,0
thread block = 975,0,0
thread block = 976,0,0
Destroy streams for kernel 1: size 0
kernel_name = _Z6vecAddPdS_S_i 
kernel_launch_uid = 1 
gpu_sim_cycle = 158391
gpu_sim_insn = 22004032
gpu_ipc =     138.9222
gpu_tot_sim_cycle = 158391
gpu_tot_sim_insn = 22004032
gpu_tot_ipc =     138.9222
gpu_tot_issued_cta = 977
gpu_occupancy = 67.9278% 
gpu_tot_occupancy = 67.9278% 
max_total_param_size = 0
gpu_stall_dramfull = 1182774
gpu_stall_icnt2sh    = 4723
partiton_level_parallism =       1.1840
partiton_level_parallism_total  =       1.1840
partiton_level_parallism_util =       2.2656
partiton_level_parallism_util_total  =       2.2656
L2_BW  =     112.2273 GB/Sec
L2_BW_total  =     112.2273 GB/Sec
gpu_total_sim_rate=213631

========= Core cache stats =========
L1I_cache:
	L1I_total_cache_accesses = 375070
	L1I_total_cache_misses = 1920
	L1I_total_cache_miss_rate = 0.0051
	L1I_total_cache_pending_hits = 0
	L1I_total_cache_reservation_fails = 8120
L1D_cache:
	L1D_cache_core[0]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[1]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[2]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[3]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[4]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[5]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[6]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[7]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[8]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[9]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[10]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[11]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[12]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[13]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[14]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[15]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[16]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[17]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[18]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_cache_core[19]: Access = 0, Miss = 0, Miss_rate = -nan, Pending_hits = 0, Reservation_fails = 0
	L1D_total_cache_accesses = 0
	L1D_total_cache_misses = 0
	L1D_total_cache_pending_hits = 0
	L1D_total_cache_reservation_fails = 0
	L1D_cache_data_port_util = 0.000
	L1D_cache_fill_port_util = 0.000
L1C_cache:
	L1C_total_cache_accesses = 0
	L1C_total_cache_misses = 0
	L1C_total_cache_pending_hits = 0
	L1C_total_cache_reservation_fails = 0
L1T_cache:
	L1T_total_cache_accesses = 0
	L1T_total_cache_misses = 0
	L1T_total_cache_pending_hits = 0
	L1T_total_cache_reservation_fails = 0

Total_core_cache_stats:
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT] = 373150
	Total_core_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MISS] = 1920
	Total_core_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 8120
	Total_core_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 1880
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	Total_core_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	Total_core_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 375070

Total_core_cache_fail_stats:
	Total_core_cache_fail_stats_breakdown[INST_ACC_R][MSHR_MERGE_ENRTY_FAIL] = 8120
ctas_completed 977, Shader 0 warp_id issue ditsribution:
warp_id:
0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 
distro:
650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 650, 
gpgpu_n_tot_thrd_icount = 23004032
gpgpu_n_tot_w_icount = 718876
gpgpu_n_stall_shd_mem = 2712439
gpgpu_n_mem_read_local = 0
gpgpu_n_mem_write_local = 0
gpgpu_n_mem_read_global = 125000
gpgpu_n_mem_write_global = 62500
gpgpu_n_mem_texture = 0
gpgpu_n_mem_const = 0
gpgpu_n_load_insn  = 2000000
gpgpu_n_store_insn = 1000000
gpgpu_n_shmem_insn = 0
gpgpu_n_sstarr_insn = 0
gpgpu_n_tex_insn = 0
gpgpu_n_const_mem_insn = 0
gpgpu_n_param_mem_insn = 0
gpgpu_n_shmem_bkconflict = 0
gpgpu_n_cache_bkconflict = 0
gpgpu_n_intrawarp_mshr_merge = 0
gpgpu_n_cmem_portconflict = 0
gpgpu_stall_shd_mem[c_mem][resource_stall] = 0
gpgpu_stall_shd_mem[s_mem][bk_conf] = 0
gpgpu_stall_shd_mem[gl_mem][resource_stall] = 0
gpgpu_stall_shd_mem[gl_mem][coal_stall] = 93750
gpgpu_stall_shd_mem[gl_mem][data_port_stall] = 0
gpu_reg_bank_conflict_stalls = 0
Warp Occupancy Distribution:
Stall:4437673	W0_Idle:215976	W0_Scoreboard:1064664	W1:0	W2:0	W3:0	W4:0	W5:0	W6:0	W7:0	W8:0	W9:0	W10:0	W11:0	W12:0	W13:0	W14:0	W15:0	W16:0	W17:0	W18:0	W19:0	W20:0	W21:0	W22:0	W23:0	W24:0	W25:0	W26:0	W27:0	W28:0	W29:0	W30:0	W31:0	W32:687626
single_issue_nums: WS0:265684	WS1:265682	
dual_issue_nums: WS0:46877	WS1:46878	
traffic_breakdown_coretomem[GLOBAL_ACC_R] = 1000000 {8:125000,}
traffic_breakdown_coretomem[GLOBAL_ACC_W] = 8500000 {136:62500,}
traffic_breakdown_coretomem[INST_ACC_R] = 320 {8:40,}
traffic_breakdown_memtocore[GLOBAL_ACC_R] = 17000000 {136:125000,}
traffic_breakdown_memtocore[GLOBAL_ACC_W] = 500000 {8:62500,}
traffic_breakdown_memtocore[INST_ACC_R] = 5440 {136:40,}
maxmflatency = 4365 
max_icnt2mem_latency = 1344 
maxmrqlatency = 3016 
max_icnt2sh_latency = 90 
averagemflatency = 1025 
avg_icnt2mem_latency = 182 
avg_mrq_latency = 317 
avg_icnt2sh_latency = 5 
mrq_lat_table:41190 	350 	2711 	6358 	12195 	22331 	29715 	36285 	44990 	36537 	15709 	1631 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
dq_lat_table:0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_table:0 	0 	0 	0 	0 	0 	0 	55 	12229 	105307 	60663 	9228 	18 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2mem_lat_table:0 	0 	1567 	30010 	22176 	16763 	20875 	38274 	49425 	8253 	197 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
icnt2sh_lat_table:0 	0 	162900 	23164 	1309 	118 	9 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
mf_lat_pw_table:0 	0 	0 	0 	0 	0 	0 	0 	1 	171 	142 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	0 	
maximum concurrent accesses to same row:
dram[0]:        32        32        32        32        32        32        32        32        32        32        32        32        32        32        30        30 
dram[1]:        32        32        32        32        32        32        32        32        32        32        32        32        30        30        30        30 
dram[2]:        30        30        32        32        32        32        32        32        32        32        32        32        28        28        30        30 
dram[3]:        32        32        30        30        32        32        32        32        32        32        26        26        30        30        28        28 
dram[4]:        30        30        28        28        32        32        32        32        32        32        26        30        26        26        30        30 
dram[5]:        32        32        32        32        32        32        32        32        32        32        28        28        28        28        28        28 
dram[6]:        32        32        32        32        32        32        32        32        32        32        32        32        30        30        30        30 
dram[7]:        30        30        32        32        32        32        32        32        32        32        28        28        30        30        32        32 
maximum service time to same row:
dram[0]:      3308      3213      3542      3456      3386      3386      2963      2965      2767      2775      3571      3596      3570      3569      2841      2562 
dram[1]:      3591      3581      3949      3890      2970      3053      3023      3547      3075      3386      3470      3430      2846      2940      2687      3102 
dram[2]:      3182      3177      2935      3542      3232      3232      2633      2634      2758      2689      2926      2884      2570      2544      2608      2614 
dram[3]:      3691      3690      3017      2951      2855      2856      3451      3484      2673      2683      2414      2386      2609      2615      2824      2809 
dram[4]:      3132      3232      3067      3067      2479      2694      3087      3030      3301      3276      2429      2715      2732      2519      2429      2459 
dram[5]:      3425      3524      3330      3278      2900      2896      2873      2883      2878      2832      3322      3376      2696      2559      2555      2547 
dram[6]:      3635      3629      3804      3797      3625      3620      3081      3082      3160      3167      2950      2956      2714      2761      2662      2663 
dram[7]:      3944      3945      3371      3379      3452      3432      3401      3407      2904      2858      2878      2878      2892      2899      3568      3567 
average row accesses per activate:
dram[0]:  3.689591  3.832046  3.627057  3.815385  3.920949  3.952191  3.574775  3.722327  3.680000  3.840954  3.824701  3.926380  3.902439  3.902439  3.809524  3.902439 
dram[1]:  3.852427  3.822736  3.882583  4.016194  3.574775  3.928713  3.750473  3.660517  3.666034  3.666034  3.542435  3.602251  3.629490  3.678161  3.855422  3.809524 
dram[2]:  3.640367  3.647059  3.647059  3.786260  3.952191  4.032520  3.647059  3.764706  3.473874  3.644613  3.671128  3.757339  3.692308  3.870968  3.878788  3.958763 
dram[3]:  3.808061  3.897839  3.523979  3.771863  3.729323  3.936508  3.530249  3.694600  3.810277  3.848303  3.685221  3.934426  3.692308  3.886640  3.622642  3.728155 
dram[4]:  3.340067  3.486819  3.687732  3.944334  3.607273  3.750473  3.779048  3.882583  3.840637  4.008316  3.801980  3.942505  3.855422  4.102564  3.453237  3.609023 
dram[5]:  3.486819  3.633700  3.640367  3.800766  3.561939  3.660517  3.771863  4.032520  3.511840  3.679389  3.615819  3.855422  3.678161  3.847695  3.522936  3.685221 
dram[6]:  3.523979  3.674074  3.568345  3.786260  3.627057  3.687732  3.667283  3.800766  4.050420  4.093418  3.678161  3.824701  3.657143  3.832335  3.629490  3.706564 
dram[7]:  3.480702  3.701493  3.701493  3.913215  3.708411  3.793499  3.334454  3.523979  3.750973  3.926680  3.293310  3.453237  3.650190  3.786982  3.602251  3.801980 
average row locality = 250002/67026 = 3.729926
number of total memory accesses made:
dram[0]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[1]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[2]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[3]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[4]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[5]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[6]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
dram[7]:         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0 
total accesses: 0
min_bank_accesses = 0!
min_chip_accesses = 0!
number of total read accesses:
dram[0]:      5956      5956      5952      5952      5952      5952      5952      5952      5796      5796      5760      5760      5760      5760      5760      5760 
dram[1]:      5952      5952      5952      5952      5952      5952      5952      5952      5796      5796      5760      5760      5760      5760      5760      5760 
dram[2]:      5952      5952      5952      5952      5952      5952      5952      5952      5784      5784      5760      5760      5760      5760      5760      5760 
dram[3]:      5952      5952      5952      5952      5952      5952      5952      5952      5784      5784      5760      5760      5760      5760      5760      5760 
dram[4]:      5952      5952      5952      5952      5952      5952      5952      5952      5784      5784      5760      5760      5760      5760      5760      5760 
dram[5]:      5952      5952      5952      5952      5952      5952      5952      5952      5784      5784      5760      5760      5760      5760      5760      5760 
dram[6]:      5952      5952      5952      5952      5952      5952      5952      5952      5784      5784      5760      5760      5760      5760      5760      5760 
dram[7]:      5952      5952      5952      5952      5952      5952      5952      5952      5784      5784      5760      5760      5760      5760      5760      5760 
total dram reads = 750008
bank skew: 5956/5760 = 1.03
chip skew: 93776/93744 = 1.00
number of total write accesses:
dram[0]:      1984      1984      1984      1984      1984      1984      1984      1984      1932      1932      1920      1920      1920      1920      1920      1920 
dram[1]:      1984      1984      1984      1984      1984      1984      1984      1984      1932      1932      1920      1920      1920      1920      1920      1920 
dram[2]:      1984      1984      1984      1984      1984      1984      1984      1984      1928      1928      1920      1920      1920      1920      1920      1920 
dram[3]:      1984      1984      1984      1984      1984      1984      1984      1984      1928      1928      1920      1920      1920      1920      1920      1920 
dram[4]:      1984      1984      1984      1984      1984      1984      1984      1984      1928      1928      1920      1920      1920      1920      1920      1920 
dram[5]:      1984      1984      1984      1984      1984      1984      1984      1984      1928      1928      1920      1920      1920      1920      1920      1920 
dram[6]:      1984      1984      1984      1984      1984      1984      1984      1984      1928      1928      1920      1920      1920      1920      1920      1920 
dram[7]:      1984      1984      1984      1984      1984      1984      1984      1984      1928      1928      1920      1920      1920      1920      1920      1920 
total dram writes = 250000
bank skew: 1984/1920 = 1.03
chip skew: 31256/31248 = 1.00
average mf latency per bank:
dram[0]:        224       229       217       222       224       228       223       225       221       228       226       232       226       229       226       226
dram[1]:        219       215       222       219       214       221       216       212       219       218       223       223       227       222       223       218
dram[2]:        198       205       196       204       201       206       199       206       197       204       204       211       202       208       208       217
dram[3]:        177       186       171       181       177       185       174       183       180       187       183       192       181       190       175       184
dram[4]:        154       163       160       167       155       162       159       166       159       168       165       172       159       172       158       167
dram[5]:        168       175       178       184       168       173       172       180       173       181       175       183       172       178       169       173
dram[6]:        169       176       166       172       164       168       169       172       175       180       171       179       172       178       171       176
dram[7]:        188       194       194       201       189       196       187       193       193       200       191       197       190       198       190       197
maximum mf latency per bank:
dram[0]:       4225      4365      3364      3374      3689      3699      3800      3805      3674      3745      3484      3491      3822      3674      3632      3417
dram[1]:       3514      3492      3975      3499      3319      3840      3454      3509      3973      3696      3522      3538      3725      3846      3569      3630
dram[2]:       3123      3355      3430      3523      3361      3177      3388      3577      3214      3243      3423      3508      3443      3487      3571      3569
dram[3]:       3388      3402      3544      3555      3619      3631      3655      3675      3065      3300      3407      3373      3358      3400      3548      3561
dram[4]:       3630      3724      2970      2981      3134      3174      3030      2951      2992      3055      2926      3203      3110      3184      3163      3351
dram[5]:       2776      3264      3830      3683      2952      2968      3085      3421      3498      3506      2780      2909      3029      3040      2959      2970
dram[6]:       4124      4346      3237      3333      3343      3353      3981      3755      3384      3232      3802      3808      3773      3779      3571      3651
dram[7]:       3705      3754      3437      3454      3405      3440      3555      3822      3592      3586      3244      3249      3154      3245      3500      3749
Memory Partition 0: 
Cache L2_bank_000:
MSHR contents
MSHR: tag=0xe599d800, atomic=0 1 entries : 0x563d2d0b8be0 :  mf: uid=633190, sid05:w24, part=0, addr=0x7f47e599d800, load , size=128, unknown  status = IN_PARTITION_DRAM (158390), 

Cache L2_bank_001:
MSHR contents
MSHR: tag=0xe599d880, atomic=0 1 entries : 0x563d2d69d850 :  mf: uid=633189, sid05:w24, part=0, addr=0x7f47e599d880, load , size=128, unknown  status = IN_PARTITION_DRAM (158389), 

In Dram Latency Queue (total = 0): 
DRAM[0]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=271047 n_nop=132645 n_act=8218 n_pre=8202 n_ref_event=0 n_req=31258 n_rd=62520 n_rd_L2_A=31252 n_write=31256 n_wr_bk=0 bw_util=0.9226
n_activity=269013 dram_eff=0.9295
bk0: 5956a 82087i bk1: 5956a 76382i bk2: 5952a 82709i bk3: 5952a 78998i bk4: 5952a 80416i bk5: 5952a 75866i bk6: 5952a 76607i bk7: 5948a 72001i bk8: 5796a 83040i bk9: 5796a 77930i bk10: 5760a 84080i bk11: 5760a 78335i bk12: 5760a 83042i bk13: 5760a 79015i bk14: 5760a 82739i bk15: 5760a 79261i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.737091
Row_Buffer_Locality_read = 0.723085
Row_Buffer_Locality_write = 0.779114
Bank_Level_Parallism = 11.500754
Bank_Level_Parallism_Col = 11.015059
Bank_Level_Parallism_Ready = 5.442451
write_to_read_ratio_blp_rw_average = 0.497089
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.922556 
total_CMD = 271047 
util_bw = 250055 
Wasted_Col = 18883 
Wasted_Row = 24 
Idle = 2085 

BW Util Bottlenecks: 
RCDc_limit = 4707 
RCDWRc_limit = 1085 
WTRc_limit = 89383 
RTWc_limit = 92784 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 89383 
RTWc_limit_alone = 92784 

Commands details: 
total_CMD = 271047 
n_nop = 132645 
Read = 62520 
Write = 31256 
L2_Alloc = 31252 
L2_WB = 0 
n_act = 8218 
n_pre = 8202 
n_ref = 0 
n_req = 31258 
total_req = 125028 

Dual Bus Interface Util: 
issued_total_row = 16420 
issued_total_col = 125028 
Row_Bus_Util =  0.060580 
CoL_Bus_Util = 0.461278 
Either_Row_CoL_Bus_Util = 0.510620 
Issued_on_Two_Bus_Simul_Util = 0.011238 
issued_two_Eff = 0.022008 
queue_avg = 63.184494 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=63.1845
Memory Partition 1: 
Cache L2_bank_002:
MSHR contents

Cache L2_bank_003:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[1]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=271047 n_nop=132247 n_act=8352 n_pre=8336 n_ref_event=0 n_req=31256 n_rd=62512 n_rd_L2_A=31256 n_write=31256 n_wr_bk=0 bw_util=0.9225
n_activity=268969 dram_eff=0.9297
bk0: 5952a 77384i bk1: 5952a 75400i bk2: 5952a 78174i bk3: 5952a 73909i bk4: 5952a 80014i bk5: 5952a 73885i bk6: 5952a 77288i bk7: 5952a 75375i bk8: 5796a 81056i bk9: 5796a 78660i bk10: 5760a 80680i bk11: 5760a 76486i bk12: 5760a 77966i bk13: 5760a 74930i bk14: 5760a 82584i bk15: 5760a 80542i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.732787
Row_Buffer_Locality_read = 0.718539
Row_Buffer_Locality_write = 0.775531
Bank_Level_Parallism = 11.600515
Bank_Level_Parallism_Col = 11.121921
Bank_Level_Parallism_Ready = 5.400351
write_to_read_ratio_blp_rw_average = 0.503433
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.922526 
total_CMD = 271047 
util_bw = 250048 
Wasted_Col = 18887 
Wasted_Row = 12 
Idle = 2100 

BW Util Bottlenecks: 
RCDc_limit = 4924 
RCDWRc_limit = 1068 
WTRc_limit = 89403 
RTWc_limit = 95972 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 89403 
RTWc_limit_alone = 95972 

Commands details: 
total_CMD = 271047 
n_nop = 132247 
Read = 62512 
Write = 31256 
L2_Alloc = 31256 
L2_WB = 0 
n_act = 8352 
n_pre = 8336 
n_ref = 0 
n_req = 31256 
total_req = 125024 

Dual Bus Interface Util: 
issued_total_row = 16688 
issued_total_col = 125024 
Row_Bus_Util =  0.061569 
CoL_Bus_Util = 0.461263 
Either_Row_CoL_Bus_Util = 0.512088 
Issued_on_Two_Bus_Simul_Util = 0.010744 
issued_two_Eff = 0.020980 
queue_avg = 63.174927 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=63.1749
Memory Partition 2: 
Cache L2_bank_004:
MSHR contents
MSHR: tag=0xe599da00, atomic=0 1 entries : 0x563d2db251e0 :  mf: uid=633184, sid05:w26, part=2, addr=0x7f47e599da00, load , size=128, unknown  status = IN_PARTITION_DRAM (158390), 

Cache L2_bank_005:
MSHR contents
MSHR: tag=0xe599da80, atomic=0 1 entries : 0x563d2d3df0f0 :  mf: uid=633183, sid05:w26, part=2, addr=0x7f47e599da80, load , size=128, unknown  status = IN_PARTITION_DRAM (158389), 

In Dram Latency Queue (total = 0): 
DRAM[2]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=271047 n_nop=132638 n_act=8336 n_pre=8320 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31242 n_write=31248 n_wr_bk=0 bw_util=0.9222
n_activity=268781 dram_eff=0.93
bk0: 5952a 83613i bk1: 5952a 78443i bk2: 5952a 81446i bk3: 5952a 75612i bk4: 5952a 84157i bk5: 5952a 78903i bk6: 5950a 75460i bk7: 5948a 69972i bk8: 5784a 81555i bk9: 5784a 76639i bk10: 5760a 80506i bk11: 5760a 77079i bk12: 5760a 81638i bk13: 5760a 77271i bk14: 5760a 81900i bk15: 5760a 78378i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.733231
Row_Buffer_Locality_read = 0.719193
Row_Buffer_Locality_write = 0.775346
Bank_Level_Parallism = 11.546486
Bank_Level_Parallism_Col = 11.046857
Bank_Level_Parallism_Ready = 5.381602
write_to_read_ratio_blp_rw_average = 0.502093
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.922246 
total_CMD = 271047 
util_bw = 249971 
Wasted_Col = 18788 
Wasted_Row = 12 
Idle = 2276 

BW Util Bottlenecks: 
RCDc_limit = 4587 
RCDWRc_limit = 974 
WTRc_limit = 87304 
RTWc_limit = 94101 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 87304 
RTWc_limit_alone = 94101 

Commands details: 
total_CMD = 271047 
n_nop = 132638 
Read = 62496 
Write = 31248 
L2_Alloc = 31242 
L2_WB = 0 
n_act = 8336 
n_pre = 8320 
n_ref = 0 
n_req = 31248 
total_req = 124986 

Dual Bus Interface Util: 
issued_total_row = 16656 
issued_total_col = 124986 
Row_Bus_Util =  0.061451 
CoL_Bus_Util = 0.461123 
Either_Row_CoL_Bus_Util = 0.510646 
Issued_on_Two_Bus_Simul_Util = 0.011928 
issued_two_Eff = 0.023358 
queue_avg = 63.165047 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=63.165
Memory Partition 3: 
Cache L2_bank_006:
MSHR contents

Cache L2_bank_007:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[3]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=271047 n_nop=132529 n_act=8329 n_pre=8313 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9223
n_activity=268377 dram_eff=0.9315
bk0: 5952a 77068i bk1: 5952a 70768i bk2: 5952a 79161i bk3: 5952a 73844i bk4: 5952a 78810i bk5: 5952a 71935i bk6: 5952a 76784i bk7: 5952a 70163i bk8: 5784a 80074i bk9: 5784a 73251i bk10: 5760a 79196i bk11: 5760a 73904i bk12: 5760a 80237i bk13: 5760a 74511i bk14: 5760a 79247i bk15: 5760a 74152i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.733455
Row_Buffer_Locality_read = 0.720387
Row_Buffer_Locality_write = 0.772657
Bank_Level_Parallism = 11.750016
Bank_Level_Parallism_Col = 11.256732
Bank_Level_Parallism_Ready = 5.461836
write_to_read_ratio_blp_rw_average = 0.502306
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.922290 
total_CMD = 271047 
util_bw = 249984 
Wasted_Col = 18341 
Wasted_Row = 12 
Idle = 2710 

BW Util Bottlenecks: 
RCDc_limit = 4362 
RCDWRc_limit = 1081 
WTRc_limit = 87037 
RTWc_limit = 94220 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 87037 
RTWc_limit_alone = 94220 

Commands details: 
total_CMD = 271047 
n_nop = 132529 
Read = 62496 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 8329 
n_pre = 8313 
n_ref = 0 
n_req = 31248 
total_req = 124992 

Dual Bus Interface Util: 
issued_total_row = 16642 
issued_total_col = 124992 
Row_Bus_Util =  0.061399 
CoL_Bus_Util = 0.461145 
Either_Row_CoL_Bus_Util = 0.511048 
Issued_on_Two_Bus_Simul_Util = 0.011496 
issued_two_Eff = 0.022495 
queue_avg = 62.676983 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=62.677
Memory Partition 4: 
Cache L2_bank_008:
MSHR contents

Cache L2_bank_009:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[4]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=271047 n_nop=132440 n_act=8348 n_pre=8332 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9223
n_activity=268230 dram_eff=0.932
bk0: 5952a 80700i bk1: 5952a 72455i bk2: 5952a 79220i bk3: 5952a 72110i bk4: 5952a 79049i bk5: 5952a 72973i bk6: 5952a 76365i bk7: 5952a 70668i bk8: 5784a 82025i bk9: 5784a 75964i bk10: 5760a 78968i bk11: 5760a 72930i bk12: 5760a 79473i bk13: 5760a 71802i bk14: 5760a 82267i bk15: 5760a 75526i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.732847
Row_Buffer_Locality_read = 0.723758
Row_Buffer_Locality_write = 0.760113
Bank_Level_Parallism = 11.724762
Bank_Level_Parallism_Col = 11.229166
Bank_Level_Parallism_Ready = 5.479269
write_to_read_ratio_blp_rw_average = 0.501407
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.922290 
total_CMD = 271047 
util_bw = 249984 
Wasted_Col = 18214 
Wasted_Row = 12 
Idle = 2837 

BW Util Bottlenecks: 
RCDc_limit = 3849 
RCDWRc_limit = 927 
WTRc_limit = 84541 
RTWc_limit = 94127 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 84541 
RTWc_limit_alone = 94127 

Commands details: 
total_CMD = 271047 
n_nop = 132440 
Read = 62496 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 8348 
n_pre = 8332 
n_ref = 0 
n_req = 31248 
total_req = 124992 

Dual Bus Interface Util: 
issued_total_row = 16680 
issued_total_col = 124992 
Row_Bus_Util =  0.061539 
CoL_Bus_Util = 0.461145 
Either_Row_CoL_Bus_Util = 0.511376 
Issued_on_Two_Bus_Simul_Util = 0.011308 
issued_two_Eff = 0.022113 
queue_avg = 60.482567 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=60.4826
Memory Partition 5: 
Cache L2_bank_010:
MSHR contents

Cache L2_bank_011:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[5]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=271047 n_nop=132286 n_act=8488 n_pre=8472 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9223
n_activity=268495 dram_eff=0.9311
bk0: 5952a 79538i bk1: 5952a 73703i bk2: 5952a 79205i bk3: 5952a 74328i bk4: 5952a 80688i bk5: 5952a 75922i bk6: 5952a 82758i bk7: 5952a 74729i bk8: 5784a 77990i bk9: 5784a 70801i bk10: 5760a 81089i bk11: 5760a 74509i bk12: 5760a 83691i bk13: 5760a 76999i bk14: 5760a 81875i bk15: 5760a 76461i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.728367
Row_Buffer_Locality_read = 0.716334
Row_Buffer_Locality_write = 0.764465
Bank_Level_Parallism = 11.630288
Bank_Level_Parallism_Col = 11.126752
Bank_Level_Parallism_Ready = 5.390835
write_to_read_ratio_blp_rw_average = 0.502945
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.922290 
total_CMD = 271047 
util_bw = 249984 
Wasted_Col = 18460 
Wasted_Row = 12 
Idle = 2591 

BW Util Bottlenecks: 
RCDc_limit = 4710 
RCDWRc_limit = 1062 
WTRc_limit = 85731 
RTWc_limit = 94829 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 85731 
RTWc_limit_alone = 94829 

Commands details: 
total_CMD = 271047 
n_nop = 132286 
Read = 62496 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 8488 
n_pre = 8472 
n_ref = 0 
n_req = 31248 
total_req = 124992 

Dual Bus Interface Util: 
issued_total_row = 16960 
issued_total_col = 124992 
Row_Bus_Util =  0.062572 
CoL_Bus_Util = 0.461145 
Either_Row_CoL_Bus_Util = 0.511944 
Issued_on_Two_Bus_Simul_Util = 0.011773 
issued_two_Eff = 0.022996 
queue_avg = 62.187931 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=62.1879
Memory Partition 6: 
Cache L2_bank_012:
MSHR contents

Cache L2_bank_013:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[6]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=271047 n_nop=132353 n_act=8375 n_pre=8359 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9223
n_activity=268244 dram_eff=0.9319
bk0: 5952a 76829i bk1: 5952a 70174i bk2: 5952a 80635i bk3: 5952a 74864i bk4: 5952a 78516i bk5: 5952a 72482i bk6: 5952a 73589i bk7: 5952a 67926i bk8: 5784a 83091i bk9: 5784a 77317i bk10: 5760a 78293i bk11: 5760a 71649i bk12: 5760a 78081i bk13: 5760a 72991i bk14: 5760a 78174i bk15: 5760a 72715i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.731983
Row_Buffer_Locality_read = 0.715054
Row_Buffer_Locality_write = 0.782770
Bank_Level_Parallism = 11.777317
Bank_Level_Parallism_Col = 11.281020
Bank_Level_Parallism_Ready = 5.456004
write_to_read_ratio_blp_rw_average = 0.502639
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.922290 
total_CMD = 271047 
util_bw = 249984 
Wasted_Col = 18206 
Wasted_Row = 24 
Idle = 2833 

BW Util Bottlenecks: 
RCDc_limit = 4533 
RCDWRc_limit = 868 
WTRc_limit = 85951 
RTWc_limit = 94848 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 85951 
RTWc_limit_alone = 94848 

Commands details: 
total_CMD = 271047 
n_nop = 132353 
Read = 62496 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 8375 
n_pre = 8359 
n_ref = 0 
n_req = 31248 
total_req = 124992 

Dual Bus Interface Util: 
issued_total_row = 16734 
issued_total_col = 124992 
Row_Bus_Util =  0.061738 
CoL_Bus_Util = 0.461145 
Either_Row_CoL_Bus_Util = 0.511697 
Issued_on_Two_Bus_Simul_Util = 0.011186 
issued_two_Eff = 0.021861 
queue_avg = 61.867012 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=61.867
Memory Partition 7: 
Cache L2_bank_014:
MSHR contents

Cache L2_bank_015:
MSHR contents

In Dram Latency Queue (total = 0): 
DRAM[7]: 16 bks, busW=4 BL=8 CL=12, tRRD=6 tCCD=2, tRCD=12 tRAS=28 tRP=12 tRC=40
n_cmd=271047 n_nop=132105 n_act=8580 n_pre=8564 n_ref_event=0 n_req=31248 n_rd=62496 n_rd_L2_A=31248 n_write=31248 n_wr_bk=0 bw_util=0.9223
n_activity=268703 dram_eff=0.9303
bk0: 5952a 79368i bk1: 5952a 74542i bk2: 5952a 77047i bk3: 5952a 71154i bk4: 5952a 77900i bk5: 5952a 72020i bk6: 5952a 73107i bk7: 5952a 67256i bk8: 5784a 79195i bk9: 5784a 73607i bk10: 5760a 75505i bk11: 5760a 71380i bk12: 5760a 78097i bk13: 5760a 72525i bk14: 5760a 77139i bk15: 5760a 72191i 

------------------------------------------------------------------------

Row_Buffer_Locality = 0.725422
Row_Buffer_Locality_read = 0.707501
Row_Buffer_Locality_write = 0.779186
Bank_Level_Parallism = 11.813569
Bank_Level_Parallism_Col = 11.303509
Bank_Level_Parallism_Ready = 5.433568
write_to_read_ratio_blp_rw_average = 0.506335
GrpLevelPara = 1.000000 

BW Util details:
bwutil = 0.922290 
total_CMD = 271047 
util_bw = 249984 
Wasted_Col = 18673 
Wasted_Row = 24 
Idle = 2366 

BW Util Bottlenecks: 
RCDc_limit = 4919 
RCDWRc_limit = 981 
WTRc_limit = 86770 
RTWc_limit = 97699 
CCDLc_limit = 0 
rwq = 0 
CCDLc_limit_alone = 0 
WTRc_limit_alone = 86770 
RTWc_limit_alone = 97699 

Commands details: 
total_CMD = 271047 
n_nop = 132105 
Read = 62496 
Write = 31248 
L2_Alloc = 31248 
L2_WB = 0 
n_act = 8580 
n_pre = 8564 
n_ref = 0 
n_req = 31248 
total_req = 124992 

Dual Bus Interface Util: 
issued_total_row = 17144 
issued_total_col = 124992 
Row_Bus_Util =  0.063251 
CoL_Bus_Util = 0.461145 
Either_Row_CoL_Bus_Util = 0.512612 
Issued_on_Two_Bus_Simul_Util = 0.011784 
issued_two_Eff = 0.022988 
queue_avg = 63.036350 


dram_util_bins: 0 0 0 0 0 0 0 0 0 0
dram_eff_bins: 0 0 0 0 0 0 0 0 0 0
mrqq: max=64 avg=63.0364

========= L2 cache stats =========
L2_cache_bank[0]: Access = 11741, Miss = 11722, Miss_rate = 0.998, Pending_hits = 19, Reservation_fails = 224
L2_cache_bank[1]: Access = 11741, Miss = 11722, Miss_rate = 0.998, Pending_hits = 19, Reservation_fails = 192
L2_cache_bank[2]: Access = 11721, Miss = 11721, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 243
L2_cache_bank[3]: Access = 11721, Miss = 11721, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 165
L2_cache_bank[4]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 209
L2_cache_bank[5]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 216
L2_cache_bank[6]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 159
L2_cache_bank[7]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 171
L2_cache_bank[8]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 71
L2_cache_bank[9]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 70
L2_cache_bank[10]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 147
L2_cache_bank[11]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 145
L2_cache_bank[12]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 114
L2_cache_bank[13]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 95
L2_cache_bank[14]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 194
L2_cache_bank[15]: Access = 11718, Miss = 11718, Miss_rate = 1.000, Pending_hits = 0, Reservation_fails = 192
L2_total_cache_accesses = 187540
L2_total_cache_misses = 187502
L2_total_cache_miss_rate = 0.9998
L2_total_cache_pending_hits = 38
L2_total_cache_reservation_fails = 2607
L2_total_cache_breakdown:
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MISS] = 125000
	L2_cache_stats_breakdown[GLOBAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[CONST_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[TEXTURE_ACC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MISS] = 62500
	L2_cache_stats_breakdown[GLOBAL_ACC_W][RESERVATION_FAIL] = 2607
	L2_cache_stats_breakdown[GLOBAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[LOCAL_ACC_W][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WRBK_ACC][MSHR_HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT] = 0
	L2_cache_stats_breakdown[INST_ACC_R][HIT_RESERVED] = 38
	L2_cache_stats_breakdown[INST_ACC_R][MISS] = 2
	L2_cache_stats_breakdown[INST_ACC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[INST_ACC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[INST_ACC_R][MSHR_HIT] = 38
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L1_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][HIT_RESERVED] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][RESERVATION_FAIL] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][SECTOR_MISS] = 0
	L2_cache_stats_breakdown[L2_WR_ALLOC_R][MSHR_HIT] = 0
	L2_cache_stats_breakdown[GLOBAL_ACC_R][TOTAL_ACCESS] = 125000
	L2_cache_stats_breakdown[GLOBAL_ACC_W][TOTAL_ACCESS] = 62500
	L2_cache_stats_breakdown[INST_ACC_R][TOTAL_ACCESS] = 40
L2_total_cache_reservation_fail_breakdown:
	L2_cache_stats_fail_breakdown[GLOBAL_ACC_W][MISS_QUEUE_FULL] = 2607
L2_cache_data_port_util = 0.000
L2_cache_fill_port_util = 0.296

icnt_total_pkts_mem_to_simt=687700
icnt_total_pkts_simt_to_mem=437540
LD_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
ST_mem_lat_dist  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
----------------------------Interconnect-DETAILS--------------------------------
Class 0:
Packet latency average = 146.657
	minimum = 6
	maximum = 2462
Network latency average = 85.8878
	minimum = 6
	maximum = 2301
Slowest packet = 3643
Flit latency average = 48.2248
	minimum = 6
	maximum = 2301
Slowest flit = 3881
Fragmentation average = 1.49409
	minimum = 0
	maximum = 1077
Injected packet rate average = 0.0256954
	minimum = 0 (at node 36)
	maximum = 0.0402168 (at node 20)
Accepted packet rate average = 0.0256954
	minimum = 0 (at node 36)
	maximum = 0.0402168 (at node 20)
Injected flit rate average = 0.0770863
	minimum = 0 (at node 36)
	maximum = 0.147553 (at node 20)
Accepted flit rate average= 0.0770863
	minimum = 0 (at node 36)
	maximum = 0.120606 (at node 0)
Injected packet length average = 3
Accepted packet length average = 3
Total in-flight flits = 0 (0 measured)
====== Overall Traffic Statistics ======
====== Traffic class 0 ======
Packet latency average = 146.657 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2462 (1 samples)
Network latency average = 85.8878 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2301 (1 samples)
Flit latency average = 48.2248 (1 samples)
	minimum = 6 (1 samples)
	maximum = 2301 (1 samples)
Fragmentation average = 1.49409 (1 samples)
	minimum = 0 (1 samples)
	maximum = 1077 (1 samples)
Injected packet rate average = 0.0256954 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0402168 (1 samples)
Accepted packet rate average = 0.0256954 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.0402168 (1 samples)
Injected flit rate average = 0.0770863 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.147553 (1 samples)
Accepted flit rate average = 0.0770863 (1 samples)
	minimum = 0 (1 samples)
	maximum = 0.120606 (1 samples)
Injected packet size average = 3 (1 samples)
Accepted packet size average = 3 (1 samples)
Hops average = 1 (1 samples)
----------------------------END-of-Interconnect-DETAILS-------------------------


gpgpu_simulation_time = 0 days, 0 hrs, 1 min, 43 sec (103 sec)
gpgpu_simulation_rate = 213631 (inst/sec)
gpgpu_simulation_rate = 1537 (cycle/sec)
gpgpu_silicon_slowdown = 1045543x
GPGPU-Sim: *** simulation thread exiting ***
GPGPU-Sim: *** exit detected ***
